schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"""whether this query should be cached (Hasura Cloud only)"""
directive @cached(
  """measured in seconds"""
  ttl: Int! = 60

  """refresh the cache entry"""
  refresh: Boolean! = false
) on QUERY

"""
columns and relationships of "BondingCurve"
"""
type BondingCurve {
  address: String!
  bcType: String
  buyFee: numeric!
  buyReserveRatio: numeric!
  chainId: Int!

  """An object relationship"""
  collateralToken: Token
  collateralToken_id: String!

  """An array relationship"""
  curveDayData(
    """distinct select on columns"""
    distinct_on: [CurveDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveDayData_order_by!]

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): [CurveDayData!]!

  """An aggregate relationship"""
  curveDayData_aggregate(
    """distinct select on columns"""
    distinct_on: [CurveDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveDayData_order_by!]

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): CurveDayData_aggregate!

  """An array relationship"""
  curveHourData(
    """distinct select on columns"""
    distinct_on: [CurveHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveHourData_order_by!]

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): [CurveHourData!]!

  """An aggregate relationship"""
  curveHourData_aggregate(
    """distinct select on columns"""
    distinct_on: [CurveHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveHourData_order_by!]

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): CurveHourData_aggregate!
  db_write_timestamp: timestamp
  id: String!

  """An object relationship"""
  issuanceToken: Token

  """An array relationship"""
  issuanceTokenDayData(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenDayData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): [IssuanceTokenDayData!]!

  """An aggregate relationship"""
  issuanceTokenDayData_aggregate(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenDayData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): IssuanceTokenDayData_aggregate!

  """An array relationship"""
  issuanceTokenHourData(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenHourData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): [IssuanceTokenHourData!]!

  """An aggregate relationship"""
  issuanceTokenHourData_aggregate(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenHourData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): IssuanceTokenHourData_aggregate!
  issuanceToken_id: String!

  """An array relationship"""
  projectFees(
    """distinct select on columns"""
    distinct_on: [ProjectFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProjectFee_order_by!]

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): [ProjectFee!]!

  """An aggregate relationship"""
  projectFees_aggregate(
    """distinct select on columns"""
    distinct_on: [ProjectFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProjectFee_order_by!]

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): ProjectFee_aggregate!

  """An array relationship"""
  protocolFees(
    """distinct select on columns"""
    distinct_on: [ProtocolFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProtocolFee_order_by!]

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): [ProtocolFee!]!

  """An aggregate relationship"""
  protocolFees_aggregate(
    """distinct select on columns"""
    distinct_on: [ProtocolFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProtocolFee_order_by!]

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): ProtocolFee_aggregate!
  sellFee: numeric!
  sellReserveRatio: numeric!

  """An array relationship"""
  swaps(
    """distinct select on columns"""
    distinct_on: [Swap_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Swap_order_by!]

    """filter the rows returned"""
    where: Swap_bool_exp
  ): [Swap!]!

  """An aggregate relationship"""
  swaps_aggregate(
    """distinct select on columns"""
    distinct_on: [Swap_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Swap_order_by!]

    """filter the rows returned"""
    where: Swap_bool_exp
  ): Swap_aggregate!
  virtualCOL: numeric!
  virtualISS: numeric!

  """An object relationship"""
  workflow: Workflow
  workflow_id: String!
}

"""
aggregated selection of "BondingCurve"
"""
type BondingCurve_aggregate {
  aggregate: BondingCurve_aggregate_fields
  nodes: [BondingCurve!]!
}

"""
aggregate fields of "BondingCurve"
"""
type BondingCurve_aggregate_fields {
  avg: BondingCurve_avg_fields
  count(columns: [BondingCurve_select_column!], distinct: Boolean): Int!
  max: BondingCurve_max_fields
  min: BondingCurve_min_fields
  stddev: BondingCurve_stddev_fields
  stddev_pop: BondingCurve_stddev_pop_fields
  stddev_samp: BondingCurve_stddev_samp_fields
  sum: BondingCurve_sum_fields
  var_pop: BondingCurve_var_pop_fields
  var_samp: BondingCurve_var_samp_fields
  variance: BondingCurve_variance_fields
}

"""aggregate avg on columns"""
type BondingCurve_avg_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""
Boolean expression to filter rows from the table "BondingCurve". All fields are combined with a logical 'AND'.
"""
input BondingCurve_bool_exp {
  _and: [BondingCurve_bool_exp!]
  _not: BondingCurve_bool_exp
  _or: [BondingCurve_bool_exp!]
  address: String_comparison_exp
  bcType: String_comparison_exp
  buyFee: numeric_comparison_exp
  buyReserveRatio: numeric_comparison_exp
  chainId: Int_comparison_exp
  collateralToken: Token_bool_exp
  collateralToken_id: String_comparison_exp
  curveDayData: CurveDayData_bool_exp
  curveDayData_aggregate: CurveDayData_aggregate_bool_exp
  curveHourData: CurveHourData_bool_exp
  curveHourData_aggregate: CurveHourData_aggregate_bool_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  issuanceToken: Token_bool_exp
  issuanceTokenDayData: IssuanceTokenDayData_bool_exp
  issuanceTokenDayData_aggregate: IssuanceTokenDayData_aggregate_bool_exp
  issuanceTokenHourData: IssuanceTokenHourData_bool_exp
  issuanceTokenHourData_aggregate: IssuanceTokenHourData_aggregate_bool_exp
  issuanceToken_id: String_comparison_exp
  projectFees: ProjectFee_bool_exp
  projectFees_aggregate: ProjectFee_aggregate_bool_exp
  protocolFees: ProtocolFee_bool_exp
  protocolFees_aggregate: ProtocolFee_aggregate_bool_exp
  sellFee: numeric_comparison_exp
  sellReserveRatio: numeric_comparison_exp
  swaps: Swap_bool_exp
  swaps_aggregate: Swap_aggregate_bool_exp
  virtualCOL: numeric_comparison_exp
  virtualISS: numeric_comparison_exp
  workflow: Workflow_bool_exp
  workflow_id: String_comparison_exp
}

"""
unique or primary key constraints on table "BondingCurve"
"""
enum BondingCurve_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  BondingCurve_pkey
}

"""
input type for incrementing numeric columns in table "BondingCurve"
"""
input BondingCurve_inc_input {
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  sellFee: numeric
  sellReserveRatio: numeric
  virtualCOL: numeric
  virtualISS: numeric
}

"""
input type for inserting data into table "BondingCurve"
"""
input BondingCurve_insert_input {
  address: String
  bcType: String
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  collateralToken: Token_obj_rel_insert_input
  collateralToken_id: String
  curveDayData: CurveDayData_arr_rel_insert_input
  curveHourData: CurveHourData_arr_rel_insert_input
  db_write_timestamp: timestamp
  id: String
  issuanceToken: Token_obj_rel_insert_input
  issuanceTokenDayData: IssuanceTokenDayData_arr_rel_insert_input
  issuanceTokenHourData: IssuanceTokenHourData_arr_rel_insert_input
  issuanceToken_id: String
  projectFees: ProjectFee_arr_rel_insert_input
  protocolFees: ProtocolFee_arr_rel_insert_input
  sellFee: numeric
  sellReserveRatio: numeric
  swaps: Swap_arr_rel_insert_input
  virtualCOL: numeric
  virtualISS: numeric
  workflow: Workflow_obj_rel_insert_input
  workflow_id: String
}

"""aggregate max on columns"""
type BondingCurve_max_fields {
  address: String
  bcType: String
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  issuanceToken_id: String
  sellFee: numeric
  sellReserveRatio: numeric
  virtualCOL: numeric
  virtualISS: numeric
  workflow_id: String
}

"""aggregate min on columns"""
type BondingCurve_min_fields {
  address: String
  bcType: String
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  issuanceToken_id: String
  sellFee: numeric
  sellReserveRatio: numeric
  virtualCOL: numeric
  virtualISS: numeric
  workflow_id: String
}

"""
response of any mutation on the table "BondingCurve"
"""
type BondingCurve_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [BondingCurve!]!
}

"""
on_conflict condition type for table "BondingCurve"
"""
input BondingCurve_on_conflict {
  constraint: BondingCurve_constraint!
  update_columns: [BondingCurve_update_column!]! = []
  where: BondingCurve_bool_exp
}

"""Ordering options when selecting data from "BondingCurve"."""
input BondingCurve_order_by {
  address: order_by
  bcType: order_by
  buyFee: order_by
  buyReserveRatio: order_by
  chainId: order_by
  collateralToken: Token_order_by
  collateralToken_id: order_by
  curveDayData_aggregate: CurveDayData_aggregate_order_by
  curveHourData_aggregate: CurveHourData_aggregate_order_by
  db_write_timestamp: order_by
  id: order_by
  issuanceToken: Token_order_by
  issuanceTokenDayData_aggregate: IssuanceTokenDayData_aggregate_order_by
  issuanceTokenHourData_aggregate: IssuanceTokenHourData_aggregate_order_by
  issuanceToken_id: order_by
  projectFees_aggregate: ProjectFee_aggregate_order_by
  protocolFees_aggregate: ProtocolFee_aggregate_order_by
  sellFee: order_by
  sellReserveRatio: order_by
  swaps_aggregate: Swap_aggregate_order_by
  virtualCOL: order_by
  virtualISS: order_by
  workflow: Workflow_order_by
  workflow_id: order_by
}

"""primary key columns input for table: BondingCurve"""
input BondingCurve_pk_columns_input {
  id: String!
}

"""
select columns of table "BondingCurve"
"""
enum BondingCurve_select_column {
  """column name"""
  address

  """column name"""
  bcType

  """column name"""
  buyFee

  """column name"""
  buyReserveRatio

  """column name"""
  chainId

  """column name"""
  collateralToken_id

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  issuanceToken_id

  """column name"""
  sellFee

  """column name"""
  sellReserveRatio

  """column name"""
  virtualCOL

  """column name"""
  virtualISS

  """column name"""
  workflow_id
}

"""
input type for updating data in table "BondingCurve"
"""
input BondingCurve_set_input {
  address: String
  bcType: String
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  issuanceToken_id: String
  sellFee: numeric
  sellReserveRatio: numeric
  virtualCOL: numeric
  virtualISS: numeric
  workflow_id: String
}

"""aggregate stddev on columns"""
type BondingCurve_stddev_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""aggregate stddev_pop on columns"""
type BondingCurve_stddev_pop_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""aggregate stddev_samp on columns"""
type BondingCurve_stddev_samp_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""
Streaming cursor of the table "BondingCurve"
"""
input BondingCurve_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: BondingCurve_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input BondingCurve_stream_cursor_value_input {
  address: String
  bcType: String
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  issuanceToken_id: String
  sellFee: numeric
  sellReserveRatio: numeric
  virtualCOL: numeric
  virtualISS: numeric
  workflow_id: String
}

"""aggregate sum on columns"""
type BondingCurve_sum_fields {
  buyFee: numeric
  buyReserveRatio: numeric
  chainId: Int
  sellFee: numeric
  sellReserveRatio: numeric
  virtualCOL: numeric
  virtualISS: numeric
}

"""
update columns of table "BondingCurve"
"""
enum BondingCurve_update_column {
  """column name"""
  address

  """column name"""
  bcType

  """column name"""
  buyFee

  """column name"""
  buyReserveRatio

  """column name"""
  chainId

  """column name"""
  collateralToken_id

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  issuanceToken_id

  """column name"""
  sellFee

  """column name"""
  sellReserveRatio

  """column name"""
  virtualCOL

  """column name"""
  virtualISS

  """column name"""
  workflow_id
}

input BondingCurve_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: BondingCurve_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: BondingCurve_set_input

  """filter the rows which have to be updated"""
  where: BondingCurve_bool_exp!
}

"""aggregate var_pop on columns"""
type BondingCurve_var_pop_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""aggregate var_samp on columns"""
type BondingCurve_var_samp_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""aggregate variance on columns"""
type BondingCurve_variance_fields {
  buyFee: Float
  buyReserveRatio: Float
  chainId: Float
  sellFee: Float
  sellReserveRatio: Float
  virtualCOL: Float
  virtualISS: Float
}

"""
Boolean expression to compare columns of type "Boolean". All fields are combined with logical 'AND'.
"""
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

"""
columns and relationships of "Bounty"
"""
type Bounty {
  """An object relationship"""
  bountyModule: BountyModule
  bountyModule_id: String!

  """An array relationship"""
  claims(
    """distinct select on columns"""
    distinct_on: [BountyClaim_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyClaim_order_by!]

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): [BountyClaim!]!

  """An aggregate relationship"""
  claims_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyClaim_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyClaim_order_by!]

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): BountyClaim_aggregate!
  db_write_timestamp: timestamp
  details: String!
  id: String!
  locked: Boolean
  maximumPayoutAmount: numeric!
  minimumPayoutAmount: numeric!
}

"""
columns and relationships of "BountyClaim"
"""
type BountyClaim {
  """An object relationship"""
  bounty: Bounty
  bounty_id: String!
  claimed: Boolean

  """An array relationship"""
  contributors(
    """distinct select on columns"""
    distinct_on: [BountyContributor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyContributor_order_by!]

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): [BountyContributor!]!

  """An aggregate relationship"""
  contributors_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyContributor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyContributor_order_by!]

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): BountyContributor_aggregate!
  db_write_timestamp: timestamp
  details: String!
  id: String!
}

"""
aggregated selection of "BountyClaim"
"""
type BountyClaim_aggregate {
  aggregate: BountyClaim_aggregate_fields
  nodes: [BountyClaim!]!
}

input BountyClaim_aggregate_bool_exp {
  bool_and: BountyClaim_aggregate_bool_exp_bool_and
  bool_or: BountyClaim_aggregate_bool_exp_bool_or
  count: BountyClaim_aggregate_bool_exp_count
}

input BountyClaim_aggregate_bool_exp_bool_and {
  arguments: BountyClaim_select_column_BountyClaim_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: BountyClaim_bool_exp
  predicate: Boolean_comparison_exp!
}

input BountyClaim_aggregate_bool_exp_bool_or {
  arguments: BountyClaim_select_column_BountyClaim_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: BountyClaim_bool_exp
  predicate: Boolean_comparison_exp!
}

input BountyClaim_aggregate_bool_exp_count {
  arguments: [BountyClaim_select_column!]
  distinct: Boolean
  filter: BountyClaim_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "BountyClaim"
"""
type BountyClaim_aggregate_fields {
  count(columns: [BountyClaim_select_column!], distinct: Boolean): Int!
  max: BountyClaim_max_fields
  min: BountyClaim_min_fields
}

"""
order by aggregate values of table "BountyClaim"
"""
input BountyClaim_aggregate_order_by {
  count: order_by
  max: BountyClaim_max_order_by
  min: BountyClaim_min_order_by
}

"""
input type for inserting array relation for remote table "BountyClaim"
"""
input BountyClaim_arr_rel_insert_input {
  data: [BountyClaim_insert_input!]!

  """upsert condition"""
  on_conflict: BountyClaim_on_conflict
}

"""
Boolean expression to filter rows from the table "BountyClaim". All fields are combined with a logical 'AND'.
"""
input BountyClaim_bool_exp {
  _and: [BountyClaim_bool_exp!]
  _not: BountyClaim_bool_exp
  _or: [BountyClaim_bool_exp!]
  bounty: Bounty_bool_exp
  bounty_id: String_comparison_exp
  claimed: Boolean_comparison_exp
  contributors: BountyContributor_bool_exp
  contributors_aggregate: BountyContributor_aggregate_bool_exp
  db_write_timestamp: timestamp_comparison_exp
  details: String_comparison_exp
  id: String_comparison_exp
}

"""
unique or primary key constraints on table "BountyClaim"
"""
enum BountyClaim_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  BountyClaim_pkey
}

"""
input type for inserting data into table "BountyClaim"
"""
input BountyClaim_insert_input {
  bounty: Bounty_obj_rel_insert_input
  bounty_id: String
  claimed: Boolean
  contributors: BountyContributor_arr_rel_insert_input
  db_write_timestamp: timestamp
  details: String
  id: String
}

"""aggregate max on columns"""
type BountyClaim_max_fields {
  bounty_id: String
  db_write_timestamp: timestamp
  details: String
  id: String
}

"""
order by max() on columns of table "BountyClaim"
"""
input BountyClaim_max_order_by {
  bounty_id: order_by
  db_write_timestamp: order_by
  details: order_by
  id: order_by
}

"""aggregate min on columns"""
type BountyClaim_min_fields {
  bounty_id: String
  db_write_timestamp: timestamp
  details: String
  id: String
}

"""
order by min() on columns of table "BountyClaim"
"""
input BountyClaim_min_order_by {
  bounty_id: order_by
  db_write_timestamp: order_by
  details: order_by
  id: order_by
}

"""
response of any mutation on the table "BountyClaim"
"""
type BountyClaim_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [BountyClaim!]!
}

"""
input type for inserting object relation for remote table "BountyClaim"
"""
input BountyClaim_obj_rel_insert_input {
  data: BountyClaim_insert_input!

  """upsert condition"""
  on_conflict: BountyClaim_on_conflict
}

"""
on_conflict condition type for table "BountyClaim"
"""
input BountyClaim_on_conflict {
  constraint: BountyClaim_constraint!
  update_columns: [BountyClaim_update_column!]! = []
  where: BountyClaim_bool_exp
}

"""Ordering options when selecting data from "BountyClaim"."""
input BountyClaim_order_by {
  bounty: Bounty_order_by
  bounty_id: order_by
  claimed: order_by
  contributors_aggregate: BountyContributor_aggregate_order_by
  db_write_timestamp: order_by
  details: order_by
  id: order_by
}

"""primary key columns input for table: BountyClaim"""
input BountyClaim_pk_columns_input {
  id: String!
}

"""
select columns of table "BountyClaim"
"""
enum BountyClaim_select_column {
  """column name"""
  bounty_id

  """column name"""
  claimed

  """column name"""
  db_write_timestamp

  """column name"""
  details

  """column name"""
  id
}

"""
select "BountyClaim_aggregate_bool_exp_bool_and_arguments_columns" columns of table "BountyClaim"
"""
enum BountyClaim_select_column_BountyClaim_aggregate_bool_exp_bool_and_arguments_columns {
  """column name"""
  claimed
}

"""
select "BountyClaim_aggregate_bool_exp_bool_or_arguments_columns" columns of table "BountyClaim"
"""
enum BountyClaim_select_column_BountyClaim_aggregate_bool_exp_bool_or_arguments_columns {
  """column name"""
  claimed
}

"""
input type for updating data in table "BountyClaim"
"""
input BountyClaim_set_input {
  bounty_id: String
  claimed: Boolean
  db_write_timestamp: timestamp
  details: String
  id: String
}

"""
Streaming cursor of the table "BountyClaim"
"""
input BountyClaim_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: BountyClaim_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input BountyClaim_stream_cursor_value_input {
  bounty_id: String
  claimed: Boolean
  db_write_timestamp: timestamp
  details: String
  id: String
}

"""
update columns of table "BountyClaim"
"""
enum BountyClaim_update_column {
  """column name"""
  bounty_id

  """column name"""
  claimed

  """column name"""
  db_write_timestamp

  """column name"""
  details

  """column name"""
  id
}

input BountyClaim_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: BountyClaim_set_input

  """filter the rows which have to be updated"""
  where: BountyClaim_bool_exp!
}

"""
columns and relationships of "BountyContributor"
"""
type BountyContributor {
  address: String!

  """An object relationship"""
  bountyClaim: BountyClaim
  bountyClaim_id: String!
  claimAmount: numeric!
  db_write_timestamp: timestamp
  id: String!
}

"""
aggregated selection of "BountyContributor"
"""
type BountyContributor_aggregate {
  aggregate: BountyContributor_aggregate_fields
  nodes: [BountyContributor!]!
}

input BountyContributor_aggregate_bool_exp {
  count: BountyContributor_aggregate_bool_exp_count
}

input BountyContributor_aggregate_bool_exp_count {
  arguments: [BountyContributor_select_column!]
  distinct: Boolean
  filter: BountyContributor_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "BountyContributor"
"""
type BountyContributor_aggregate_fields {
  avg: BountyContributor_avg_fields
  count(columns: [BountyContributor_select_column!], distinct: Boolean): Int!
  max: BountyContributor_max_fields
  min: BountyContributor_min_fields
  stddev: BountyContributor_stddev_fields
  stddev_pop: BountyContributor_stddev_pop_fields
  stddev_samp: BountyContributor_stddev_samp_fields
  sum: BountyContributor_sum_fields
  var_pop: BountyContributor_var_pop_fields
  var_samp: BountyContributor_var_samp_fields
  variance: BountyContributor_variance_fields
}

"""
order by aggregate values of table "BountyContributor"
"""
input BountyContributor_aggregate_order_by {
  avg: BountyContributor_avg_order_by
  count: order_by
  max: BountyContributor_max_order_by
  min: BountyContributor_min_order_by
  stddev: BountyContributor_stddev_order_by
  stddev_pop: BountyContributor_stddev_pop_order_by
  stddev_samp: BountyContributor_stddev_samp_order_by
  sum: BountyContributor_sum_order_by
  var_pop: BountyContributor_var_pop_order_by
  var_samp: BountyContributor_var_samp_order_by
  variance: BountyContributor_variance_order_by
}

"""
input type for inserting array relation for remote table "BountyContributor"
"""
input BountyContributor_arr_rel_insert_input {
  data: [BountyContributor_insert_input!]!

  """upsert condition"""
  on_conflict: BountyContributor_on_conflict
}

"""aggregate avg on columns"""
type BountyContributor_avg_fields {
  claimAmount: Float
}

"""
order by avg() on columns of table "BountyContributor"
"""
input BountyContributor_avg_order_by {
  claimAmount: order_by
}

"""
Boolean expression to filter rows from the table "BountyContributor". All fields are combined with a logical 'AND'.
"""
input BountyContributor_bool_exp {
  _and: [BountyContributor_bool_exp!]
  _not: BountyContributor_bool_exp
  _or: [BountyContributor_bool_exp!]
  address: String_comparison_exp
  bountyClaim: BountyClaim_bool_exp
  bountyClaim_id: String_comparison_exp
  claimAmount: numeric_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
}

"""
unique or primary key constraints on table "BountyContributor"
"""
enum BountyContributor_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  BountyContributor_pkey
}

"""
input type for incrementing numeric columns in table "BountyContributor"
"""
input BountyContributor_inc_input {
  claimAmount: numeric
}

"""
input type for inserting data into table "BountyContributor"
"""
input BountyContributor_insert_input {
  address: String
  bountyClaim: BountyClaim_obj_rel_insert_input
  bountyClaim_id: String
  claimAmount: numeric
  db_write_timestamp: timestamp
  id: String
}

"""aggregate max on columns"""
type BountyContributor_max_fields {
  address: String
  bountyClaim_id: String
  claimAmount: numeric
  db_write_timestamp: timestamp
  id: String
}

"""
order by max() on columns of table "BountyContributor"
"""
input BountyContributor_max_order_by {
  address: order_by
  bountyClaim_id: order_by
  claimAmount: order_by
  db_write_timestamp: order_by
  id: order_by
}

"""aggregate min on columns"""
type BountyContributor_min_fields {
  address: String
  bountyClaim_id: String
  claimAmount: numeric
  db_write_timestamp: timestamp
  id: String
}

"""
order by min() on columns of table "BountyContributor"
"""
input BountyContributor_min_order_by {
  address: order_by
  bountyClaim_id: order_by
  claimAmount: order_by
  db_write_timestamp: order_by
  id: order_by
}

"""
response of any mutation on the table "BountyContributor"
"""
type BountyContributor_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [BountyContributor!]!
}

"""
on_conflict condition type for table "BountyContributor"
"""
input BountyContributor_on_conflict {
  constraint: BountyContributor_constraint!
  update_columns: [BountyContributor_update_column!]! = []
  where: BountyContributor_bool_exp
}

"""Ordering options when selecting data from "BountyContributor"."""
input BountyContributor_order_by {
  address: order_by
  bountyClaim: BountyClaim_order_by
  bountyClaim_id: order_by
  claimAmount: order_by
  db_write_timestamp: order_by
  id: order_by
}

"""primary key columns input for table: BountyContributor"""
input BountyContributor_pk_columns_input {
  id: String!
}

"""
select columns of table "BountyContributor"
"""
enum BountyContributor_select_column {
  """column name"""
  address

  """column name"""
  bountyClaim_id

  """column name"""
  claimAmount

  """column name"""
  db_write_timestamp

  """column name"""
  id
}

"""
input type for updating data in table "BountyContributor"
"""
input BountyContributor_set_input {
  address: String
  bountyClaim_id: String
  claimAmount: numeric
  db_write_timestamp: timestamp
  id: String
}

"""aggregate stddev on columns"""
type BountyContributor_stddev_fields {
  claimAmount: Float
}

"""
order by stddev() on columns of table "BountyContributor"
"""
input BountyContributor_stddev_order_by {
  claimAmount: order_by
}

"""aggregate stddev_pop on columns"""
type BountyContributor_stddev_pop_fields {
  claimAmount: Float
}

"""
order by stddev_pop() on columns of table "BountyContributor"
"""
input BountyContributor_stddev_pop_order_by {
  claimAmount: order_by
}

"""aggregate stddev_samp on columns"""
type BountyContributor_stddev_samp_fields {
  claimAmount: Float
}

"""
order by stddev_samp() on columns of table "BountyContributor"
"""
input BountyContributor_stddev_samp_order_by {
  claimAmount: order_by
}

"""
Streaming cursor of the table "BountyContributor"
"""
input BountyContributor_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: BountyContributor_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input BountyContributor_stream_cursor_value_input {
  address: String
  bountyClaim_id: String
  claimAmount: numeric
  db_write_timestamp: timestamp
  id: String
}

"""aggregate sum on columns"""
type BountyContributor_sum_fields {
  claimAmount: numeric
}

"""
order by sum() on columns of table "BountyContributor"
"""
input BountyContributor_sum_order_by {
  claimAmount: order_by
}

"""
update columns of table "BountyContributor"
"""
enum BountyContributor_update_column {
  """column name"""
  address

  """column name"""
  bountyClaim_id

  """column name"""
  claimAmount

  """column name"""
  db_write_timestamp

  """column name"""
  id
}

input BountyContributor_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: BountyContributor_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: BountyContributor_set_input

  """filter the rows which have to be updated"""
  where: BountyContributor_bool_exp!
}

"""aggregate var_pop on columns"""
type BountyContributor_var_pop_fields {
  claimAmount: Float
}

"""
order by var_pop() on columns of table "BountyContributor"
"""
input BountyContributor_var_pop_order_by {
  claimAmount: order_by
}

"""aggregate var_samp on columns"""
type BountyContributor_var_samp_fields {
  claimAmount: Float
}

"""
order by var_samp() on columns of table "BountyContributor"
"""
input BountyContributor_var_samp_order_by {
  claimAmount: order_by
}

"""aggregate variance on columns"""
type BountyContributor_variance_fields {
  claimAmount: Float
}

"""
order by variance() on columns of table "BountyContributor"
"""
input BountyContributor_variance_order_by {
  claimAmount: order_by
}

"""
columns and relationships of "BountyModule"
"""
type BountyModule {
  """An array relationship"""
  bounties(
    """distinct select on columns"""
    distinct_on: [Bounty_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Bounty_order_by!]

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): [Bounty!]!

  """An aggregate relationship"""
  bounties_aggregate(
    """distinct select on columns"""
    distinct_on: [Bounty_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Bounty_order_by!]

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): Bounty_aggregate!
  chainId: Int!
  db_write_timestamp: timestamp
  id: String!

  """An object relationship"""
  workflow: Workflow
  workflow_id: String!
}

"""
aggregated selection of "BountyModule"
"""
type BountyModule_aggregate {
  aggregate: BountyModule_aggregate_fields
  nodes: [BountyModule!]!
}

"""
aggregate fields of "BountyModule"
"""
type BountyModule_aggregate_fields {
  avg: BountyModule_avg_fields
  count(columns: [BountyModule_select_column!], distinct: Boolean): Int!
  max: BountyModule_max_fields
  min: BountyModule_min_fields
  stddev: BountyModule_stddev_fields
  stddev_pop: BountyModule_stddev_pop_fields
  stddev_samp: BountyModule_stddev_samp_fields
  sum: BountyModule_sum_fields
  var_pop: BountyModule_var_pop_fields
  var_samp: BountyModule_var_samp_fields
  variance: BountyModule_variance_fields
}

"""aggregate avg on columns"""
type BountyModule_avg_fields {
  chainId: Float
}

"""
Boolean expression to filter rows from the table "BountyModule". All fields are combined with a logical 'AND'.
"""
input BountyModule_bool_exp {
  _and: [BountyModule_bool_exp!]
  _not: BountyModule_bool_exp
  _or: [BountyModule_bool_exp!]
  bounties: Bounty_bool_exp
  bounties_aggregate: Bounty_aggregate_bool_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  workflow: Workflow_bool_exp
  workflow_id: String_comparison_exp
}

"""
unique or primary key constraints on table "BountyModule"
"""
enum BountyModule_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  BountyModule_pkey
}

"""
input type for incrementing numeric columns in table "BountyModule"
"""
input BountyModule_inc_input {
  chainId: Int
}

"""
input type for inserting data into table "BountyModule"
"""
input BountyModule_insert_input {
  bounties: Bounty_arr_rel_insert_input
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow: Workflow_obj_rel_insert_input
  workflow_id: String
}

"""aggregate max on columns"""
type BountyModule_max_fields {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""aggregate min on columns"""
type BountyModule_min_fields {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""
response of any mutation on the table "BountyModule"
"""
type BountyModule_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [BountyModule!]!
}

"""
input type for inserting object relation for remote table "BountyModule"
"""
input BountyModule_obj_rel_insert_input {
  data: BountyModule_insert_input!

  """upsert condition"""
  on_conflict: BountyModule_on_conflict
}

"""
on_conflict condition type for table "BountyModule"
"""
input BountyModule_on_conflict {
  constraint: BountyModule_constraint!
  update_columns: [BountyModule_update_column!]! = []
  where: BountyModule_bool_exp
}

"""Ordering options when selecting data from "BountyModule"."""
input BountyModule_order_by {
  bounties_aggregate: Bounty_aggregate_order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  workflow: Workflow_order_by
  workflow_id: order_by
}

"""primary key columns input for table: BountyModule"""
input BountyModule_pk_columns_input {
  id: String!
}

"""
select columns of table "BountyModule"
"""
enum BountyModule_select_column {
  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  workflow_id
}

"""
input type for updating data in table "BountyModule"
"""
input BountyModule_set_input {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""aggregate stddev on columns"""
type BountyModule_stddev_fields {
  chainId: Float
}

"""aggregate stddev_pop on columns"""
type BountyModule_stddev_pop_fields {
  chainId: Float
}

"""aggregate stddev_samp on columns"""
type BountyModule_stddev_samp_fields {
  chainId: Float
}

"""
Streaming cursor of the table "BountyModule"
"""
input BountyModule_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: BountyModule_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input BountyModule_stream_cursor_value_input {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""aggregate sum on columns"""
type BountyModule_sum_fields {
  chainId: Int
}

"""
update columns of table "BountyModule"
"""
enum BountyModule_update_column {
  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  workflow_id
}

input BountyModule_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: BountyModule_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: BountyModule_set_input

  """filter the rows which have to be updated"""
  where: BountyModule_bool_exp!
}

"""aggregate var_pop on columns"""
type BountyModule_var_pop_fields {
  chainId: Float
}

"""aggregate var_samp on columns"""
type BountyModule_var_samp_fields {
  chainId: Float
}

"""aggregate variance on columns"""
type BountyModule_variance_fields {
  chainId: Float
}

"""
aggregated selection of "Bounty"
"""
type Bounty_aggregate {
  aggregate: Bounty_aggregate_fields
  nodes: [Bounty!]!
}

input Bounty_aggregate_bool_exp {
  bool_and: Bounty_aggregate_bool_exp_bool_and
  bool_or: Bounty_aggregate_bool_exp_bool_or
  count: Bounty_aggregate_bool_exp_count
}

input Bounty_aggregate_bool_exp_bool_and {
  arguments: Bounty_select_column_Bounty_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: Bounty_bool_exp
  predicate: Boolean_comparison_exp!
}

input Bounty_aggregate_bool_exp_bool_or {
  arguments: Bounty_select_column_Bounty_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: Bounty_bool_exp
  predicate: Boolean_comparison_exp!
}

input Bounty_aggregate_bool_exp_count {
  arguments: [Bounty_select_column!]
  distinct: Boolean
  filter: Bounty_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "Bounty"
"""
type Bounty_aggregate_fields {
  avg: Bounty_avg_fields
  count(columns: [Bounty_select_column!], distinct: Boolean): Int!
  max: Bounty_max_fields
  min: Bounty_min_fields
  stddev: Bounty_stddev_fields
  stddev_pop: Bounty_stddev_pop_fields
  stddev_samp: Bounty_stddev_samp_fields
  sum: Bounty_sum_fields
  var_pop: Bounty_var_pop_fields
  var_samp: Bounty_var_samp_fields
  variance: Bounty_variance_fields
}

"""
order by aggregate values of table "Bounty"
"""
input Bounty_aggregate_order_by {
  avg: Bounty_avg_order_by
  count: order_by
  max: Bounty_max_order_by
  min: Bounty_min_order_by
  stddev: Bounty_stddev_order_by
  stddev_pop: Bounty_stddev_pop_order_by
  stddev_samp: Bounty_stddev_samp_order_by
  sum: Bounty_sum_order_by
  var_pop: Bounty_var_pop_order_by
  var_samp: Bounty_var_samp_order_by
  variance: Bounty_variance_order_by
}

"""
input type for inserting array relation for remote table "Bounty"
"""
input Bounty_arr_rel_insert_input {
  data: [Bounty_insert_input!]!

  """upsert condition"""
  on_conflict: Bounty_on_conflict
}

"""aggregate avg on columns"""
type Bounty_avg_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by avg() on columns of table "Bounty"
"""
input Bounty_avg_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""
Boolean expression to filter rows from the table "Bounty". All fields are combined with a logical 'AND'.
"""
input Bounty_bool_exp {
  _and: [Bounty_bool_exp!]
  _not: Bounty_bool_exp
  _or: [Bounty_bool_exp!]
  bountyModule: BountyModule_bool_exp
  bountyModule_id: String_comparison_exp
  claims: BountyClaim_bool_exp
  claims_aggregate: BountyClaim_aggregate_bool_exp
  db_write_timestamp: timestamp_comparison_exp
  details: String_comparison_exp
  id: String_comparison_exp
  locked: Boolean_comparison_exp
  maximumPayoutAmount: numeric_comparison_exp
  minimumPayoutAmount: numeric_comparison_exp
}

"""
unique or primary key constraints on table "Bounty"
"""
enum Bounty_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  Bounty_pkey
}

"""
input type for incrementing numeric columns in table "Bounty"
"""
input Bounty_inc_input {
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""
input type for inserting data into table "Bounty"
"""
input Bounty_insert_input {
  bountyModule: BountyModule_obj_rel_insert_input
  bountyModule_id: String
  claims: BountyClaim_arr_rel_insert_input
  db_write_timestamp: timestamp
  details: String
  id: String
  locked: Boolean
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""aggregate max on columns"""
type Bounty_max_fields {
  bountyModule_id: String
  db_write_timestamp: timestamp
  details: String
  id: String
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""
order by max() on columns of table "Bounty"
"""
input Bounty_max_order_by {
  bountyModule_id: order_by
  db_write_timestamp: order_by
  details: order_by
  id: order_by
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""aggregate min on columns"""
type Bounty_min_fields {
  bountyModule_id: String
  db_write_timestamp: timestamp
  details: String
  id: String
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""
order by min() on columns of table "Bounty"
"""
input Bounty_min_order_by {
  bountyModule_id: order_by
  db_write_timestamp: order_by
  details: order_by
  id: order_by
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""
response of any mutation on the table "Bounty"
"""
type Bounty_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [Bounty!]!
}

"""
input type for inserting object relation for remote table "Bounty"
"""
input Bounty_obj_rel_insert_input {
  data: Bounty_insert_input!

  """upsert condition"""
  on_conflict: Bounty_on_conflict
}

"""
on_conflict condition type for table "Bounty"
"""
input Bounty_on_conflict {
  constraint: Bounty_constraint!
  update_columns: [Bounty_update_column!]! = []
  where: Bounty_bool_exp
}

"""Ordering options when selecting data from "Bounty"."""
input Bounty_order_by {
  bountyModule: BountyModule_order_by
  bountyModule_id: order_by
  claims_aggregate: BountyClaim_aggregate_order_by
  db_write_timestamp: order_by
  details: order_by
  id: order_by
  locked: order_by
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""primary key columns input for table: Bounty"""
input Bounty_pk_columns_input {
  id: String!
}

"""
select columns of table "Bounty"
"""
enum Bounty_select_column {
  """column name"""
  bountyModule_id

  """column name"""
  db_write_timestamp

  """column name"""
  details

  """column name"""
  id

  """column name"""
  locked

  """column name"""
  maximumPayoutAmount

  """column name"""
  minimumPayoutAmount
}

"""
select "Bounty_aggregate_bool_exp_bool_and_arguments_columns" columns of table "Bounty"
"""
enum Bounty_select_column_Bounty_aggregate_bool_exp_bool_and_arguments_columns {
  """column name"""
  locked
}

"""
select "Bounty_aggregate_bool_exp_bool_or_arguments_columns" columns of table "Bounty"
"""
enum Bounty_select_column_Bounty_aggregate_bool_exp_bool_or_arguments_columns {
  """column name"""
  locked
}

"""
input type for updating data in table "Bounty"
"""
input Bounty_set_input {
  bountyModule_id: String
  db_write_timestamp: timestamp
  details: String
  id: String
  locked: Boolean
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""aggregate stddev on columns"""
type Bounty_stddev_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by stddev() on columns of table "Bounty"
"""
input Bounty_stddev_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""aggregate stddev_pop on columns"""
type Bounty_stddev_pop_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by stddev_pop() on columns of table "Bounty"
"""
input Bounty_stddev_pop_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""aggregate stddev_samp on columns"""
type Bounty_stddev_samp_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by stddev_samp() on columns of table "Bounty"
"""
input Bounty_stddev_samp_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""
Streaming cursor of the table "Bounty"
"""
input Bounty_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: Bounty_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input Bounty_stream_cursor_value_input {
  bountyModule_id: String
  db_write_timestamp: timestamp
  details: String
  id: String
  locked: Boolean
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""aggregate sum on columns"""
type Bounty_sum_fields {
  maximumPayoutAmount: numeric
  minimumPayoutAmount: numeric
}

"""
order by sum() on columns of table "Bounty"
"""
input Bounty_sum_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""
update columns of table "Bounty"
"""
enum Bounty_update_column {
  """column name"""
  bountyModule_id

  """column name"""
  db_write_timestamp

  """column name"""
  details

  """column name"""
  id

  """column name"""
  locked

  """column name"""
  maximumPayoutAmount

  """column name"""
  minimumPayoutAmount
}

input Bounty_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: Bounty_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: Bounty_set_input

  """filter the rows which have to be updated"""
  where: Bounty_bool_exp!
}

"""aggregate var_pop on columns"""
type Bounty_var_pop_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by var_pop() on columns of table "Bounty"
"""
input Bounty_var_pop_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""aggregate var_samp on columns"""
type Bounty_var_samp_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by var_samp() on columns of table "Bounty"
"""
input Bounty_var_samp_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""aggregate variance on columns"""
type Bounty_variance_fields {
  maximumPayoutAmount: Float
  minimumPayoutAmount: Float
}

"""
order by variance() on columns of table "Bounty"
"""
input Bounty_variance_order_by {
  maximumPayoutAmount: order_by
  minimumPayoutAmount: order_by
}

"""
columns and relationships of "CurveDayData"
"""
type CurveDayData {
  chainId: Int!
  closeCOL: numeric!
  closeUSD: numeric!

  """An object relationship"""
  collateralToken: Token
  collateralToken_id: String!
  date: Int!
  db_write_timestamp: timestamp
  highCOL: numeric!
  highUSD: numeric!
  id: String!

  """An object relationship"""
  issuanceToken: Token
  issuanceToken_id: String!
  lowCOL: numeric!
  lowUSD: numeric!
  module_id: String!
  openCOL: numeric!
  openUSD: numeric!
  priceCOL: numeric!
  priceUSD: numeric!
  projectFeeCOL: numeric!
  projectFeeUSD: numeric!
  protocolFeeCOL: numeric!
  protocolFeeISS: numeric!
  protocolFeeUSD: numeric!
  volumeCOL: numeric!
  volumeISS: numeric!
  volumeUSD: numeric!
}

"""
aggregated selection of "CurveDayData"
"""
type CurveDayData_aggregate {
  aggregate: CurveDayData_aggregate_fields
  nodes: [CurveDayData!]!
}

input CurveDayData_aggregate_bool_exp {
  count: CurveDayData_aggregate_bool_exp_count
}

input CurveDayData_aggregate_bool_exp_count {
  arguments: [CurveDayData_select_column!]
  distinct: Boolean
  filter: CurveDayData_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "CurveDayData"
"""
type CurveDayData_aggregate_fields {
  avg: CurveDayData_avg_fields
  count(columns: [CurveDayData_select_column!], distinct: Boolean): Int!
  max: CurveDayData_max_fields
  min: CurveDayData_min_fields
  stddev: CurveDayData_stddev_fields
  stddev_pop: CurveDayData_stddev_pop_fields
  stddev_samp: CurveDayData_stddev_samp_fields
  sum: CurveDayData_sum_fields
  var_pop: CurveDayData_var_pop_fields
  var_samp: CurveDayData_var_samp_fields
  variance: CurveDayData_variance_fields
}

"""
order by aggregate values of table "CurveDayData"
"""
input CurveDayData_aggregate_order_by {
  avg: CurveDayData_avg_order_by
  count: order_by
  max: CurveDayData_max_order_by
  min: CurveDayData_min_order_by
  stddev: CurveDayData_stddev_order_by
  stddev_pop: CurveDayData_stddev_pop_order_by
  stddev_samp: CurveDayData_stddev_samp_order_by
  sum: CurveDayData_sum_order_by
  var_pop: CurveDayData_var_pop_order_by
  var_samp: CurveDayData_var_samp_order_by
  variance: CurveDayData_variance_order_by
}

"""
input type for inserting array relation for remote table "CurveDayData"
"""
input CurveDayData_arr_rel_insert_input {
  data: [CurveDayData_insert_input!]!

  """upsert condition"""
  on_conflict: CurveDayData_on_conflict
}

"""aggregate avg on columns"""
type CurveDayData_avg_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by avg() on columns of table "CurveDayData"
"""
input CurveDayData_avg_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Boolean expression to filter rows from the table "CurveDayData". All fields are combined with a logical 'AND'.
"""
input CurveDayData_bool_exp {
  _and: [CurveDayData_bool_exp!]
  _not: CurveDayData_bool_exp
  _or: [CurveDayData_bool_exp!]
  chainId: Int_comparison_exp
  closeCOL: numeric_comparison_exp
  closeUSD: numeric_comparison_exp
  collateralToken: Token_bool_exp
  collateralToken_id: String_comparison_exp
  date: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  highCOL: numeric_comparison_exp
  highUSD: numeric_comparison_exp
  id: String_comparison_exp
  issuanceToken: Token_bool_exp
  issuanceToken_id: String_comparison_exp
  lowCOL: numeric_comparison_exp
  lowUSD: numeric_comparison_exp
  module_id: String_comparison_exp
  openCOL: numeric_comparison_exp
  openUSD: numeric_comparison_exp
  priceCOL: numeric_comparison_exp
  priceUSD: numeric_comparison_exp
  projectFeeCOL: numeric_comparison_exp
  projectFeeUSD: numeric_comparison_exp
  protocolFeeCOL: numeric_comparison_exp
  protocolFeeISS: numeric_comparison_exp
  protocolFeeUSD: numeric_comparison_exp
  volumeCOL: numeric_comparison_exp
  volumeISS: numeric_comparison_exp
  volumeUSD: numeric_comparison_exp
}

"""
unique or primary key constraints on table "CurveDayData"
"""
enum CurveDayData_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  CurveDayData_pkey
}

"""
input type for incrementing numeric columns in table "CurveDayData"
"""
input CurveDayData_inc_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  date: Int
  highCOL: numeric
  highUSD: numeric
  lowCOL: numeric
  lowUSD: numeric
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
input type for inserting data into table "CurveDayData"
"""
input CurveDayData_insert_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken: Token_obj_rel_insert_input
  collateralToken_id: String
  date: Int
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken: Token_obj_rel_insert_input
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate max on columns"""
type CurveDayData_max_fields {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  date: Int
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by max() on columns of table "CurveDayData"
"""
input CurveDayData_max_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  collateralToken_id: order_by
  date: order_by
  db_write_timestamp: order_by
  highCOL: order_by
  highUSD: order_by
  id: order_by
  issuanceToken_id: order_by
  lowCOL: order_by
  lowUSD: order_by
  module_id: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate min on columns"""
type CurveDayData_min_fields {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  date: Int
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by min() on columns of table "CurveDayData"
"""
input CurveDayData_min_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  collateralToken_id: order_by
  date: order_by
  db_write_timestamp: order_by
  highCOL: order_by
  highUSD: order_by
  id: order_by
  issuanceToken_id: order_by
  lowCOL: order_by
  lowUSD: order_by
  module_id: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
response of any mutation on the table "CurveDayData"
"""
type CurveDayData_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [CurveDayData!]!
}

"""
on_conflict condition type for table "CurveDayData"
"""
input CurveDayData_on_conflict {
  constraint: CurveDayData_constraint!
  update_columns: [CurveDayData_update_column!]! = []
  where: CurveDayData_bool_exp
}

"""Ordering options when selecting data from "CurveDayData"."""
input CurveDayData_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  collateralToken: Token_order_by
  collateralToken_id: order_by
  date: order_by
  db_write_timestamp: order_by
  highCOL: order_by
  highUSD: order_by
  id: order_by
  issuanceToken: Token_order_by
  issuanceToken_id: order_by
  lowCOL: order_by
  lowUSD: order_by
  module_id: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""primary key columns input for table: CurveDayData"""
input CurveDayData_pk_columns_input {
  id: String!
}

"""
select columns of table "CurveDayData"
"""
enum CurveDayData_select_column {
  """column name"""
  chainId

  """column name"""
  closeCOL

  """column name"""
  closeUSD

  """column name"""
  collateralToken_id

  """column name"""
  date

  """column name"""
  db_write_timestamp

  """column name"""
  highCOL

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  issuanceToken_id

  """column name"""
  lowCOL

  """column name"""
  lowUSD

  """column name"""
  module_id

  """column name"""
  openCOL

  """column name"""
  openUSD

  """column name"""
  priceCOL

  """column name"""
  priceUSD

  """column name"""
  projectFeeCOL

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeCOL

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  volumeCOL

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

"""
input type for updating data in table "CurveDayData"
"""
input CurveDayData_set_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  date: Int
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate stddev on columns"""
type CurveDayData_stddev_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev() on columns of table "CurveDayData"
"""
input CurveDayData_stddev_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_pop on columns"""
type CurveDayData_stddev_pop_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_pop() on columns of table "CurveDayData"
"""
input CurveDayData_stddev_pop_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_samp on columns"""
type CurveDayData_stddev_samp_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_samp() on columns of table "CurveDayData"
"""
input CurveDayData_stddev_samp_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Streaming cursor of the table "CurveDayData"
"""
input CurveDayData_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: CurveDayData_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input CurveDayData_stream_cursor_value_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  date: Int
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate sum on columns"""
type CurveDayData_sum_fields {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  date: Int
  highCOL: numeric
  highUSD: numeric
  lowCOL: numeric
  lowUSD: numeric
  openCOL: numeric
  openUSD: numeric
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by sum() on columns of table "CurveDayData"
"""
input CurveDayData_sum_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
update columns of table "CurveDayData"
"""
enum CurveDayData_update_column {
  """column name"""
  chainId

  """column name"""
  closeCOL

  """column name"""
  closeUSD

  """column name"""
  collateralToken_id

  """column name"""
  date

  """column name"""
  db_write_timestamp

  """column name"""
  highCOL

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  issuanceToken_id

  """column name"""
  lowCOL

  """column name"""
  lowUSD

  """column name"""
  module_id

  """column name"""
  openCOL

  """column name"""
  openUSD

  """column name"""
  priceCOL

  """column name"""
  priceUSD

  """column name"""
  projectFeeCOL

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeCOL

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  volumeCOL

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

input CurveDayData_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: CurveDayData_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: CurveDayData_set_input

  """filter the rows which have to be updated"""
  where: CurveDayData_bool_exp!
}

"""aggregate var_pop on columns"""
type CurveDayData_var_pop_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_pop() on columns of table "CurveDayData"
"""
input CurveDayData_var_pop_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate var_samp on columns"""
type CurveDayData_var_samp_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_samp() on columns of table "CurveDayData"
"""
input CurveDayData_var_samp_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate variance on columns"""
type CurveDayData_variance_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  date: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by variance() on columns of table "CurveDayData"
"""
input CurveDayData_variance_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  date: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
columns and relationships of "CurveHourData"
"""
type CurveHourData {
  chainId: Int!
  closeCOL: numeric!
  closeUSD: numeric!

  """An object relationship"""
  collateralToken: Token
  collateralToken_id: String!
  db_write_timestamp: timestamp
  highCOL: numeric!
  highUSD: numeric!
  id: String!

  """An object relationship"""
  issuanceToken: Token
  issuanceToken_id: String!
  lowCOL: numeric!
  lowUSD: numeric!
  module_id: String!
  openCOL: numeric!
  openUSD: numeric!
  periodStartUnix: Int!
  priceCOL: numeric!
  priceUSD: numeric!
  projectFeeCOL: numeric!
  projectFeeUSD: numeric!
  protocolFeeCOL: numeric!
  protocolFeeISS: numeric!
  protocolFeeUSD: numeric!
  volumeCOL: numeric!
  volumeISS: numeric!
  volumeUSD: numeric!
}

"""
aggregated selection of "CurveHourData"
"""
type CurveHourData_aggregate {
  aggregate: CurveHourData_aggregate_fields
  nodes: [CurveHourData!]!
}

input CurveHourData_aggregate_bool_exp {
  count: CurveHourData_aggregate_bool_exp_count
}

input CurveHourData_aggregate_bool_exp_count {
  arguments: [CurveHourData_select_column!]
  distinct: Boolean
  filter: CurveHourData_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "CurveHourData"
"""
type CurveHourData_aggregate_fields {
  avg: CurveHourData_avg_fields
  count(columns: [CurveHourData_select_column!], distinct: Boolean): Int!
  max: CurveHourData_max_fields
  min: CurveHourData_min_fields
  stddev: CurveHourData_stddev_fields
  stddev_pop: CurveHourData_stddev_pop_fields
  stddev_samp: CurveHourData_stddev_samp_fields
  sum: CurveHourData_sum_fields
  var_pop: CurveHourData_var_pop_fields
  var_samp: CurveHourData_var_samp_fields
  variance: CurveHourData_variance_fields
}

"""
order by aggregate values of table "CurveHourData"
"""
input CurveHourData_aggregate_order_by {
  avg: CurveHourData_avg_order_by
  count: order_by
  max: CurveHourData_max_order_by
  min: CurveHourData_min_order_by
  stddev: CurveHourData_stddev_order_by
  stddev_pop: CurveHourData_stddev_pop_order_by
  stddev_samp: CurveHourData_stddev_samp_order_by
  sum: CurveHourData_sum_order_by
  var_pop: CurveHourData_var_pop_order_by
  var_samp: CurveHourData_var_samp_order_by
  variance: CurveHourData_variance_order_by
}

"""
input type for inserting array relation for remote table "CurveHourData"
"""
input CurveHourData_arr_rel_insert_input {
  data: [CurveHourData_insert_input!]!

  """upsert condition"""
  on_conflict: CurveHourData_on_conflict
}

"""aggregate avg on columns"""
type CurveHourData_avg_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by avg() on columns of table "CurveHourData"
"""
input CurveHourData_avg_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Boolean expression to filter rows from the table "CurveHourData". All fields are combined with a logical 'AND'.
"""
input CurveHourData_bool_exp {
  _and: [CurveHourData_bool_exp!]
  _not: CurveHourData_bool_exp
  _or: [CurveHourData_bool_exp!]
  chainId: Int_comparison_exp
  closeCOL: numeric_comparison_exp
  closeUSD: numeric_comparison_exp
  collateralToken: Token_bool_exp
  collateralToken_id: String_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  highCOL: numeric_comparison_exp
  highUSD: numeric_comparison_exp
  id: String_comparison_exp
  issuanceToken: Token_bool_exp
  issuanceToken_id: String_comparison_exp
  lowCOL: numeric_comparison_exp
  lowUSD: numeric_comparison_exp
  module_id: String_comparison_exp
  openCOL: numeric_comparison_exp
  openUSD: numeric_comparison_exp
  periodStartUnix: Int_comparison_exp
  priceCOL: numeric_comparison_exp
  priceUSD: numeric_comparison_exp
  projectFeeCOL: numeric_comparison_exp
  projectFeeUSD: numeric_comparison_exp
  protocolFeeCOL: numeric_comparison_exp
  protocolFeeISS: numeric_comparison_exp
  protocolFeeUSD: numeric_comparison_exp
  volumeCOL: numeric_comparison_exp
  volumeISS: numeric_comparison_exp
  volumeUSD: numeric_comparison_exp
}

"""
unique or primary key constraints on table "CurveHourData"
"""
enum CurveHourData_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  CurveHourData_pkey
}

"""
input type for incrementing numeric columns in table "CurveHourData"
"""
input CurveHourData_inc_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  highCOL: numeric
  highUSD: numeric
  lowCOL: numeric
  lowUSD: numeric
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
input type for inserting data into table "CurveHourData"
"""
input CurveHourData_insert_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken: Token_obj_rel_insert_input
  collateralToken_id: String
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken: Token_obj_rel_insert_input
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate max on columns"""
type CurveHourData_max_fields {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by max() on columns of table "CurveHourData"
"""
input CurveHourData_max_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  collateralToken_id: order_by
  db_write_timestamp: order_by
  highCOL: order_by
  highUSD: order_by
  id: order_by
  issuanceToken_id: order_by
  lowCOL: order_by
  lowUSD: order_by
  module_id: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate min on columns"""
type CurveHourData_min_fields {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by min() on columns of table "CurveHourData"
"""
input CurveHourData_min_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  collateralToken_id: order_by
  db_write_timestamp: order_by
  highCOL: order_by
  highUSD: order_by
  id: order_by
  issuanceToken_id: order_by
  lowCOL: order_by
  lowUSD: order_by
  module_id: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
response of any mutation on the table "CurveHourData"
"""
type CurveHourData_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [CurveHourData!]!
}

"""
on_conflict condition type for table "CurveHourData"
"""
input CurveHourData_on_conflict {
  constraint: CurveHourData_constraint!
  update_columns: [CurveHourData_update_column!]! = []
  where: CurveHourData_bool_exp
}

"""Ordering options when selecting data from "CurveHourData"."""
input CurveHourData_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  collateralToken: Token_order_by
  collateralToken_id: order_by
  db_write_timestamp: order_by
  highCOL: order_by
  highUSD: order_by
  id: order_by
  issuanceToken: Token_order_by
  issuanceToken_id: order_by
  lowCOL: order_by
  lowUSD: order_by
  module_id: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""primary key columns input for table: CurveHourData"""
input CurveHourData_pk_columns_input {
  id: String!
}

"""
select columns of table "CurveHourData"
"""
enum CurveHourData_select_column {
  """column name"""
  chainId

  """column name"""
  closeCOL

  """column name"""
  closeUSD

  """column name"""
  collateralToken_id

  """column name"""
  db_write_timestamp

  """column name"""
  highCOL

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  issuanceToken_id

  """column name"""
  lowCOL

  """column name"""
  lowUSD

  """column name"""
  module_id

  """column name"""
  openCOL

  """column name"""
  openUSD

  """column name"""
  periodStartUnix

  """column name"""
  priceCOL

  """column name"""
  priceUSD

  """column name"""
  projectFeeCOL

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeCOL

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  volumeCOL

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

"""
input type for updating data in table "CurveHourData"
"""
input CurveHourData_set_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate stddev on columns"""
type CurveHourData_stddev_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev() on columns of table "CurveHourData"
"""
input CurveHourData_stddev_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_pop on columns"""
type CurveHourData_stddev_pop_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_pop() on columns of table "CurveHourData"
"""
input CurveHourData_stddev_pop_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_samp on columns"""
type CurveHourData_stddev_samp_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_samp() on columns of table "CurveHourData"
"""
input CurveHourData_stddev_samp_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Streaming cursor of the table "CurveHourData"
"""
input CurveHourData_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: CurveHourData_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input CurveHourData_stream_cursor_value_input {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  collateralToken_id: String
  db_write_timestamp: timestamp
  highCOL: numeric
  highUSD: numeric
  id: String
  issuanceToken_id: String
  lowCOL: numeric
  lowUSD: numeric
  module_id: String
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate sum on columns"""
type CurveHourData_sum_fields {
  chainId: Int
  closeCOL: numeric
  closeUSD: numeric
  highCOL: numeric
  highUSD: numeric
  lowCOL: numeric
  lowUSD: numeric
  openCOL: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceCOL: numeric
  priceUSD: numeric
  projectFeeCOL: numeric
  projectFeeUSD: numeric
  protocolFeeCOL: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeCOL: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by sum() on columns of table "CurveHourData"
"""
input CurveHourData_sum_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
update columns of table "CurveHourData"
"""
enum CurveHourData_update_column {
  """column name"""
  chainId

  """column name"""
  closeCOL

  """column name"""
  closeUSD

  """column name"""
  collateralToken_id

  """column name"""
  db_write_timestamp

  """column name"""
  highCOL

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  issuanceToken_id

  """column name"""
  lowCOL

  """column name"""
  lowUSD

  """column name"""
  module_id

  """column name"""
  openCOL

  """column name"""
  openUSD

  """column name"""
  periodStartUnix

  """column name"""
  priceCOL

  """column name"""
  priceUSD

  """column name"""
  projectFeeCOL

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeCOL

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  volumeCOL

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

input CurveHourData_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: CurveHourData_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: CurveHourData_set_input

  """filter the rows which have to be updated"""
  where: CurveHourData_bool_exp!
}

"""aggregate var_pop on columns"""
type CurveHourData_var_pop_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_pop() on columns of table "CurveHourData"
"""
input CurveHourData_var_pop_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate var_samp on columns"""
type CurveHourData_var_samp_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_samp() on columns of table "CurveHourData"
"""
input CurveHourData_var_samp_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate variance on columns"""
type CurveHourData_variance_fields {
  chainId: Float
  closeCOL: Float
  closeUSD: Float
  highCOL: Float
  highUSD: Float
  lowCOL: Float
  lowUSD: Float
  openCOL: Float
  openUSD: Float
  periodStartUnix: Float
  priceCOL: Float
  priceUSD: Float
  projectFeeCOL: Float
  projectFeeUSD: Float
  protocolFeeCOL: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeCOL: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by variance() on columns of table "CurveHourData"
"""
input CurveHourData_variance_order_by {
  chainId: order_by
  closeCOL: order_by
  closeUSD: order_by
  highCOL: order_by
  highUSD: order_by
  lowCOL: order_by
  lowUSD: order_by
  openCOL: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceCOL: order_by
  priceUSD: order_by
  projectFeeCOL: order_by
  projectFeeUSD: order_by
  protocolFeeCOL: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeCOL: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
columns and relationships of "Deposit"
"""
type Deposit {
  amount: numeric!
  blockTimestamp: Int!
  db_write_timestamp: timestamp

  """An object relationship"""
  depositVault: DepositVault
  depositVault_id: String!
  depositor: String!
  id: String!
}

"""
columns and relationships of "DepositVault"
"""
type DepositVault {
  address: String!
  balance: numeric
  chainId: Int!
  db_write_timestamp: timestamp

  """An array relationship"""
  deposits(
    """distinct select on columns"""
    distinct_on: [Deposit_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Deposit_order_by!]

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): [Deposit!]!

  """An aggregate relationship"""
  deposits_aggregate(
    """distinct select on columns"""
    distinct_on: [Deposit_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Deposit_order_by!]

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): Deposit_aggregate!
  id: String!

  """An object relationship"""
  token: Token
  token_id: String!

  """An array relationship"""
  transfers(
    """distinct select on columns"""
    distinct_on: [Transfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Transfer_order_by!]

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): [Transfer!]!

  """An aggregate relationship"""
  transfers_aggregate(
    """distinct select on columns"""
    distinct_on: [Transfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Transfer_order_by!]

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): Transfer_aggregate!

  """An object relationship"""
  workflow: Workflow
  workflow_id: String!
}

"""
aggregated selection of "DepositVault"
"""
type DepositVault_aggregate {
  aggregate: DepositVault_aggregate_fields
  nodes: [DepositVault!]!
}

"""
aggregate fields of "DepositVault"
"""
type DepositVault_aggregate_fields {
  avg: DepositVault_avg_fields
  count(columns: [DepositVault_select_column!], distinct: Boolean): Int!
  max: DepositVault_max_fields
  min: DepositVault_min_fields
  stddev: DepositVault_stddev_fields
  stddev_pop: DepositVault_stddev_pop_fields
  stddev_samp: DepositVault_stddev_samp_fields
  sum: DepositVault_sum_fields
  var_pop: DepositVault_var_pop_fields
  var_samp: DepositVault_var_samp_fields
  variance: DepositVault_variance_fields
}

"""aggregate avg on columns"""
type DepositVault_avg_fields {
  balance: Float
  chainId: Float
}

"""
Boolean expression to filter rows from the table "DepositVault". All fields are combined with a logical 'AND'.
"""
input DepositVault_bool_exp {
  _and: [DepositVault_bool_exp!]
  _not: DepositVault_bool_exp
  _or: [DepositVault_bool_exp!]
  address: String_comparison_exp
  balance: numeric_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  deposits: Deposit_bool_exp
  deposits_aggregate: Deposit_aggregate_bool_exp
  id: String_comparison_exp
  token: Token_bool_exp
  token_id: String_comparison_exp
  transfers: Transfer_bool_exp
  transfers_aggregate: Transfer_aggregate_bool_exp
  workflow: Workflow_bool_exp
  workflow_id: String_comparison_exp
}

"""
unique or primary key constraints on table "DepositVault"
"""
enum DepositVault_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  DepositVault_pkey
}

"""
input type for incrementing numeric columns in table "DepositVault"
"""
input DepositVault_inc_input {
  balance: numeric
  chainId: Int
}

"""
input type for inserting data into table "DepositVault"
"""
input DepositVault_insert_input {
  address: String
  balance: numeric
  chainId: Int
  db_write_timestamp: timestamp
  deposits: Deposit_arr_rel_insert_input
  id: String
  token: Token_obj_rel_insert_input
  token_id: String
  transfers: Transfer_arr_rel_insert_input
  workflow: Workflow_obj_rel_insert_input
  workflow_id: String
}

"""aggregate max on columns"""
type DepositVault_max_fields {
  address: String
  balance: numeric
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  token_id: String
  workflow_id: String
}

"""aggregate min on columns"""
type DepositVault_min_fields {
  address: String
  balance: numeric
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  token_id: String
  workflow_id: String
}

"""
response of any mutation on the table "DepositVault"
"""
type DepositVault_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [DepositVault!]!
}

"""
input type for inserting object relation for remote table "DepositVault"
"""
input DepositVault_obj_rel_insert_input {
  data: DepositVault_insert_input!

  """upsert condition"""
  on_conflict: DepositVault_on_conflict
}

"""
on_conflict condition type for table "DepositVault"
"""
input DepositVault_on_conflict {
  constraint: DepositVault_constraint!
  update_columns: [DepositVault_update_column!]! = []
  where: DepositVault_bool_exp
}

"""Ordering options when selecting data from "DepositVault"."""
input DepositVault_order_by {
  address: order_by
  balance: order_by
  chainId: order_by
  db_write_timestamp: order_by
  deposits_aggregate: Deposit_aggregate_order_by
  id: order_by
  token: Token_order_by
  token_id: order_by
  transfers_aggregate: Transfer_aggregate_order_by
  workflow: Workflow_order_by
  workflow_id: order_by
}

"""primary key columns input for table: DepositVault"""
input DepositVault_pk_columns_input {
  id: String!
}

"""
select columns of table "DepositVault"
"""
enum DepositVault_select_column {
  """column name"""
  address

  """column name"""
  balance

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  token_id

  """column name"""
  workflow_id
}

"""
input type for updating data in table "DepositVault"
"""
input DepositVault_set_input {
  address: String
  balance: numeric
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  token_id: String
  workflow_id: String
}

"""aggregate stddev on columns"""
type DepositVault_stddev_fields {
  balance: Float
  chainId: Float
}

"""aggregate stddev_pop on columns"""
type DepositVault_stddev_pop_fields {
  balance: Float
  chainId: Float
}

"""aggregate stddev_samp on columns"""
type DepositVault_stddev_samp_fields {
  balance: Float
  chainId: Float
}

"""
Streaming cursor of the table "DepositVault"
"""
input DepositVault_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: DepositVault_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input DepositVault_stream_cursor_value_input {
  address: String
  balance: numeric
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  token_id: String
  workflow_id: String
}

"""aggregate sum on columns"""
type DepositVault_sum_fields {
  balance: numeric
  chainId: Int
}

"""
update columns of table "DepositVault"
"""
enum DepositVault_update_column {
  """column name"""
  address

  """column name"""
  balance

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  token_id

  """column name"""
  workflow_id
}

input DepositVault_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: DepositVault_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: DepositVault_set_input

  """filter the rows which have to be updated"""
  where: DepositVault_bool_exp!
}

"""aggregate var_pop on columns"""
type DepositVault_var_pop_fields {
  balance: Float
  chainId: Float
}

"""aggregate var_samp on columns"""
type DepositVault_var_samp_fields {
  balance: Float
  chainId: Float
}

"""aggregate variance on columns"""
type DepositVault_variance_fields {
  balance: Float
  chainId: Float
}

"""
aggregated selection of "Deposit"
"""
type Deposit_aggregate {
  aggregate: Deposit_aggregate_fields
  nodes: [Deposit!]!
}

input Deposit_aggregate_bool_exp {
  count: Deposit_aggregate_bool_exp_count
}

input Deposit_aggregate_bool_exp_count {
  arguments: [Deposit_select_column!]
  distinct: Boolean
  filter: Deposit_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "Deposit"
"""
type Deposit_aggregate_fields {
  avg: Deposit_avg_fields
  count(columns: [Deposit_select_column!], distinct: Boolean): Int!
  max: Deposit_max_fields
  min: Deposit_min_fields
  stddev: Deposit_stddev_fields
  stddev_pop: Deposit_stddev_pop_fields
  stddev_samp: Deposit_stddev_samp_fields
  sum: Deposit_sum_fields
  var_pop: Deposit_var_pop_fields
  var_samp: Deposit_var_samp_fields
  variance: Deposit_variance_fields
}

"""
order by aggregate values of table "Deposit"
"""
input Deposit_aggregate_order_by {
  avg: Deposit_avg_order_by
  count: order_by
  max: Deposit_max_order_by
  min: Deposit_min_order_by
  stddev: Deposit_stddev_order_by
  stddev_pop: Deposit_stddev_pop_order_by
  stddev_samp: Deposit_stddev_samp_order_by
  sum: Deposit_sum_order_by
  var_pop: Deposit_var_pop_order_by
  var_samp: Deposit_var_samp_order_by
  variance: Deposit_variance_order_by
}

"""
input type for inserting array relation for remote table "Deposit"
"""
input Deposit_arr_rel_insert_input {
  data: [Deposit_insert_input!]!

  """upsert condition"""
  on_conflict: Deposit_on_conflict
}

"""aggregate avg on columns"""
type Deposit_avg_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by avg() on columns of table "Deposit"
"""
input Deposit_avg_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
Boolean expression to filter rows from the table "Deposit". All fields are combined with a logical 'AND'.
"""
input Deposit_bool_exp {
  _and: [Deposit_bool_exp!]
  _not: Deposit_bool_exp
  _or: [Deposit_bool_exp!]
  amount: numeric_comparison_exp
  blockTimestamp: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  depositVault: DepositVault_bool_exp
  depositVault_id: String_comparison_exp
  depositor: String_comparison_exp
  id: String_comparison_exp
}

"""
unique or primary key constraints on table "Deposit"
"""
enum Deposit_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  Deposit_pkey
}

"""
input type for incrementing numeric columns in table "Deposit"
"""
input Deposit_inc_input {
  amount: numeric
  blockTimestamp: Int
}

"""
input type for inserting data into table "Deposit"
"""
input Deposit_insert_input {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault: DepositVault_obj_rel_insert_input
  depositVault_id: String
  depositor: String
  id: String
}

"""aggregate max on columns"""
type Deposit_max_fields {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  depositor: String
  id: String
}

"""
order by max() on columns of table "Deposit"
"""
input Deposit_max_order_by {
  amount: order_by
  blockTimestamp: order_by
  db_write_timestamp: order_by
  depositVault_id: order_by
  depositor: order_by
  id: order_by
}

"""aggregate min on columns"""
type Deposit_min_fields {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  depositor: String
  id: String
}

"""
order by min() on columns of table "Deposit"
"""
input Deposit_min_order_by {
  amount: order_by
  blockTimestamp: order_by
  db_write_timestamp: order_by
  depositVault_id: order_by
  depositor: order_by
  id: order_by
}

"""
response of any mutation on the table "Deposit"
"""
type Deposit_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [Deposit!]!
}

"""
on_conflict condition type for table "Deposit"
"""
input Deposit_on_conflict {
  constraint: Deposit_constraint!
  update_columns: [Deposit_update_column!]! = []
  where: Deposit_bool_exp
}

"""Ordering options when selecting data from "Deposit"."""
input Deposit_order_by {
  amount: order_by
  blockTimestamp: order_by
  db_write_timestamp: order_by
  depositVault: DepositVault_order_by
  depositVault_id: order_by
  depositor: order_by
  id: order_by
}

"""primary key columns input for table: Deposit"""
input Deposit_pk_columns_input {
  id: String!
}

"""
select columns of table "Deposit"
"""
enum Deposit_select_column {
  """column name"""
  amount

  """column name"""
  blockTimestamp

  """column name"""
  db_write_timestamp

  """column name"""
  depositVault_id

  """column name"""
  depositor

  """column name"""
  id
}

"""
input type for updating data in table "Deposit"
"""
input Deposit_set_input {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  depositor: String
  id: String
}

"""aggregate stddev on columns"""
type Deposit_stddev_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by stddev() on columns of table "Deposit"
"""
input Deposit_stddev_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate stddev_pop on columns"""
type Deposit_stddev_pop_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by stddev_pop() on columns of table "Deposit"
"""
input Deposit_stddev_pop_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate stddev_samp on columns"""
type Deposit_stddev_samp_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by stddev_samp() on columns of table "Deposit"
"""
input Deposit_stddev_samp_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
Streaming cursor of the table "Deposit"
"""
input Deposit_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: Deposit_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input Deposit_stream_cursor_value_input {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  depositor: String
  id: String
}

"""aggregate sum on columns"""
type Deposit_sum_fields {
  amount: numeric
  blockTimestamp: Int
}

"""
order by sum() on columns of table "Deposit"
"""
input Deposit_sum_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
update columns of table "Deposit"
"""
enum Deposit_update_column {
  """column name"""
  amount

  """column name"""
  blockTimestamp

  """column name"""
  db_write_timestamp

  """column name"""
  depositVault_id

  """column name"""
  depositor

  """column name"""
  id
}

input Deposit_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: Deposit_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: Deposit_set_input

  """filter the rows which have to be updated"""
  where: Deposit_bool_exp!
}

"""aggregate var_pop on columns"""
type Deposit_var_pop_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by var_pop() on columns of table "Deposit"
"""
input Deposit_var_pop_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate var_samp on columns"""
type Deposit_var_samp_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by var_samp() on columns of table "Deposit"
"""
input Deposit_var_samp_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate variance on columns"""
type Deposit_variance_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by variance() on columns of table "Deposit"
"""
input Deposit_variance_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
Boolean expression to compare columns of type "Int". All fields are combined with logical 'AND'.
"""
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"""
columns and relationships of "IssuanceTokenDayData"
"""
type IssuanceTokenDayData {
  chainId: Int!
  closeUSD: numeric!
  date: Int!
  db_write_timestamp: timestamp
  highUSD: numeric!
  id: String!
  lowUSD: numeric!
  openUSD: numeric!
  priceUSD: numeric!
  projectFeeUSD: numeric!
  protocolFeeISS: numeric!
  protocolFeeUSD: numeric!
  token_id: String!
  volumeISS: numeric!
  volumeUSD: numeric!
}

"""
aggregated selection of "IssuanceTokenDayData"
"""
type IssuanceTokenDayData_aggregate {
  aggregate: IssuanceTokenDayData_aggregate_fields
  nodes: [IssuanceTokenDayData!]!
}

input IssuanceTokenDayData_aggregate_bool_exp {
  count: IssuanceTokenDayData_aggregate_bool_exp_count
}

input IssuanceTokenDayData_aggregate_bool_exp_count {
  arguments: [IssuanceTokenDayData_select_column!]
  distinct: Boolean
  filter: IssuanceTokenDayData_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "IssuanceTokenDayData"
"""
type IssuanceTokenDayData_aggregate_fields {
  avg: IssuanceTokenDayData_avg_fields
  count(columns: [IssuanceTokenDayData_select_column!], distinct: Boolean): Int!
  max: IssuanceTokenDayData_max_fields
  min: IssuanceTokenDayData_min_fields
  stddev: IssuanceTokenDayData_stddev_fields
  stddev_pop: IssuanceTokenDayData_stddev_pop_fields
  stddev_samp: IssuanceTokenDayData_stddev_samp_fields
  sum: IssuanceTokenDayData_sum_fields
  var_pop: IssuanceTokenDayData_var_pop_fields
  var_samp: IssuanceTokenDayData_var_samp_fields
  variance: IssuanceTokenDayData_variance_fields
}

"""
order by aggregate values of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_aggregate_order_by {
  avg: IssuanceTokenDayData_avg_order_by
  count: order_by
  max: IssuanceTokenDayData_max_order_by
  min: IssuanceTokenDayData_min_order_by
  stddev: IssuanceTokenDayData_stddev_order_by
  stddev_pop: IssuanceTokenDayData_stddev_pop_order_by
  stddev_samp: IssuanceTokenDayData_stddev_samp_order_by
  sum: IssuanceTokenDayData_sum_order_by
  var_pop: IssuanceTokenDayData_var_pop_order_by
  var_samp: IssuanceTokenDayData_var_samp_order_by
  variance: IssuanceTokenDayData_variance_order_by
}

"""
input type for inserting array relation for remote table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_arr_rel_insert_input {
  data: [IssuanceTokenDayData_insert_input!]!

  """upsert condition"""
  on_conflict: IssuanceTokenDayData_on_conflict
}

"""aggregate avg on columns"""
type IssuanceTokenDayData_avg_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by avg() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_avg_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Boolean expression to filter rows from the table "IssuanceTokenDayData". All fields are combined with a logical 'AND'.
"""
input IssuanceTokenDayData_bool_exp {
  _and: [IssuanceTokenDayData_bool_exp!]
  _not: IssuanceTokenDayData_bool_exp
  _or: [IssuanceTokenDayData_bool_exp!]
  chainId: Int_comparison_exp
  closeUSD: numeric_comparison_exp
  date: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  highUSD: numeric_comparison_exp
  id: String_comparison_exp
  lowUSD: numeric_comparison_exp
  openUSD: numeric_comparison_exp
  priceUSD: numeric_comparison_exp
  projectFeeUSD: numeric_comparison_exp
  protocolFeeISS: numeric_comparison_exp
  protocolFeeUSD: numeric_comparison_exp
  token_id: String_comparison_exp
  volumeISS: numeric_comparison_exp
  volumeUSD: numeric_comparison_exp
}

"""
unique or primary key constraints on table "IssuanceTokenDayData"
"""
enum IssuanceTokenDayData_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  IssuanceTokenDayData_pkey
}

"""
input type for incrementing numeric columns in table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_inc_input {
  chainId: Int
  closeUSD: numeric
  date: Int
  highUSD: numeric
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
input type for inserting data into table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_insert_input {
  chainId: Int
  closeUSD: numeric
  date: Int
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate max on columns"""
type IssuanceTokenDayData_max_fields {
  chainId: Int
  closeUSD: numeric
  date: Int
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by max() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_max_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  db_write_timestamp: order_by
  highUSD: order_by
  id: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  token_id: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate min on columns"""
type IssuanceTokenDayData_min_fields {
  chainId: Int
  closeUSD: numeric
  date: Int
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by min() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_min_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  db_write_timestamp: order_by
  highUSD: order_by
  id: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  token_id: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
response of any mutation on the table "IssuanceTokenDayData"
"""
type IssuanceTokenDayData_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [IssuanceTokenDayData!]!
}

"""
on_conflict condition type for table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_on_conflict {
  constraint: IssuanceTokenDayData_constraint!
  update_columns: [IssuanceTokenDayData_update_column!]! = []
  where: IssuanceTokenDayData_bool_exp
}

"""Ordering options when selecting data from "IssuanceTokenDayData"."""
input IssuanceTokenDayData_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  db_write_timestamp: order_by
  highUSD: order_by
  id: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  token_id: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""primary key columns input for table: IssuanceTokenDayData"""
input IssuanceTokenDayData_pk_columns_input {
  id: String!
}

"""
select columns of table "IssuanceTokenDayData"
"""
enum IssuanceTokenDayData_select_column {
  """column name"""
  chainId

  """column name"""
  closeUSD

  """column name"""
  date

  """column name"""
  db_write_timestamp

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  lowUSD

  """column name"""
  openUSD

  """column name"""
  priceUSD

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  token_id

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

"""
input type for updating data in table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_set_input {
  chainId: Int
  closeUSD: numeric
  date: Int
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate stddev on columns"""
type IssuanceTokenDayData_stddev_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_stddev_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_pop on columns"""
type IssuanceTokenDayData_stddev_pop_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_pop() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_stddev_pop_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_samp on columns"""
type IssuanceTokenDayData_stddev_samp_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_samp() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_stddev_samp_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Streaming cursor of the table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: IssuanceTokenDayData_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input IssuanceTokenDayData_stream_cursor_value_input {
  chainId: Int
  closeUSD: numeric
  date: Int
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate sum on columns"""
type IssuanceTokenDayData_sum_fields {
  chainId: Int
  closeUSD: numeric
  date: Int
  highUSD: numeric
  lowUSD: numeric
  openUSD: numeric
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by sum() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_sum_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
update columns of table "IssuanceTokenDayData"
"""
enum IssuanceTokenDayData_update_column {
  """column name"""
  chainId

  """column name"""
  closeUSD

  """column name"""
  date

  """column name"""
  db_write_timestamp

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  lowUSD

  """column name"""
  openUSD

  """column name"""
  priceUSD

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  token_id

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

input IssuanceTokenDayData_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: IssuanceTokenDayData_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: IssuanceTokenDayData_set_input

  """filter the rows which have to be updated"""
  where: IssuanceTokenDayData_bool_exp!
}

"""aggregate var_pop on columns"""
type IssuanceTokenDayData_var_pop_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_pop() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_var_pop_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate var_samp on columns"""
type IssuanceTokenDayData_var_samp_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_samp() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_var_samp_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate variance on columns"""
type IssuanceTokenDayData_variance_fields {
  chainId: Float
  closeUSD: Float
  date: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by variance() on columns of table "IssuanceTokenDayData"
"""
input IssuanceTokenDayData_variance_order_by {
  chainId: order_by
  closeUSD: order_by
  date: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
columns and relationships of "IssuanceTokenHourData"
"""
type IssuanceTokenHourData {
  chainId: Int!
  closeUSD: numeric!
  db_write_timestamp: timestamp
  highUSD: numeric!
  id: String!
  lowUSD: numeric!
  openUSD: numeric!
  periodStartUnix: Int!
  priceUSD: numeric!
  projectFeeUSD: numeric!
  protocolFeeISS: numeric!
  protocolFeeUSD: numeric!
  token_id: String!
  volumeISS: numeric!
  volumeUSD: numeric!
}

"""
aggregated selection of "IssuanceTokenHourData"
"""
type IssuanceTokenHourData_aggregate {
  aggregate: IssuanceTokenHourData_aggregate_fields
  nodes: [IssuanceTokenHourData!]!
}

input IssuanceTokenHourData_aggregate_bool_exp {
  count: IssuanceTokenHourData_aggregate_bool_exp_count
}

input IssuanceTokenHourData_aggregate_bool_exp_count {
  arguments: [IssuanceTokenHourData_select_column!]
  distinct: Boolean
  filter: IssuanceTokenHourData_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "IssuanceTokenHourData"
"""
type IssuanceTokenHourData_aggregate_fields {
  avg: IssuanceTokenHourData_avg_fields
  count(columns: [IssuanceTokenHourData_select_column!], distinct: Boolean): Int!
  max: IssuanceTokenHourData_max_fields
  min: IssuanceTokenHourData_min_fields
  stddev: IssuanceTokenHourData_stddev_fields
  stddev_pop: IssuanceTokenHourData_stddev_pop_fields
  stddev_samp: IssuanceTokenHourData_stddev_samp_fields
  sum: IssuanceTokenHourData_sum_fields
  var_pop: IssuanceTokenHourData_var_pop_fields
  var_samp: IssuanceTokenHourData_var_samp_fields
  variance: IssuanceTokenHourData_variance_fields
}

"""
order by aggregate values of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_aggregate_order_by {
  avg: IssuanceTokenHourData_avg_order_by
  count: order_by
  max: IssuanceTokenHourData_max_order_by
  min: IssuanceTokenHourData_min_order_by
  stddev: IssuanceTokenHourData_stddev_order_by
  stddev_pop: IssuanceTokenHourData_stddev_pop_order_by
  stddev_samp: IssuanceTokenHourData_stddev_samp_order_by
  sum: IssuanceTokenHourData_sum_order_by
  var_pop: IssuanceTokenHourData_var_pop_order_by
  var_samp: IssuanceTokenHourData_var_samp_order_by
  variance: IssuanceTokenHourData_variance_order_by
}

"""
input type for inserting array relation for remote table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_arr_rel_insert_input {
  data: [IssuanceTokenHourData_insert_input!]!

  """upsert condition"""
  on_conflict: IssuanceTokenHourData_on_conflict
}

"""aggregate avg on columns"""
type IssuanceTokenHourData_avg_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by avg() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_avg_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Boolean expression to filter rows from the table "IssuanceTokenHourData". All fields are combined with a logical 'AND'.
"""
input IssuanceTokenHourData_bool_exp {
  _and: [IssuanceTokenHourData_bool_exp!]
  _not: IssuanceTokenHourData_bool_exp
  _or: [IssuanceTokenHourData_bool_exp!]
  chainId: Int_comparison_exp
  closeUSD: numeric_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  highUSD: numeric_comparison_exp
  id: String_comparison_exp
  lowUSD: numeric_comparison_exp
  openUSD: numeric_comparison_exp
  periodStartUnix: Int_comparison_exp
  priceUSD: numeric_comparison_exp
  projectFeeUSD: numeric_comparison_exp
  protocolFeeISS: numeric_comparison_exp
  protocolFeeUSD: numeric_comparison_exp
  token_id: String_comparison_exp
  volumeISS: numeric_comparison_exp
  volumeUSD: numeric_comparison_exp
}

"""
unique or primary key constraints on table "IssuanceTokenHourData"
"""
enum IssuanceTokenHourData_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  IssuanceTokenHourData_pkey
}

"""
input type for incrementing numeric columns in table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_inc_input {
  chainId: Int
  closeUSD: numeric
  highUSD: numeric
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
input type for inserting data into table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_insert_input {
  chainId: Int
  closeUSD: numeric
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate max on columns"""
type IssuanceTokenHourData_max_fields {
  chainId: Int
  closeUSD: numeric
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by max() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_max_order_by {
  chainId: order_by
  closeUSD: order_by
  db_write_timestamp: order_by
  highUSD: order_by
  id: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  token_id: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate min on columns"""
type IssuanceTokenHourData_min_fields {
  chainId: Int
  closeUSD: numeric
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by min() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_min_order_by {
  chainId: order_by
  closeUSD: order_by
  db_write_timestamp: order_by
  highUSD: order_by
  id: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  token_id: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
response of any mutation on the table "IssuanceTokenHourData"
"""
type IssuanceTokenHourData_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [IssuanceTokenHourData!]!
}

"""
on_conflict condition type for table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_on_conflict {
  constraint: IssuanceTokenHourData_constraint!
  update_columns: [IssuanceTokenHourData_update_column!]! = []
  where: IssuanceTokenHourData_bool_exp
}

"""Ordering options when selecting data from "IssuanceTokenHourData"."""
input IssuanceTokenHourData_order_by {
  chainId: order_by
  closeUSD: order_by
  db_write_timestamp: order_by
  highUSD: order_by
  id: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  token_id: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""primary key columns input for table: IssuanceTokenHourData"""
input IssuanceTokenHourData_pk_columns_input {
  id: String!
}

"""
select columns of table "IssuanceTokenHourData"
"""
enum IssuanceTokenHourData_select_column {
  """column name"""
  chainId

  """column name"""
  closeUSD

  """column name"""
  db_write_timestamp

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  lowUSD

  """column name"""
  openUSD

  """column name"""
  periodStartUnix

  """column name"""
  priceUSD

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  token_id

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

"""
input type for updating data in table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_set_input {
  chainId: Int
  closeUSD: numeric
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate stddev on columns"""
type IssuanceTokenHourData_stddev_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_stddev_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_pop on columns"""
type IssuanceTokenHourData_stddev_pop_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_pop() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_stddev_pop_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate stddev_samp on columns"""
type IssuanceTokenHourData_stddev_samp_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by stddev_samp() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_stddev_samp_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
Streaming cursor of the table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: IssuanceTokenHourData_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input IssuanceTokenHourData_stream_cursor_value_input {
  chainId: Int
  closeUSD: numeric
  db_write_timestamp: timestamp
  highUSD: numeric
  id: String
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  token_id: String
  volumeISS: numeric
  volumeUSD: numeric
}

"""aggregate sum on columns"""
type IssuanceTokenHourData_sum_fields {
  chainId: Int
  closeUSD: numeric
  highUSD: numeric
  lowUSD: numeric
  openUSD: numeric
  periodStartUnix: Int
  priceUSD: numeric
  projectFeeUSD: numeric
  protocolFeeISS: numeric
  protocolFeeUSD: numeric
  volumeISS: numeric
  volumeUSD: numeric
}

"""
order by sum() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_sum_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
update columns of table "IssuanceTokenHourData"
"""
enum IssuanceTokenHourData_update_column {
  """column name"""
  chainId

  """column name"""
  closeUSD

  """column name"""
  db_write_timestamp

  """column name"""
  highUSD

  """column name"""
  id

  """column name"""
  lowUSD

  """column name"""
  openUSD

  """column name"""
  periodStartUnix

  """column name"""
  priceUSD

  """column name"""
  projectFeeUSD

  """column name"""
  protocolFeeISS

  """column name"""
  protocolFeeUSD

  """column name"""
  token_id

  """column name"""
  volumeISS

  """column name"""
  volumeUSD
}

input IssuanceTokenHourData_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: IssuanceTokenHourData_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: IssuanceTokenHourData_set_input

  """filter the rows which have to be updated"""
  where: IssuanceTokenHourData_bool_exp!
}

"""aggregate var_pop on columns"""
type IssuanceTokenHourData_var_pop_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_pop() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_var_pop_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate var_samp on columns"""
type IssuanceTokenHourData_var_samp_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by var_samp() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_var_samp_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""aggregate variance on columns"""
type IssuanceTokenHourData_variance_fields {
  chainId: Float
  closeUSD: Float
  highUSD: Float
  lowUSD: Float
  openUSD: Float
  periodStartUnix: Float
  priceUSD: Float
  projectFeeUSD: Float
  protocolFeeISS: Float
  protocolFeeUSD: Float
  volumeISS: Float
  volumeUSD: Float
}

"""
order by variance() on columns of table "IssuanceTokenHourData"
"""
input IssuanceTokenHourData_variance_order_by {
  chainId: order_by
  closeUSD: order_by
  highUSD: order_by
  lowUSD: order_by
  openUSD: order_by
  periodStartUnix: order_by
  priceUSD: order_by
  projectFeeUSD: order_by
  protocolFeeISS: order_by
  protocolFeeUSD: order_by
  volumeISS: order_by
  volumeUSD: order_by
}

"""
columns and relationships of "LinearVesting"
"""
type LinearVesting {
  amount: numeric!
  blockTimestamp: Int!
  chainId: Int!
  cliff: numeric!
  db_write_timestamp: timestamp
  end: numeric!
  id: String!
  recipient: String!
  start: numeric!
  status: vestingstatus!

  """An object relationship"""
  streamingPaymentProcessor: StreamingPaymentProcessor
  streamingPaymentProcessor_id: String!

  """An object relationship"""
  token: Token
  token_id: String!
}

"""
aggregated selection of "LinearVesting"
"""
type LinearVesting_aggregate {
  aggregate: LinearVesting_aggregate_fields
  nodes: [LinearVesting!]!
}

input LinearVesting_aggregate_bool_exp {
  count: LinearVesting_aggregate_bool_exp_count
}

input LinearVesting_aggregate_bool_exp_count {
  arguments: [LinearVesting_select_column!]
  distinct: Boolean
  filter: LinearVesting_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "LinearVesting"
"""
type LinearVesting_aggregate_fields {
  avg: LinearVesting_avg_fields
  count(columns: [LinearVesting_select_column!], distinct: Boolean): Int!
  max: LinearVesting_max_fields
  min: LinearVesting_min_fields
  stddev: LinearVesting_stddev_fields
  stddev_pop: LinearVesting_stddev_pop_fields
  stddev_samp: LinearVesting_stddev_samp_fields
  sum: LinearVesting_sum_fields
  var_pop: LinearVesting_var_pop_fields
  var_samp: LinearVesting_var_samp_fields
  variance: LinearVesting_variance_fields
}

"""
order by aggregate values of table "LinearVesting"
"""
input LinearVesting_aggregate_order_by {
  avg: LinearVesting_avg_order_by
  count: order_by
  max: LinearVesting_max_order_by
  min: LinearVesting_min_order_by
  stddev: LinearVesting_stddev_order_by
  stddev_pop: LinearVesting_stddev_pop_order_by
  stddev_samp: LinearVesting_stddev_samp_order_by
  sum: LinearVesting_sum_order_by
  var_pop: LinearVesting_var_pop_order_by
  var_samp: LinearVesting_var_samp_order_by
  variance: LinearVesting_variance_order_by
}

"""
input type for inserting array relation for remote table "LinearVesting"
"""
input LinearVesting_arr_rel_insert_input {
  data: [LinearVesting_insert_input!]!

  """upsert condition"""
  on_conflict: LinearVesting_on_conflict
}

"""aggregate avg on columns"""
type LinearVesting_avg_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by avg() on columns of table "LinearVesting"
"""
input LinearVesting_avg_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""
Boolean expression to filter rows from the table "LinearVesting". All fields are combined with a logical 'AND'.
"""
input LinearVesting_bool_exp {
  _and: [LinearVesting_bool_exp!]
  _not: LinearVesting_bool_exp
  _or: [LinearVesting_bool_exp!]
  amount: numeric_comparison_exp
  blockTimestamp: Int_comparison_exp
  chainId: Int_comparison_exp
  cliff: numeric_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  end: numeric_comparison_exp
  id: String_comparison_exp
  recipient: String_comparison_exp
  start: numeric_comparison_exp
  status: vestingstatus_comparison_exp
  streamingPaymentProcessor: StreamingPaymentProcessor_bool_exp
  streamingPaymentProcessor_id: String_comparison_exp
  token: Token_bool_exp
  token_id: String_comparison_exp
}

"""
unique or primary key constraints on table "LinearVesting"
"""
enum LinearVesting_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  LinearVesting_pkey
}

"""
input type for incrementing numeric columns in table "LinearVesting"
"""
input LinearVesting_inc_input {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  end: numeric
  start: numeric
}

"""
input type for inserting data into table "LinearVesting"
"""
input LinearVesting_insert_input {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  db_write_timestamp: timestamp
  end: numeric
  id: String
  recipient: String
  start: numeric
  status: vestingstatus
  streamingPaymentProcessor: StreamingPaymentProcessor_obj_rel_insert_input
  streamingPaymentProcessor_id: String
  token: Token_obj_rel_insert_input
  token_id: String
}

"""aggregate max on columns"""
type LinearVesting_max_fields {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  db_write_timestamp: timestamp
  end: numeric
  id: String
  recipient: String
  start: numeric
  status: vestingstatus
  streamingPaymentProcessor_id: String
  token_id: String
}

"""
order by max() on columns of table "LinearVesting"
"""
input LinearVesting_max_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  db_write_timestamp: order_by
  end: order_by
  id: order_by
  recipient: order_by
  start: order_by
  status: order_by
  streamingPaymentProcessor_id: order_by
  token_id: order_by
}

"""aggregate min on columns"""
type LinearVesting_min_fields {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  db_write_timestamp: timestamp
  end: numeric
  id: String
  recipient: String
  start: numeric
  status: vestingstatus
  streamingPaymentProcessor_id: String
  token_id: String
}

"""
order by min() on columns of table "LinearVesting"
"""
input LinearVesting_min_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  db_write_timestamp: order_by
  end: order_by
  id: order_by
  recipient: order_by
  start: order_by
  status: order_by
  streamingPaymentProcessor_id: order_by
  token_id: order_by
}

"""
response of any mutation on the table "LinearVesting"
"""
type LinearVesting_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [LinearVesting!]!
}

"""
on_conflict condition type for table "LinearVesting"
"""
input LinearVesting_on_conflict {
  constraint: LinearVesting_constraint!
  update_columns: [LinearVesting_update_column!]! = []
  where: LinearVesting_bool_exp
}

"""Ordering options when selecting data from "LinearVesting"."""
input LinearVesting_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  db_write_timestamp: order_by
  end: order_by
  id: order_by
  recipient: order_by
  start: order_by
  status: order_by
  streamingPaymentProcessor: StreamingPaymentProcessor_order_by
  streamingPaymentProcessor_id: order_by
  token: Token_order_by
  token_id: order_by
}

"""primary key columns input for table: LinearVesting"""
input LinearVesting_pk_columns_input {
  id: String!
}

"""
select columns of table "LinearVesting"
"""
enum LinearVesting_select_column {
  """column name"""
  amount

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  cliff

  """column name"""
  db_write_timestamp

  """column name"""
  end

  """column name"""
  id

  """column name"""
  recipient

  """column name"""
  start

  """column name"""
  status

  """column name"""
  streamingPaymentProcessor_id

  """column name"""
  token_id
}

"""
input type for updating data in table "LinearVesting"
"""
input LinearVesting_set_input {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  db_write_timestamp: timestamp
  end: numeric
  id: String
  recipient: String
  start: numeric
  status: vestingstatus
  streamingPaymentProcessor_id: String
  token_id: String
}

"""aggregate stddev on columns"""
type LinearVesting_stddev_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by stddev() on columns of table "LinearVesting"
"""
input LinearVesting_stddev_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""aggregate stddev_pop on columns"""
type LinearVesting_stddev_pop_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by stddev_pop() on columns of table "LinearVesting"
"""
input LinearVesting_stddev_pop_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""aggregate stddev_samp on columns"""
type LinearVesting_stddev_samp_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by stddev_samp() on columns of table "LinearVesting"
"""
input LinearVesting_stddev_samp_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""
Streaming cursor of the table "LinearVesting"
"""
input LinearVesting_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: LinearVesting_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input LinearVesting_stream_cursor_value_input {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  db_write_timestamp: timestamp
  end: numeric
  id: String
  recipient: String
  start: numeric
  status: vestingstatus
  streamingPaymentProcessor_id: String
  token_id: String
}

"""aggregate sum on columns"""
type LinearVesting_sum_fields {
  amount: numeric
  blockTimestamp: Int
  chainId: Int
  cliff: numeric
  end: numeric
  start: numeric
}

"""
order by sum() on columns of table "LinearVesting"
"""
input LinearVesting_sum_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""
update columns of table "LinearVesting"
"""
enum LinearVesting_update_column {
  """column name"""
  amount

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  cliff

  """column name"""
  db_write_timestamp

  """column name"""
  end

  """column name"""
  id

  """column name"""
  recipient

  """column name"""
  start

  """column name"""
  status

  """column name"""
  streamingPaymentProcessor_id

  """column name"""
  token_id
}

input LinearVesting_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: LinearVesting_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: LinearVesting_set_input

  """filter the rows which have to be updated"""
  where: LinearVesting_bool_exp!
}

"""aggregate var_pop on columns"""
type LinearVesting_var_pop_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by var_pop() on columns of table "LinearVesting"
"""
input LinearVesting_var_pop_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""aggregate var_samp on columns"""
type LinearVesting_var_samp_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by var_samp() on columns of table "LinearVesting"
"""
input LinearVesting_var_samp_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""aggregate variance on columns"""
type LinearVesting_variance_fields {
  amount: Float
  blockTimestamp: Float
  chainId: Float
  cliff: Float
  end: Float
  start: Float
}

"""
order by variance() on columns of table "LinearVesting"
"""
input LinearVesting_variance_order_by {
  amount: order_by
  blockTimestamp: order_by
  chainId: order_by
  cliff: order_by
  end: order_by
  start: order_by
}

"""
columns and relationships of "ProjectFee"
"""
type ProjectFee {
  amount: numeric!
  amountUSD: numeric!
  blockTimestamp: Int!
  chainId: Int!
  db_write_timestamp: timestamp
  id: String!
  module_id: String!
  recipient: String!

  """An object relationship"""
  token: Token
  token_id: String!
}

"""
aggregated selection of "ProjectFee"
"""
type ProjectFee_aggregate {
  aggregate: ProjectFee_aggregate_fields
  nodes: [ProjectFee!]!
}

input ProjectFee_aggregate_bool_exp {
  count: ProjectFee_aggregate_bool_exp_count
}

input ProjectFee_aggregate_bool_exp_count {
  arguments: [ProjectFee_select_column!]
  distinct: Boolean
  filter: ProjectFee_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "ProjectFee"
"""
type ProjectFee_aggregate_fields {
  avg: ProjectFee_avg_fields
  count(columns: [ProjectFee_select_column!], distinct: Boolean): Int!
  max: ProjectFee_max_fields
  min: ProjectFee_min_fields
  stddev: ProjectFee_stddev_fields
  stddev_pop: ProjectFee_stddev_pop_fields
  stddev_samp: ProjectFee_stddev_samp_fields
  sum: ProjectFee_sum_fields
  var_pop: ProjectFee_var_pop_fields
  var_samp: ProjectFee_var_samp_fields
  variance: ProjectFee_variance_fields
}

"""
order by aggregate values of table "ProjectFee"
"""
input ProjectFee_aggregate_order_by {
  avg: ProjectFee_avg_order_by
  count: order_by
  max: ProjectFee_max_order_by
  min: ProjectFee_min_order_by
  stddev: ProjectFee_stddev_order_by
  stddev_pop: ProjectFee_stddev_pop_order_by
  stddev_samp: ProjectFee_stddev_samp_order_by
  sum: ProjectFee_sum_order_by
  var_pop: ProjectFee_var_pop_order_by
  var_samp: ProjectFee_var_samp_order_by
  variance: ProjectFee_variance_order_by
}

"""
input type for inserting array relation for remote table "ProjectFee"
"""
input ProjectFee_arr_rel_insert_input {
  data: [ProjectFee_insert_input!]!

  """upsert condition"""
  on_conflict: ProjectFee_on_conflict
}

"""aggregate avg on columns"""
type ProjectFee_avg_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by avg() on columns of table "ProjectFee"
"""
input ProjectFee_avg_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
Boolean expression to filter rows from the table "ProjectFee". All fields are combined with a logical 'AND'.
"""
input ProjectFee_bool_exp {
  _and: [ProjectFee_bool_exp!]
  _not: ProjectFee_bool_exp
  _or: [ProjectFee_bool_exp!]
  amount: numeric_comparison_exp
  amountUSD: numeric_comparison_exp
  blockTimestamp: Int_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  module_id: String_comparison_exp
  recipient: String_comparison_exp
  token: Token_bool_exp
  token_id: String_comparison_exp
}

"""
unique or primary key constraints on table "ProjectFee"
"""
enum ProjectFee_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  ProjectFee_pkey
}

"""
input type for incrementing numeric columns in table "ProjectFee"
"""
input ProjectFee_inc_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
}

"""
input type for inserting data into table "ProjectFee"
"""
input ProjectFee_insert_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  recipient: String
  token: Token_obj_rel_insert_input
  token_id: String
}

"""aggregate max on columns"""
type ProjectFee_max_fields {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  recipient: String
  token_id: String
}

"""
order by max() on columns of table "ProjectFee"
"""
input ProjectFee_max_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  module_id: order_by
  recipient: order_by
  token_id: order_by
}

"""aggregate min on columns"""
type ProjectFee_min_fields {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  recipient: String
  token_id: String
}

"""
order by min() on columns of table "ProjectFee"
"""
input ProjectFee_min_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  module_id: order_by
  recipient: order_by
  token_id: order_by
}

"""
response of any mutation on the table "ProjectFee"
"""
type ProjectFee_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [ProjectFee!]!
}

"""
on_conflict condition type for table "ProjectFee"
"""
input ProjectFee_on_conflict {
  constraint: ProjectFee_constraint!
  update_columns: [ProjectFee_update_column!]! = []
  where: ProjectFee_bool_exp
}

"""Ordering options when selecting data from "ProjectFee"."""
input ProjectFee_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  module_id: order_by
  recipient: order_by
  token: Token_order_by
  token_id: order_by
}

"""primary key columns input for table: ProjectFee"""
input ProjectFee_pk_columns_input {
  id: String!
}

"""
select columns of table "ProjectFee"
"""
enum ProjectFee_select_column {
  """column name"""
  amount

  """column name"""
  amountUSD

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  module_id

  """column name"""
  recipient

  """column name"""
  token_id
}

"""
input type for updating data in table "ProjectFee"
"""
input ProjectFee_set_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  recipient: String
  token_id: String
}

"""aggregate stddev on columns"""
type ProjectFee_stddev_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by stddev() on columns of table "ProjectFee"
"""
input ProjectFee_stddev_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate stddev_pop on columns"""
type ProjectFee_stddev_pop_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by stddev_pop() on columns of table "ProjectFee"
"""
input ProjectFee_stddev_pop_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate stddev_samp on columns"""
type ProjectFee_stddev_samp_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by stddev_samp() on columns of table "ProjectFee"
"""
input ProjectFee_stddev_samp_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
Streaming cursor of the table "ProjectFee"
"""
input ProjectFee_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: ProjectFee_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input ProjectFee_stream_cursor_value_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  recipient: String
  token_id: String
}

"""aggregate sum on columns"""
type ProjectFee_sum_fields {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
}

"""
order by sum() on columns of table "ProjectFee"
"""
input ProjectFee_sum_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
update columns of table "ProjectFee"
"""
enum ProjectFee_update_column {
  """column name"""
  amount

  """column name"""
  amountUSD

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  module_id

  """column name"""
  recipient

  """column name"""
  token_id
}

input ProjectFee_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: ProjectFee_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: ProjectFee_set_input

  """filter the rows which have to be updated"""
  where: ProjectFee_bool_exp!
}

"""aggregate var_pop on columns"""
type ProjectFee_var_pop_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by var_pop() on columns of table "ProjectFee"
"""
input ProjectFee_var_pop_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate var_samp on columns"""
type ProjectFee_var_samp_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by var_samp() on columns of table "ProjectFee"
"""
input ProjectFee_var_samp_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate variance on columns"""
type ProjectFee_variance_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by variance() on columns of table "ProjectFee"
"""
input ProjectFee_variance_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
columns and relationships of "ProtocolFee"
"""
type ProtocolFee {
  amount: numeric!
  amountUSD: numeric!
  blockTimestamp: Int!
  chainId: Int!
  db_write_timestamp: timestamp
  id: String!
  module_id: String!
  source: feesource!

  """An object relationship"""
  token: Token
  token_id: String!
  treasury: String!
}

"""
aggregated selection of "ProtocolFee"
"""
type ProtocolFee_aggregate {
  aggregate: ProtocolFee_aggregate_fields
  nodes: [ProtocolFee!]!
}

input ProtocolFee_aggregate_bool_exp {
  count: ProtocolFee_aggregate_bool_exp_count
}

input ProtocolFee_aggregate_bool_exp_count {
  arguments: [ProtocolFee_select_column!]
  distinct: Boolean
  filter: ProtocolFee_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "ProtocolFee"
"""
type ProtocolFee_aggregate_fields {
  avg: ProtocolFee_avg_fields
  count(columns: [ProtocolFee_select_column!], distinct: Boolean): Int!
  max: ProtocolFee_max_fields
  min: ProtocolFee_min_fields
  stddev: ProtocolFee_stddev_fields
  stddev_pop: ProtocolFee_stddev_pop_fields
  stddev_samp: ProtocolFee_stddev_samp_fields
  sum: ProtocolFee_sum_fields
  var_pop: ProtocolFee_var_pop_fields
  var_samp: ProtocolFee_var_samp_fields
  variance: ProtocolFee_variance_fields
}

"""
order by aggregate values of table "ProtocolFee"
"""
input ProtocolFee_aggregate_order_by {
  avg: ProtocolFee_avg_order_by
  count: order_by
  max: ProtocolFee_max_order_by
  min: ProtocolFee_min_order_by
  stddev: ProtocolFee_stddev_order_by
  stddev_pop: ProtocolFee_stddev_pop_order_by
  stddev_samp: ProtocolFee_stddev_samp_order_by
  sum: ProtocolFee_sum_order_by
  var_pop: ProtocolFee_var_pop_order_by
  var_samp: ProtocolFee_var_samp_order_by
  variance: ProtocolFee_variance_order_by
}

"""
input type for inserting array relation for remote table "ProtocolFee"
"""
input ProtocolFee_arr_rel_insert_input {
  data: [ProtocolFee_insert_input!]!

  """upsert condition"""
  on_conflict: ProtocolFee_on_conflict
}

"""aggregate avg on columns"""
type ProtocolFee_avg_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by avg() on columns of table "ProtocolFee"
"""
input ProtocolFee_avg_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
Boolean expression to filter rows from the table "ProtocolFee". All fields are combined with a logical 'AND'.
"""
input ProtocolFee_bool_exp {
  _and: [ProtocolFee_bool_exp!]
  _not: ProtocolFee_bool_exp
  _or: [ProtocolFee_bool_exp!]
  amount: numeric_comparison_exp
  amountUSD: numeric_comparison_exp
  blockTimestamp: Int_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  module_id: String_comparison_exp
  source: feesource_comparison_exp
  token: Token_bool_exp
  token_id: String_comparison_exp
  treasury: String_comparison_exp
}

"""
unique or primary key constraints on table "ProtocolFee"
"""
enum ProtocolFee_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  ProtocolFee_pkey
}

"""
input type for incrementing numeric columns in table "ProtocolFee"
"""
input ProtocolFee_inc_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
}

"""
input type for inserting data into table "ProtocolFee"
"""
input ProtocolFee_insert_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  source: feesource
  token: Token_obj_rel_insert_input
  token_id: String
  treasury: String
}

"""aggregate max on columns"""
type ProtocolFee_max_fields {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  source: feesource
  token_id: String
  treasury: String
}

"""
order by max() on columns of table "ProtocolFee"
"""
input ProtocolFee_max_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  module_id: order_by
  source: order_by
  token_id: order_by
  treasury: order_by
}

"""aggregate min on columns"""
type ProtocolFee_min_fields {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  source: feesource
  token_id: String
  treasury: String
}

"""
order by min() on columns of table "ProtocolFee"
"""
input ProtocolFee_min_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  module_id: order_by
  source: order_by
  token_id: order_by
  treasury: order_by
}

"""
response of any mutation on the table "ProtocolFee"
"""
type ProtocolFee_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [ProtocolFee!]!
}

"""
on_conflict condition type for table "ProtocolFee"
"""
input ProtocolFee_on_conflict {
  constraint: ProtocolFee_constraint!
  update_columns: [ProtocolFee_update_column!]! = []
  where: ProtocolFee_bool_exp
}

"""Ordering options when selecting data from "ProtocolFee"."""
input ProtocolFee_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  module_id: order_by
  source: order_by
  token: Token_order_by
  token_id: order_by
  treasury: order_by
}

"""primary key columns input for table: ProtocolFee"""
input ProtocolFee_pk_columns_input {
  id: String!
}

"""
select columns of table "ProtocolFee"
"""
enum ProtocolFee_select_column {
  """column name"""
  amount

  """column name"""
  amountUSD

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  module_id

  """column name"""
  source

  """column name"""
  token_id

  """column name"""
  treasury
}

"""
input type for updating data in table "ProtocolFee"
"""
input ProtocolFee_set_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  source: feesource
  token_id: String
  treasury: String
}

"""aggregate stddev on columns"""
type ProtocolFee_stddev_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by stddev() on columns of table "ProtocolFee"
"""
input ProtocolFee_stddev_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate stddev_pop on columns"""
type ProtocolFee_stddev_pop_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by stddev_pop() on columns of table "ProtocolFee"
"""
input ProtocolFee_stddev_pop_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate stddev_samp on columns"""
type ProtocolFee_stddev_samp_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by stddev_samp() on columns of table "ProtocolFee"
"""
input ProtocolFee_stddev_samp_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
Streaming cursor of the table "ProtocolFee"
"""
input ProtocolFee_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: ProtocolFee_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input ProtocolFee_stream_cursor_value_input {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  module_id: String
  source: feesource
  token_id: String
  treasury: String
}

"""aggregate sum on columns"""
type ProtocolFee_sum_fields {
  amount: numeric
  amountUSD: numeric
  blockTimestamp: Int
  chainId: Int
}

"""
order by sum() on columns of table "ProtocolFee"
"""
input ProtocolFee_sum_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
update columns of table "ProtocolFee"
"""
enum ProtocolFee_update_column {
  """column name"""
  amount

  """column name"""
  amountUSD

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  module_id

  """column name"""
  source

  """column name"""
  token_id

  """column name"""
  treasury
}

input ProtocolFee_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: ProtocolFee_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: ProtocolFee_set_input

  """filter the rows which have to be updated"""
  where: ProtocolFee_bool_exp!
}

"""aggregate var_pop on columns"""
type ProtocolFee_var_pop_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by var_pop() on columns of table "ProtocolFee"
"""
input ProtocolFee_var_pop_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate var_samp on columns"""
type ProtocolFee_var_samp_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by var_samp() on columns of table "ProtocolFee"
"""
input ProtocolFee_var_samp_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""aggregate variance on columns"""
type ProtocolFee_variance_fields {
  amount: Float
  amountUSD: Float
  blockTimestamp: Float
  chainId: Float
}

"""
order by variance() on columns of table "ProtocolFee"
"""
input ProtocolFee_variance_order_by {
  amount: order_by
  amountUSD: order_by
  blockTimestamp: order_by
  chainId: order_by
}

"""
columns and relationships of "StreamingPaymentProcessor"
"""
type StreamingPaymentProcessor {
  chainId: Int!
  db_write_timestamp: timestamp
  id: String!

  """An array relationship"""
  vestings(
    """distinct select on columns"""
    distinct_on: [LinearVesting_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [LinearVesting_order_by!]

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): [LinearVesting!]!

  """An aggregate relationship"""
  vestings_aggregate(
    """distinct select on columns"""
    distinct_on: [LinearVesting_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [LinearVesting_order_by!]

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): LinearVesting_aggregate!

  """An object relationship"""
  workflow: Workflow
  workflow_id: String!
}

"""
aggregated selection of "StreamingPaymentProcessor"
"""
type StreamingPaymentProcessor_aggregate {
  aggregate: StreamingPaymentProcessor_aggregate_fields
  nodes: [StreamingPaymentProcessor!]!
}

"""
aggregate fields of "StreamingPaymentProcessor"
"""
type StreamingPaymentProcessor_aggregate_fields {
  avg: StreamingPaymentProcessor_avg_fields
  count(columns: [StreamingPaymentProcessor_select_column!], distinct: Boolean): Int!
  max: StreamingPaymentProcessor_max_fields
  min: StreamingPaymentProcessor_min_fields
  stddev: StreamingPaymentProcessor_stddev_fields
  stddev_pop: StreamingPaymentProcessor_stddev_pop_fields
  stddev_samp: StreamingPaymentProcessor_stddev_samp_fields
  sum: StreamingPaymentProcessor_sum_fields
  var_pop: StreamingPaymentProcessor_var_pop_fields
  var_samp: StreamingPaymentProcessor_var_samp_fields
  variance: StreamingPaymentProcessor_variance_fields
}

"""aggregate avg on columns"""
type StreamingPaymentProcessor_avg_fields {
  chainId: Float
}

"""
Boolean expression to filter rows from the table "StreamingPaymentProcessor". All fields are combined with a logical 'AND'.
"""
input StreamingPaymentProcessor_bool_exp {
  _and: [StreamingPaymentProcessor_bool_exp!]
  _not: StreamingPaymentProcessor_bool_exp
  _or: [StreamingPaymentProcessor_bool_exp!]
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  vestings: LinearVesting_bool_exp
  vestings_aggregate: LinearVesting_aggregate_bool_exp
  workflow: Workflow_bool_exp
  workflow_id: String_comparison_exp
}

"""
unique or primary key constraints on table "StreamingPaymentProcessor"
"""
enum StreamingPaymentProcessor_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  StreamingPaymentProcessor_pkey
}

"""
input type for incrementing numeric columns in table "StreamingPaymentProcessor"
"""
input StreamingPaymentProcessor_inc_input {
  chainId: Int
}

"""
input type for inserting data into table "StreamingPaymentProcessor"
"""
input StreamingPaymentProcessor_insert_input {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  vestings: LinearVesting_arr_rel_insert_input
  workflow: Workflow_obj_rel_insert_input
  workflow_id: String
}

"""aggregate max on columns"""
type StreamingPaymentProcessor_max_fields {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""aggregate min on columns"""
type StreamingPaymentProcessor_min_fields {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""
response of any mutation on the table "StreamingPaymentProcessor"
"""
type StreamingPaymentProcessor_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [StreamingPaymentProcessor!]!
}

"""
input type for inserting object relation for remote table "StreamingPaymentProcessor"
"""
input StreamingPaymentProcessor_obj_rel_insert_input {
  data: StreamingPaymentProcessor_insert_input!

  """upsert condition"""
  on_conflict: StreamingPaymentProcessor_on_conflict
}

"""
on_conflict condition type for table "StreamingPaymentProcessor"
"""
input StreamingPaymentProcessor_on_conflict {
  constraint: StreamingPaymentProcessor_constraint!
  update_columns: [StreamingPaymentProcessor_update_column!]! = []
  where: StreamingPaymentProcessor_bool_exp
}

"""Ordering options when selecting data from "StreamingPaymentProcessor"."""
input StreamingPaymentProcessor_order_by {
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  vestings_aggregate: LinearVesting_aggregate_order_by
  workflow: Workflow_order_by
  workflow_id: order_by
}

"""primary key columns input for table: StreamingPaymentProcessor"""
input StreamingPaymentProcessor_pk_columns_input {
  id: String!
}

"""
select columns of table "StreamingPaymentProcessor"
"""
enum StreamingPaymentProcessor_select_column {
  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  workflow_id
}

"""
input type for updating data in table "StreamingPaymentProcessor"
"""
input StreamingPaymentProcessor_set_input {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""aggregate stddev on columns"""
type StreamingPaymentProcessor_stddev_fields {
  chainId: Float
}

"""aggregate stddev_pop on columns"""
type StreamingPaymentProcessor_stddev_pop_fields {
  chainId: Float
}

"""aggregate stddev_samp on columns"""
type StreamingPaymentProcessor_stddev_samp_fields {
  chainId: Float
}

"""
Streaming cursor of the table "StreamingPaymentProcessor"
"""
input StreamingPaymentProcessor_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: StreamingPaymentProcessor_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input StreamingPaymentProcessor_stream_cursor_value_input {
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  workflow_id: String
}

"""aggregate sum on columns"""
type StreamingPaymentProcessor_sum_fields {
  chainId: Int
}

"""
update columns of table "StreamingPaymentProcessor"
"""
enum StreamingPaymentProcessor_update_column {
  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  workflow_id
}

input StreamingPaymentProcessor_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: StreamingPaymentProcessor_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: StreamingPaymentProcessor_set_input

  """filter the rows which have to be updated"""
  where: StreamingPaymentProcessor_bool_exp!
}

"""aggregate var_pop on columns"""
type StreamingPaymentProcessor_var_pop_fields {
  chainId: Float
}

"""aggregate var_samp on columns"""
type StreamingPaymentProcessor_var_samp_fields {
  chainId: Float
}

"""aggregate variance on columns"""
type StreamingPaymentProcessor_variance_fields {
  chainId: Float
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_array_comparison_exp {
  """is the array contained in the given array value"""
  _contained_in: [String!]

  """does the array contain the given value"""
  _contains: [String!]
  _eq: [String!]
  _gt: [String!]
  _gte: [String!]
  _in: [[String!]!]
  _is_null: Boolean
  _lt: [String!]
  _lte: [String!]
  _neq: [String!]
  _nin: [[String!]!]
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String

  """does the column match the given case-insensitive pattern"""
  _ilike: String
  _in: [String!]

  """
  does the column match the given POSIX regular expression, case insensitive
  """
  _iregex: String
  _is_null: Boolean

  """does the column match the given pattern"""
  _like: String
  _lt: String
  _lte: String
  _neq: String

  """does the column NOT match the given case-insensitive pattern"""
  _nilike: String
  _nin: [String!]

  """
  does the column NOT match the given POSIX regular expression, case insensitive
  """
  _niregex: String

  """does the column NOT match the given pattern"""
  _nlike: String

  """
  does the column NOT match the given POSIX regular expression, case sensitive
  """
  _nregex: String

  """does the column NOT match the given SQL regular expression"""
  _nsimilar: String

  """
  does the column match the given POSIX regular expression, case sensitive
  """
  _regex: String

  """does the column match the given SQL regular expression"""
  _similar: String
}

"""
columns and relationships of "Swap"
"""
type Swap {
  amountCOL: numeric!
  amountISS: numeric!
  blockTimestamp: Int!
  chainId: Int!

  """An object relationship"""
  collateralToken: Token
  collateralToken_id: String!
  db_write_timestamp: timestamp
  id: String!
  initiator: String!

  """An object relationship"""
  issuanceToken: Token
  issuanceToken_id: String!
  module_id: String!
  priceCOL: numeric!
  priceUSD: numeric!
  recipient: String!
  swapType: swaptype!
}

"""
aggregated selection of "Swap"
"""
type Swap_aggregate {
  aggregate: Swap_aggregate_fields
  nodes: [Swap!]!
}

input Swap_aggregate_bool_exp {
  count: Swap_aggregate_bool_exp_count
}

input Swap_aggregate_bool_exp_count {
  arguments: [Swap_select_column!]
  distinct: Boolean
  filter: Swap_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "Swap"
"""
type Swap_aggregate_fields {
  avg: Swap_avg_fields
  count(columns: [Swap_select_column!], distinct: Boolean): Int!
  max: Swap_max_fields
  min: Swap_min_fields
  stddev: Swap_stddev_fields
  stddev_pop: Swap_stddev_pop_fields
  stddev_samp: Swap_stddev_samp_fields
  sum: Swap_sum_fields
  var_pop: Swap_var_pop_fields
  var_samp: Swap_var_samp_fields
  variance: Swap_variance_fields
}

"""
order by aggregate values of table "Swap"
"""
input Swap_aggregate_order_by {
  avg: Swap_avg_order_by
  count: order_by
  max: Swap_max_order_by
  min: Swap_min_order_by
  stddev: Swap_stddev_order_by
  stddev_pop: Swap_stddev_pop_order_by
  stddev_samp: Swap_stddev_samp_order_by
  sum: Swap_sum_order_by
  var_pop: Swap_var_pop_order_by
  var_samp: Swap_var_samp_order_by
  variance: Swap_variance_order_by
}

"""
input type for inserting array relation for remote table "Swap"
"""
input Swap_arr_rel_insert_input {
  data: [Swap_insert_input!]!

  """upsert condition"""
  on_conflict: Swap_on_conflict
}

"""aggregate avg on columns"""
type Swap_avg_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by avg() on columns of table "Swap"
"""
input Swap_avg_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""
Boolean expression to filter rows from the table "Swap". All fields are combined with a logical 'AND'.
"""
input Swap_bool_exp {
  _and: [Swap_bool_exp!]
  _not: Swap_bool_exp
  _or: [Swap_bool_exp!]
  amountCOL: numeric_comparison_exp
  amountISS: numeric_comparison_exp
  blockTimestamp: Int_comparison_exp
  chainId: Int_comparison_exp
  collateralToken: Token_bool_exp
  collateralToken_id: String_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  initiator: String_comparison_exp
  issuanceToken: Token_bool_exp
  issuanceToken_id: String_comparison_exp
  module_id: String_comparison_exp
  priceCOL: numeric_comparison_exp
  priceUSD: numeric_comparison_exp
  recipient: String_comparison_exp
  swapType: swaptype_comparison_exp
}

"""
unique or primary key constraints on table "Swap"
"""
enum Swap_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  Swap_pkey
}

"""
input type for incrementing numeric columns in table "Swap"
"""
input Swap_inc_input {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  priceCOL: numeric
  priceUSD: numeric
}

"""
input type for inserting data into table "Swap"
"""
input Swap_insert_input {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  collateralToken: Token_obj_rel_insert_input
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  initiator: String
  issuanceToken: Token_obj_rel_insert_input
  issuanceToken_id: String
  module_id: String
  priceCOL: numeric
  priceUSD: numeric
  recipient: String
  swapType: swaptype
}

"""aggregate max on columns"""
type Swap_max_fields {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  initiator: String
  issuanceToken_id: String
  module_id: String
  priceCOL: numeric
  priceUSD: numeric
  recipient: String
  swapType: swaptype
}

"""
order by max() on columns of table "Swap"
"""
input Swap_max_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  collateralToken_id: order_by
  db_write_timestamp: order_by
  id: order_by
  initiator: order_by
  issuanceToken_id: order_by
  module_id: order_by
  priceCOL: order_by
  priceUSD: order_by
  recipient: order_by
  swapType: order_by
}

"""aggregate min on columns"""
type Swap_min_fields {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  initiator: String
  issuanceToken_id: String
  module_id: String
  priceCOL: numeric
  priceUSD: numeric
  recipient: String
  swapType: swaptype
}

"""
order by min() on columns of table "Swap"
"""
input Swap_min_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  collateralToken_id: order_by
  db_write_timestamp: order_by
  id: order_by
  initiator: order_by
  issuanceToken_id: order_by
  module_id: order_by
  priceCOL: order_by
  priceUSD: order_by
  recipient: order_by
  swapType: order_by
}

"""
response of any mutation on the table "Swap"
"""
type Swap_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [Swap!]!
}

"""
on_conflict condition type for table "Swap"
"""
input Swap_on_conflict {
  constraint: Swap_constraint!
  update_columns: [Swap_update_column!]! = []
  where: Swap_bool_exp
}

"""Ordering options when selecting data from "Swap"."""
input Swap_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  collateralToken: Token_order_by
  collateralToken_id: order_by
  db_write_timestamp: order_by
  id: order_by
  initiator: order_by
  issuanceToken: Token_order_by
  issuanceToken_id: order_by
  module_id: order_by
  priceCOL: order_by
  priceUSD: order_by
  recipient: order_by
  swapType: order_by
}

"""primary key columns input for table: Swap"""
input Swap_pk_columns_input {
  id: String!
}

"""
select columns of table "Swap"
"""
enum Swap_select_column {
  """column name"""
  amountCOL

  """column name"""
  amountISS

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  collateralToken_id

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  initiator

  """column name"""
  issuanceToken_id

  """column name"""
  module_id

  """column name"""
  priceCOL

  """column name"""
  priceUSD

  """column name"""
  recipient

  """column name"""
  swapType
}

"""
input type for updating data in table "Swap"
"""
input Swap_set_input {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  initiator: String
  issuanceToken_id: String
  module_id: String
  priceCOL: numeric
  priceUSD: numeric
  recipient: String
  swapType: swaptype
}

"""aggregate stddev on columns"""
type Swap_stddev_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by stddev() on columns of table "Swap"
"""
input Swap_stddev_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""aggregate stddev_pop on columns"""
type Swap_stddev_pop_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by stddev_pop() on columns of table "Swap"
"""
input Swap_stddev_pop_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""aggregate stddev_samp on columns"""
type Swap_stddev_samp_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by stddev_samp() on columns of table "Swap"
"""
input Swap_stddev_samp_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""
Streaming cursor of the table "Swap"
"""
input Swap_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: Swap_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input Swap_stream_cursor_value_input {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  collateralToken_id: String
  db_write_timestamp: timestamp
  id: String
  initiator: String
  issuanceToken_id: String
  module_id: String
  priceCOL: numeric
  priceUSD: numeric
  recipient: String
  swapType: swaptype
}

"""aggregate sum on columns"""
type Swap_sum_fields {
  amountCOL: numeric
  amountISS: numeric
  blockTimestamp: Int
  chainId: Int
  priceCOL: numeric
  priceUSD: numeric
}

"""
order by sum() on columns of table "Swap"
"""
input Swap_sum_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""
update columns of table "Swap"
"""
enum Swap_update_column {
  """column name"""
  amountCOL

  """column name"""
  amountISS

  """column name"""
  blockTimestamp

  """column name"""
  chainId

  """column name"""
  collateralToken_id

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  initiator

  """column name"""
  issuanceToken_id

  """column name"""
  module_id

  """column name"""
  priceCOL

  """column name"""
  priceUSD

  """column name"""
  recipient

  """column name"""
  swapType
}

input Swap_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: Swap_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: Swap_set_input

  """filter the rows which have to be updated"""
  where: Swap_bool_exp!
}

"""aggregate var_pop on columns"""
type Swap_var_pop_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by var_pop() on columns of table "Swap"
"""
input Swap_var_pop_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""aggregate var_samp on columns"""
type Swap_var_samp_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by var_samp() on columns of table "Swap"
"""
input Swap_var_samp_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""aggregate variance on columns"""
type Swap_variance_fields {
  amountCOL: Float
  amountISS: Float
  blockTimestamp: Float
  chainId: Float
  priceCOL: Float
  priceUSD: Float
}

"""
order by variance() on columns of table "Swap"
"""
input Swap_variance_order_by {
  amountCOL: order_by
  amountISS: order_by
  blockTimestamp: order_by
  chainId: order_by
  priceCOL: order_by
  priceUSD: order_by
}

"""
columns and relationships of "Token"
"""
type Token {
  address: String!
  chainId: Int!
  db_write_timestamp: timestamp
  decimals: Int!
  id: String!
  name: String!
  priceUSD: numeric!
  symbol: String!
  totalSupply: numeric!
}

"""
aggregated selection of "Token"
"""
type Token_aggregate {
  aggregate: Token_aggregate_fields
  nodes: [Token!]!
}

"""
aggregate fields of "Token"
"""
type Token_aggregate_fields {
  avg: Token_avg_fields
  count(columns: [Token_select_column!], distinct: Boolean): Int!
  max: Token_max_fields
  min: Token_min_fields
  stddev: Token_stddev_fields
  stddev_pop: Token_stddev_pop_fields
  stddev_samp: Token_stddev_samp_fields
  sum: Token_sum_fields
  var_pop: Token_var_pop_fields
  var_samp: Token_var_samp_fields
  variance: Token_variance_fields
}

"""aggregate avg on columns"""
type Token_avg_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""
Boolean expression to filter rows from the table "Token". All fields are combined with a logical 'AND'.
"""
input Token_bool_exp {
  _and: [Token_bool_exp!]
  _not: Token_bool_exp
  _or: [Token_bool_exp!]
  address: String_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  decimals: Int_comparison_exp
  id: String_comparison_exp
  name: String_comparison_exp
  priceUSD: numeric_comparison_exp
  symbol: String_comparison_exp
  totalSupply: numeric_comparison_exp
}

"""
unique or primary key constraints on table "Token"
"""
enum Token_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  Token_pkey
}

"""
input type for incrementing numeric columns in table "Token"
"""
input Token_inc_input {
  chainId: Int
  decimals: Int
  priceUSD: numeric
  totalSupply: numeric
}

"""
input type for inserting data into table "Token"
"""
input Token_insert_input {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  decimals: Int
  id: String
  name: String
  priceUSD: numeric
  symbol: String
  totalSupply: numeric
}

"""aggregate max on columns"""
type Token_max_fields {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  decimals: Int
  id: String
  name: String
  priceUSD: numeric
  symbol: String
  totalSupply: numeric
}

"""aggregate min on columns"""
type Token_min_fields {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  decimals: Int
  id: String
  name: String
  priceUSD: numeric
  symbol: String
  totalSupply: numeric
}

"""
response of any mutation on the table "Token"
"""
type Token_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [Token!]!
}

"""
input type for inserting object relation for remote table "Token"
"""
input Token_obj_rel_insert_input {
  data: Token_insert_input!

  """upsert condition"""
  on_conflict: Token_on_conflict
}

"""
on_conflict condition type for table "Token"
"""
input Token_on_conflict {
  constraint: Token_constraint!
  update_columns: [Token_update_column!]! = []
  where: Token_bool_exp
}

"""Ordering options when selecting data from "Token"."""
input Token_order_by {
  address: order_by
  chainId: order_by
  db_write_timestamp: order_by
  decimals: order_by
  id: order_by
  name: order_by
  priceUSD: order_by
  symbol: order_by
  totalSupply: order_by
}

"""primary key columns input for table: Token"""
input Token_pk_columns_input {
  id: String!
}

"""
select columns of table "Token"
"""
enum Token_select_column {
  """column name"""
  address

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  decimals

  """column name"""
  id

  """column name"""
  name

  """column name"""
  priceUSD

  """column name"""
  symbol

  """column name"""
  totalSupply
}

"""
input type for updating data in table "Token"
"""
input Token_set_input {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  decimals: Int
  id: String
  name: String
  priceUSD: numeric
  symbol: String
  totalSupply: numeric
}

"""aggregate stddev on columns"""
type Token_stddev_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""aggregate stddev_pop on columns"""
type Token_stddev_pop_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""aggregate stddev_samp on columns"""
type Token_stddev_samp_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""
Streaming cursor of the table "Token"
"""
input Token_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: Token_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input Token_stream_cursor_value_input {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  decimals: Int
  id: String
  name: String
  priceUSD: numeric
  symbol: String
  totalSupply: numeric
}

"""aggregate sum on columns"""
type Token_sum_fields {
  chainId: Int
  decimals: Int
  priceUSD: numeric
  totalSupply: numeric
}

"""
update columns of table "Token"
"""
enum Token_update_column {
  """column name"""
  address

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  decimals

  """column name"""
  id

  """column name"""
  name

  """column name"""
  priceUSD

  """column name"""
  symbol

  """column name"""
  totalSupply
}

input Token_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: Token_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: Token_set_input

  """filter the rows which have to be updated"""
  where: Token_bool_exp!
}

"""aggregate var_pop on columns"""
type Token_var_pop_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""aggregate var_samp on columns"""
type Token_var_samp_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""aggregate variance on columns"""
type Token_variance_fields {
  chainId: Float
  decimals: Float
  priceUSD: Float
  totalSupply: Float
}

"""
columns and relationships of "Transfer"
"""
type Transfer {
  amount: numeric!
  blockTimestamp: Int!
  db_write_timestamp: timestamp

  """An object relationship"""
  depositVault: DepositVault
  depositVault_id: String!
  id: String!
  recipient: String!
}

"""
aggregated selection of "Transfer"
"""
type Transfer_aggregate {
  aggregate: Transfer_aggregate_fields
  nodes: [Transfer!]!
}

input Transfer_aggregate_bool_exp {
  count: Transfer_aggregate_bool_exp_count
}

input Transfer_aggregate_bool_exp_count {
  arguments: [Transfer_select_column!]
  distinct: Boolean
  filter: Transfer_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "Transfer"
"""
type Transfer_aggregate_fields {
  avg: Transfer_avg_fields
  count(columns: [Transfer_select_column!], distinct: Boolean): Int!
  max: Transfer_max_fields
  min: Transfer_min_fields
  stddev: Transfer_stddev_fields
  stddev_pop: Transfer_stddev_pop_fields
  stddev_samp: Transfer_stddev_samp_fields
  sum: Transfer_sum_fields
  var_pop: Transfer_var_pop_fields
  var_samp: Transfer_var_samp_fields
  variance: Transfer_variance_fields
}

"""
order by aggregate values of table "Transfer"
"""
input Transfer_aggregate_order_by {
  avg: Transfer_avg_order_by
  count: order_by
  max: Transfer_max_order_by
  min: Transfer_min_order_by
  stddev: Transfer_stddev_order_by
  stddev_pop: Transfer_stddev_pop_order_by
  stddev_samp: Transfer_stddev_samp_order_by
  sum: Transfer_sum_order_by
  var_pop: Transfer_var_pop_order_by
  var_samp: Transfer_var_samp_order_by
  variance: Transfer_variance_order_by
}

"""
input type for inserting array relation for remote table "Transfer"
"""
input Transfer_arr_rel_insert_input {
  data: [Transfer_insert_input!]!

  """upsert condition"""
  on_conflict: Transfer_on_conflict
}

"""aggregate avg on columns"""
type Transfer_avg_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by avg() on columns of table "Transfer"
"""
input Transfer_avg_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
Boolean expression to filter rows from the table "Transfer". All fields are combined with a logical 'AND'.
"""
input Transfer_bool_exp {
  _and: [Transfer_bool_exp!]
  _not: Transfer_bool_exp
  _or: [Transfer_bool_exp!]
  amount: numeric_comparison_exp
  blockTimestamp: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  depositVault: DepositVault_bool_exp
  depositVault_id: String_comparison_exp
  id: String_comparison_exp
  recipient: String_comparison_exp
}

"""
unique or primary key constraints on table "Transfer"
"""
enum Transfer_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  Transfer_pkey
}

"""
input type for incrementing numeric columns in table "Transfer"
"""
input Transfer_inc_input {
  amount: numeric
  blockTimestamp: Int
}

"""
input type for inserting data into table "Transfer"
"""
input Transfer_insert_input {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault: DepositVault_obj_rel_insert_input
  depositVault_id: String
  id: String
  recipient: String
}

"""aggregate max on columns"""
type Transfer_max_fields {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  id: String
  recipient: String
}

"""
order by max() on columns of table "Transfer"
"""
input Transfer_max_order_by {
  amount: order_by
  blockTimestamp: order_by
  db_write_timestamp: order_by
  depositVault_id: order_by
  id: order_by
  recipient: order_by
}

"""aggregate min on columns"""
type Transfer_min_fields {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  id: String
  recipient: String
}

"""
order by min() on columns of table "Transfer"
"""
input Transfer_min_order_by {
  amount: order_by
  blockTimestamp: order_by
  db_write_timestamp: order_by
  depositVault_id: order_by
  id: order_by
  recipient: order_by
}

"""
response of any mutation on the table "Transfer"
"""
type Transfer_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [Transfer!]!
}

"""
on_conflict condition type for table "Transfer"
"""
input Transfer_on_conflict {
  constraint: Transfer_constraint!
  update_columns: [Transfer_update_column!]! = []
  where: Transfer_bool_exp
}

"""Ordering options when selecting data from "Transfer"."""
input Transfer_order_by {
  amount: order_by
  blockTimestamp: order_by
  db_write_timestamp: order_by
  depositVault: DepositVault_order_by
  depositVault_id: order_by
  id: order_by
  recipient: order_by
}

"""primary key columns input for table: Transfer"""
input Transfer_pk_columns_input {
  id: String!
}

"""
select columns of table "Transfer"
"""
enum Transfer_select_column {
  """column name"""
  amount

  """column name"""
  blockTimestamp

  """column name"""
  db_write_timestamp

  """column name"""
  depositVault_id

  """column name"""
  id

  """column name"""
  recipient
}

"""
input type for updating data in table "Transfer"
"""
input Transfer_set_input {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  id: String
  recipient: String
}

"""aggregate stddev on columns"""
type Transfer_stddev_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by stddev() on columns of table "Transfer"
"""
input Transfer_stddev_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate stddev_pop on columns"""
type Transfer_stddev_pop_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by stddev_pop() on columns of table "Transfer"
"""
input Transfer_stddev_pop_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate stddev_samp on columns"""
type Transfer_stddev_samp_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by stddev_samp() on columns of table "Transfer"
"""
input Transfer_stddev_samp_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
Streaming cursor of the table "Transfer"
"""
input Transfer_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: Transfer_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input Transfer_stream_cursor_value_input {
  amount: numeric
  blockTimestamp: Int
  db_write_timestamp: timestamp
  depositVault_id: String
  id: String
  recipient: String
}

"""aggregate sum on columns"""
type Transfer_sum_fields {
  amount: numeric
  blockTimestamp: Int
}

"""
order by sum() on columns of table "Transfer"
"""
input Transfer_sum_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
update columns of table "Transfer"
"""
enum Transfer_update_column {
  """column name"""
  amount

  """column name"""
  blockTimestamp

  """column name"""
  db_write_timestamp

  """column name"""
  depositVault_id

  """column name"""
  id

  """column name"""
  recipient
}

input Transfer_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: Transfer_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: Transfer_set_input

  """filter the rows which have to be updated"""
  where: Transfer_bool_exp!
}

"""aggregate var_pop on columns"""
type Transfer_var_pop_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by var_pop() on columns of table "Transfer"
"""
input Transfer_var_pop_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate var_samp on columns"""
type Transfer_var_samp_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by var_samp() on columns of table "Transfer"
"""
input Transfer_var_samp_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""aggregate variance on columns"""
type Transfer_variance_fields {
  amount: Float
  blockTimestamp: Float
}

"""
order by variance() on columns of table "Transfer"
"""
input Transfer_variance_order_by {
  amount: order_by
  blockTimestamp: order_by
}

"""
columns and relationships of "Workflow"
"""
type Workflow {
  """An object relationship"""
  authorizer: WorkflowModule
  authorizer_id: String!
  chainId: Int!
  db_write_timestamp: timestamp

  """An object relationship"""
  fundingManager: WorkflowModule
  fundingManager_id: String!
  id: String!
  optionalModules: [String!]
  orchestrator: String!

  """An object relationship"""
  paymentProcessor: WorkflowModule
  paymentProcessor_id: String!
}

"""
columns and relationships of "WorkflowModule"
"""
type WorkflowModule {
  address: String!
  chainId: Int!
  db_write_timestamp: timestamp
  id: String!

  """An object relationship"""
  moduleType: WorkflowModuleType
  moduleType_id: String!
  orchestrator: String!
}

"""
columns and relationships of "WorkflowModuleType"
"""
type WorkflowModuleType {
  beacon: String!
  chainId: Int!
  db_write_timestamp: timestamp
  id: String!
  majorVersion: numeric!
  minorVersion: numeric!
  name: String!
  patchVersion: numeric!
  url: String!
}

"""
aggregated selection of "WorkflowModuleType"
"""
type WorkflowModuleType_aggregate {
  aggregate: WorkflowModuleType_aggregate_fields
  nodes: [WorkflowModuleType!]!
}

"""
aggregate fields of "WorkflowModuleType"
"""
type WorkflowModuleType_aggregate_fields {
  avg: WorkflowModuleType_avg_fields
  count(columns: [WorkflowModuleType_select_column!], distinct: Boolean): Int!
  max: WorkflowModuleType_max_fields
  min: WorkflowModuleType_min_fields
  stddev: WorkflowModuleType_stddev_fields
  stddev_pop: WorkflowModuleType_stddev_pop_fields
  stddev_samp: WorkflowModuleType_stddev_samp_fields
  sum: WorkflowModuleType_sum_fields
  var_pop: WorkflowModuleType_var_pop_fields
  var_samp: WorkflowModuleType_var_samp_fields
  variance: WorkflowModuleType_variance_fields
}

"""aggregate avg on columns"""
type WorkflowModuleType_avg_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""
Boolean expression to filter rows from the table "WorkflowModuleType". All fields are combined with a logical 'AND'.
"""
input WorkflowModuleType_bool_exp {
  _and: [WorkflowModuleType_bool_exp!]
  _not: WorkflowModuleType_bool_exp
  _or: [WorkflowModuleType_bool_exp!]
  beacon: String_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  majorVersion: numeric_comparison_exp
  minorVersion: numeric_comparison_exp
  name: String_comparison_exp
  patchVersion: numeric_comparison_exp
  url: String_comparison_exp
}

"""
unique or primary key constraints on table "WorkflowModuleType"
"""
enum WorkflowModuleType_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  WorkflowModuleType_pkey
}

"""
input type for incrementing numeric columns in table "WorkflowModuleType"
"""
input WorkflowModuleType_inc_input {
  chainId: Int
  majorVersion: numeric
  minorVersion: numeric
  patchVersion: numeric
}

"""
input type for inserting data into table "WorkflowModuleType"
"""
input WorkflowModuleType_insert_input {
  beacon: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  majorVersion: numeric
  minorVersion: numeric
  name: String
  patchVersion: numeric
  url: String
}

"""aggregate max on columns"""
type WorkflowModuleType_max_fields {
  beacon: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  majorVersion: numeric
  minorVersion: numeric
  name: String
  patchVersion: numeric
  url: String
}

"""aggregate min on columns"""
type WorkflowModuleType_min_fields {
  beacon: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  majorVersion: numeric
  minorVersion: numeric
  name: String
  patchVersion: numeric
  url: String
}

"""
response of any mutation on the table "WorkflowModuleType"
"""
type WorkflowModuleType_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [WorkflowModuleType!]!
}

"""
input type for inserting object relation for remote table "WorkflowModuleType"
"""
input WorkflowModuleType_obj_rel_insert_input {
  data: WorkflowModuleType_insert_input!

  """upsert condition"""
  on_conflict: WorkflowModuleType_on_conflict
}

"""
on_conflict condition type for table "WorkflowModuleType"
"""
input WorkflowModuleType_on_conflict {
  constraint: WorkflowModuleType_constraint!
  update_columns: [WorkflowModuleType_update_column!]! = []
  where: WorkflowModuleType_bool_exp
}

"""Ordering options when selecting data from "WorkflowModuleType"."""
input WorkflowModuleType_order_by {
  beacon: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  majorVersion: order_by
  minorVersion: order_by
  name: order_by
  patchVersion: order_by
  url: order_by
}

"""primary key columns input for table: WorkflowModuleType"""
input WorkflowModuleType_pk_columns_input {
  id: String!
}

"""
select columns of table "WorkflowModuleType"
"""
enum WorkflowModuleType_select_column {
  """column name"""
  beacon

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  majorVersion

  """column name"""
  minorVersion

  """column name"""
  name

  """column name"""
  patchVersion

  """column name"""
  url
}

"""
input type for updating data in table "WorkflowModuleType"
"""
input WorkflowModuleType_set_input {
  beacon: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  majorVersion: numeric
  minorVersion: numeric
  name: String
  patchVersion: numeric
  url: String
}

"""aggregate stddev on columns"""
type WorkflowModuleType_stddev_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""aggregate stddev_pop on columns"""
type WorkflowModuleType_stddev_pop_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""aggregate stddev_samp on columns"""
type WorkflowModuleType_stddev_samp_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""
Streaming cursor of the table "WorkflowModuleType"
"""
input WorkflowModuleType_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: WorkflowModuleType_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input WorkflowModuleType_stream_cursor_value_input {
  beacon: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  majorVersion: numeric
  minorVersion: numeric
  name: String
  patchVersion: numeric
  url: String
}

"""aggregate sum on columns"""
type WorkflowModuleType_sum_fields {
  chainId: Int
  majorVersion: numeric
  minorVersion: numeric
  patchVersion: numeric
}

"""
update columns of table "WorkflowModuleType"
"""
enum WorkflowModuleType_update_column {
  """column name"""
  beacon

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  majorVersion

  """column name"""
  minorVersion

  """column name"""
  name

  """column name"""
  patchVersion

  """column name"""
  url
}

input WorkflowModuleType_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: WorkflowModuleType_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: WorkflowModuleType_set_input

  """filter the rows which have to be updated"""
  where: WorkflowModuleType_bool_exp!
}

"""aggregate var_pop on columns"""
type WorkflowModuleType_var_pop_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""aggregate var_samp on columns"""
type WorkflowModuleType_var_samp_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""aggregate variance on columns"""
type WorkflowModuleType_variance_fields {
  chainId: Float
  majorVersion: Float
  minorVersion: Float
  patchVersion: Float
}

"""
aggregated selection of "WorkflowModule"
"""
type WorkflowModule_aggregate {
  aggregate: WorkflowModule_aggregate_fields
  nodes: [WorkflowModule!]!
}

"""
aggregate fields of "WorkflowModule"
"""
type WorkflowModule_aggregate_fields {
  avg: WorkflowModule_avg_fields
  count(columns: [WorkflowModule_select_column!], distinct: Boolean): Int!
  max: WorkflowModule_max_fields
  min: WorkflowModule_min_fields
  stddev: WorkflowModule_stddev_fields
  stddev_pop: WorkflowModule_stddev_pop_fields
  stddev_samp: WorkflowModule_stddev_samp_fields
  sum: WorkflowModule_sum_fields
  var_pop: WorkflowModule_var_pop_fields
  var_samp: WorkflowModule_var_samp_fields
  variance: WorkflowModule_variance_fields
}

"""aggregate avg on columns"""
type WorkflowModule_avg_fields {
  chainId: Float
}

"""
Boolean expression to filter rows from the table "WorkflowModule". All fields are combined with a logical 'AND'.
"""
input WorkflowModule_bool_exp {
  _and: [WorkflowModule_bool_exp!]
  _not: WorkflowModule_bool_exp
  _or: [WorkflowModule_bool_exp!]
  address: String_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  id: String_comparison_exp
  moduleType: WorkflowModuleType_bool_exp
  moduleType_id: String_comparison_exp
  orchestrator: String_comparison_exp
}

"""
unique or primary key constraints on table "WorkflowModule"
"""
enum WorkflowModule_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  WorkflowModule_pkey
}

"""
input type for incrementing numeric columns in table "WorkflowModule"
"""
input WorkflowModule_inc_input {
  chainId: Int
}

"""
input type for inserting data into table "WorkflowModule"
"""
input WorkflowModule_insert_input {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  moduleType: WorkflowModuleType_obj_rel_insert_input
  moduleType_id: String
  orchestrator: String
}

"""aggregate max on columns"""
type WorkflowModule_max_fields {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  moduleType_id: String
  orchestrator: String
}

"""aggregate min on columns"""
type WorkflowModule_min_fields {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  moduleType_id: String
  orchestrator: String
}

"""
response of any mutation on the table "WorkflowModule"
"""
type WorkflowModule_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [WorkflowModule!]!
}

"""
input type for inserting object relation for remote table "WorkflowModule"
"""
input WorkflowModule_obj_rel_insert_input {
  data: WorkflowModule_insert_input!

  """upsert condition"""
  on_conflict: WorkflowModule_on_conflict
}

"""
on_conflict condition type for table "WorkflowModule"
"""
input WorkflowModule_on_conflict {
  constraint: WorkflowModule_constraint!
  update_columns: [WorkflowModule_update_column!]! = []
  where: WorkflowModule_bool_exp
}

"""Ordering options when selecting data from "WorkflowModule"."""
input WorkflowModule_order_by {
  address: order_by
  chainId: order_by
  db_write_timestamp: order_by
  id: order_by
  moduleType: WorkflowModuleType_order_by
  moduleType_id: order_by
  orchestrator: order_by
}

"""primary key columns input for table: WorkflowModule"""
input WorkflowModule_pk_columns_input {
  id: String!
}

"""
select columns of table "WorkflowModule"
"""
enum WorkflowModule_select_column {
  """column name"""
  address

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  moduleType_id

  """column name"""
  orchestrator
}

"""
input type for updating data in table "WorkflowModule"
"""
input WorkflowModule_set_input {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  moduleType_id: String
  orchestrator: String
}

"""aggregate stddev on columns"""
type WorkflowModule_stddev_fields {
  chainId: Float
}

"""aggregate stddev_pop on columns"""
type WorkflowModule_stddev_pop_fields {
  chainId: Float
}

"""aggregate stddev_samp on columns"""
type WorkflowModule_stddev_samp_fields {
  chainId: Float
}

"""
Streaming cursor of the table "WorkflowModule"
"""
input WorkflowModule_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: WorkflowModule_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input WorkflowModule_stream_cursor_value_input {
  address: String
  chainId: Int
  db_write_timestamp: timestamp
  id: String
  moduleType_id: String
  orchestrator: String
}

"""aggregate sum on columns"""
type WorkflowModule_sum_fields {
  chainId: Int
}

"""
update columns of table "WorkflowModule"
"""
enum WorkflowModule_update_column {
  """column name"""
  address

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  id

  """column name"""
  moduleType_id

  """column name"""
  orchestrator
}

input WorkflowModule_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: WorkflowModule_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: WorkflowModule_set_input

  """filter the rows which have to be updated"""
  where: WorkflowModule_bool_exp!
}

"""aggregate var_pop on columns"""
type WorkflowModule_var_pop_fields {
  chainId: Float
}

"""aggregate var_samp on columns"""
type WorkflowModule_var_samp_fields {
  chainId: Float
}

"""aggregate variance on columns"""
type WorkflowModule_variance_fields {
  chainId: Float
}

"""
aggregated selection of "Workflow"
"""
type Workflow_aggregate {
  aggregate: Workflow_aggregate_fields
  nodes: [Workflow!]!
}

"""
aggregate fields of "Workflow"
"""
type Workflow_aggregate_fields {
  avg: Workflow_avg_fields
  count(columns: [Workflow_select_column!], distinct: Boolean): Int!
  max: Workflow_max_fields
  min: Workflow_min_fields
  stddev: Workflow_stddev_fields
  stddev_pop: Workflow_stddev_pop_fields
  stddev_samp: Workflow_stddev_samp_fields
  sum: Workflow_sum_fields
  var_pop: Workflow_var_pop_fields
  var_samp: Workflow_var_samp_fields
  variance: Workflow_variance_fields
}

"""aggregate avg on columns"""
type Workflow_avg_fields {
  chainId: Float
}

"""
Boolean expression to filter rows from the table "Workflow". All fields are combined with a logical 'AND'.
"""
input Workflow_bool_exp {
  _and: [Workflow_bool_exp!]
  _not: Workflow_bool_exp
  _or: [Workflow_bool_exp!]
  authorizer: WorkflowModule_bool_exp
  authorizer_id: String_comparison_exp
  chainId: Int_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  fundingManager: WorkflowModule_bool_exp
  fundingManager_id: String_comparison_exp
  id: String_comparison_exp
  optionalModules: String_array_comparison_exp
  orchestrator: String_comparison_exp
  paymentProcessor: WorkflowModule_bool_exp
  paymentProcessor_id: String_comparison_exp
}

"""
unique or primary key constraints on table "Workflow"
"""
enum Workflow_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  Workflow_pkey
}

"""
input type for incrementing numeric columns in table "Workflow"
"""
input Workflow_inc_input {
  chainId: Int
}

"""
input type for inserting data into table "Workflow"
"""
input Workflow_insert_input {
  authorizer: WorkflowModule_obj_rel_insert_input
  authorizer_id: String
  chainId: Int
  db_write_timestamp: timestamp
  fundingManager: WorkflowModule_obj_rel_insert_input
  fundingManager_id: String
  id: String
  optionalModules: [String!]
  orchestrator: String
  paymentProcessor: WorkflowModule_obj_rel_insert_input
  paymentProcessor_id: String
}

"""aggregate max on columns"""
type Workflow_max_fields {
  authorizer_id: String
  chainId: Int
  db_write_timestamp: timestamp
  fundingManager_id: String
  id: String
  optionalModules: [String!]
  orchestrator: String
  paymentProcessor_id: String
}

"""aggregate min on columns"""
type Workflow_min_fields {
  authorizer_id: String
  chainId: Int
  db_write_timestamp: timestamp
  fundingManager_id: String
  id: String
  optionalModules: [String!]
  orchestrator: String
  paymentProcessor_id: String
}

"""
response of any mutation on the table "Workflow"
"""
type Workflow_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [Workflow!]!
}

"""
input type for inserting object relation for remote table "Workflow"
"""
input Workflow_obj_rel_insert_input {
  data: Workflow_insert_input!

  """upsert condition"""
  on_conflict: Workflow_on_conflict
}

"""
on_conflict condition type for table "Workflow"
"""
input Workflow_on_conflict {
  constraint: Workflow_constraint!
  update_columns: [Workflow_update_column!]! = []
  where: Workflow_bool_exp
}

"""Ordering options when selecting data from "Workflow"."""
input Workflow_order_by {
  authorizer: WorkflowModule_order_by
  authorizer_id: order_by
  chainId: order_by
  db_write_timestamp: order_by
  fundingManager: WorkflowModule_order_by
  fundingManager_id: order_by
  id: order_by
  optionalModules: order_by
  orchestrator: order_by
  paymentProcessor: WorkflowModule_order_by
  paymentProcessor_id: order_by
}

"""primary key columns input for table: Workflow"""
input Workflow_pk_columns_input {
  id: String!
}

"""
select columns of table "Workflow"
"""
enum Workflow_select_column {
  """column name"""
  authorizer_id

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  fundingManager_id

  """column name"""
  id

  """column name"""
  optionalModules

  """column name"""
  orchestrator

  """column name"""
  paymentProcessor_id
}

"""
input type for updating data in table "Workflow"
"""
input Workflow_set_input {
  authorizer_id: String
  chainId: Int
  db_write_timestamp: timestamp
  fundingManager_id: String
  id: String
  optionalModules: [String!]
  orchestrator: String
  paymentProcessor_id: String
}

"""aggregate stddev on columns"""
type Workflow_stddev_fields {
  chainId: Float
}

"""aggregate stddev_pop on columns"""
type Workflow_stddev_pop_fields {
  chainId: Float
}

"""aggregate stddev_samp on columns"""
type Workflow_stddev_samp_fields {
  chainId: Float
}

"""
Streaming cursor of the table "Workflow"
"""
input Workflow_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: Workflow_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input Workflow_stream_cursor_value_input {
  authorizer_id: String
  chainId: Int
  db_write_timestamp: timestamp
  fundingManager_id: String
  id: String
  optionalModules: [String!]
  orchestrator: String
  paymentProcessor_id: String
}

"""aggregate sum on columns"""
type Workflow_sum_fields {
  chainId: Int
}

"""
update columns of table "Workflow"
"""
enum Workflow_update_column {
  """column name"""
  authorizer_id

  """column name"""
  chainId

  """column name"""
  db_write_timestamp

  """column name"""
  fundingManager_id

  """column name"""
  id

  """column name"""
  optionalModules

  """column name"""
  orchestrator

  """column name"""
  paymentProcessor_id
}

input Workflow_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: Workflow_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: Workflow_set_input

  """filter the rows which have to be updated"""
  where: Workflow_bool_exp!
}

"""aggregate var_pop on columns"""
type Workflow_var_pop_fields {
  chainId: Float
}

"""aggregate var_samp on columns"""
type Workflow_var_samp_fields {
  chainId: Float
}

"""aggregate variance on columns"""
type Workflow_variance_fields {
  chainId: Float
}

"""
columns and relationships of "chain_metadata"
"""
type chain_metadata {
  block_height: Int!
  chain_id: Int!
  end_block: Int
  first_event_block_number: Int
  is_hyper_sync: Boolean!
  latest_fetched_block_number: Int!
  latest_processed_block: Int
  num_batches_fetched: Int!
  num_events_processed: Int
  start_block: Int!
  timestamp_caught_up_to_head_or_endblock: timestamptz
}

"""
aggregated selection of "chain_metadata"
"""
type chain_metadata_aggregate {
  aggregate: chain_metadata_aggregate_fields
  nodes: [chain_metadata!]!
}

"""
aggregate fields of "chain_metadata"
"""
type chain_metadata_aggregate_fields {
  avg: chain_metadata_avg_fields
  count(columns: [chain_metadata_select_column!], distinct: Boolean): Int!
  max: chain_metadata_max_fields
  min: chain_metadata_min_fields
  stddev: chain_metadata_stddev_fields
  stddev_pop: chain_metadata_stddev_pop_fields
  stddev_samp: chain_metadata_stddev_samp_fields
  sum: chain_metadata_sum_fields
  var_pop: chain_metadata_var_pop_fields
  var_samp: chain_metadata_var_samp_fields
  variance: chain_metadata_variance_fields
}

"""aggregate avg on columns"""
type chain_metadata_avg_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

"""
Boolean expression to filter rows from the table "chain_metadata". All fields are combined with a logical 'AND'.
"""
input chain_metadata_bool_exp {
  _and: [chain_metadata_bool_exp!]
  _not: chain_metadata_bool_exp
  _or: [chain_metadata_bool_exp!]
  block_height: Int_comparison_exp
  chain_id: Int_comparison_exp
  end_block: Int_comparison_exp
  first_event_block_number: Int_comparison_exp
  is_hyper_sync: Boolean_comparison_exp
  latest_fetched_block_number: Int_comparison_exp
  latest_processed_block: Int_comparison_exp
  num_batches_fetched: Int_comparison_exp
  num_events_processed: Int_comparison_exp
  start_block: Int_comparison_exp
  timestamp_caught_up_to_head_or_endblock: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "chain_metadata"
"""
enum chain_metadata_constraint {
  """
  unique or primary key constraint on columns "chain_id"
  """
  chain_metadata_pkey
}

"""
input type for incrementing numeric columns in table "chain_metadata"
"""
input chain_metadata_inc_input {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
}

"""
input type for inserting data into table "chain_metadata"
"""
input chain_metadata_insert_input {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  is_hyper_sync: Boolean
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
  timestamp_caught_up_to_head_or_endblock: timestamptz
}

"""aggregate max on columns"""
type chain_metadata_max_fields {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
  timestamp_caught_up_to_head_or_endblock: timestamptz
}

"""aggregate min on columns"""
type chain_metadata_min_fields {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
  timestamp_caught_up_to_head_or_endblock: timestamptz
}

"""
response of any mutation on the table "chain_metadata"
"""
type chain_metadata_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [chain_metadata!]!
}

"""
on_conflict condition type for table "chain_metadata"
"""
input chain_metadata_on_conflict {
  constraint: chain_metadata_constraint!
  update_columns: [chain_metadata_update_column!]! = []
  where: chain_metadata_bool_exp
}

"""Ordering options when selecting data from "chain_metadata"."""
input chain_metadata_order_by {
  block_height: order_by
  chain_id: order_by
  end_block: order_by
  first_event_block_number: order_by
  is_hyper_sync: order_by
  latest_fetched_block_number: order_by
  latest_processed_block: order_by
  num_batches_fetched: order_by
  num_events_processed: order_by
  start_block: order_by
  timestamp_caught_up_to_head_or_endblock: order_by
}

"""primary key columns input for table: chain_metadata"""
input chain_metadata_pk_columns_input {
  chain_id: Int!
}

"""
select columns of table "chain_metadata"
"""
enum chain_metadata_select_column {
  """column name"""
  block_height

  """column name"""
  chain_id

  """column name"""
  end_block

  """column name"""
  first_event_block_number

  """column name"""
  is_hyper_sync

  """column name"""
  latest_fetched_block_number

  """column name"""
  latest_processed_block

  """column name"""
  num_batches_fetched

  """column name"""
  num_events_processed

  """column name"""
  start_block

  """column name"""
  timestamp_caught_up_to_head_or_endblock
}

"""
input type for updating data in table "chain_metadata"
"""
input chain_metadata_set_input {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  is_hyper_sync: Boolean
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
  timestamp_caught_up_to_head_or_endblock: timestamptz
}

"""aggregate stddev on columns"""
type chain_metadata_stddev_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

"""aggregate stddev_pop on columns"""
type chain_metadata_stddev_pop_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

"""aggregate stddev_samp on columns"""
type chain_metadata_stddev_samp_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

"""
Streaming cursor of the table "chain_metadata"
"""
input chain_metadata_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: chain_metadata_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input chain_metadata_stream_cursor_value_input {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  is_hyper_sync: Boolean
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
  timestamp_caught_up_to_head_or_endblock: timestamptz
}

"""aggregate sum on columns"""
type chain_metadata_sum_fields {
  block_height: Int
  chain_id: Int
  end_block: Int
  first_event_block_number: Int
  latest_fetched_block_number: Int
  latest_processed_block: Int
  num_batches_fetched: Int
  num_events_processed: Int
  start_block: Int
}

"""
update columns of table "chain_metadata"
"""
enum chain_metadata_update_column {
  """column name"""
  block_height

  """column name"""
  chain_id

  """column name"""
  end_block

  """column name"""
  first_event_block_number

  """column name"""
  is_hyper_sync

  """column name"""
  latest_fetched_block_number

  """column name"""
  latest_processed_block

  """column name"""
  num_batches_fetched

  """column name"""
  num_events_processed

  """column name"""
  start_block

  """column name"""
  timestamp_caught_up_to_head_or_endblock
}

input chain_metadata_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: chain_metadata_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: chain_metadata_set_input

  """filter the rows which have to be updated"""
  where: chain_metadata_bool_exp!
}

"""aggregate var_pop on columns"""
type chain_metadata_var_pop_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

"""aggregate var_samp on columns"""
type chain_metadata_var_samp_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

"""aggregate variance on columns"""
type chain_metadata_variance_fields {
  block_height: Float
  chain_id: Float
  end_block: Float
  first_event_block_number: Float
  latest_fetched_block_number: Float
  latest_processed_block: Float
  num_batches_fetched: Float
  num_events_processed: Float
  start_block: Float
}

scalar contract_type

"""
Boolean expression to compare columns of type "contract_type". All fields are combined with logical 'AND'.
"""
input contract_type_comparison_exp {
  _eq: contract_type
  _gt: contract_type
  _gte: contract_type
  _in: [contract_type!]
  _is_null: Boolean
  _lt: contract_type
  _lte: contract_type
  _neq: contract_type
  _nin: [contract_type!]
}

"""ordering argument of a cursor"""
enum cursor_ordering {
  """ascending ordering of the cursor"""
  ASC

  """descending ordering of the cursor"""
  DESC
}

"""
columns and relationships of "dynamic_contract_registry"
"""
type dynamic_contract_registry {
  chain_id: Int!
  contract_address: String!
  contract_type: contract_type!
  id: String!
  is_pre_registered: Boolean!
  registering_event_block_number: Int!
  registering_event_block_timestamp: Int!
  registering_event_contract_name: String!
  registering_event_log_index: Int!
  registering_event_name: String!
  registering_event_src_address: String!
}

"""
aggregated selection of "dynamic_contract_registry"
"""
type dynamic_contract_registry_aggregate {
  aggregate: dynamic_contract_registry_aggregate_fields
  nodes: [dynamic_contract_registry!]!
}

"""
aggregate fields of "dynamic_contract_registry"
"""
type dynamic_contract_registry_aggregate_fields {
  avg: dynamic_contract_registry_avg_fields
  count(columns: [dynamic_contract_registry_select_column!], distinct: Boolean): Int!
  max: dynamic_contract_registry_max_fields
  min: dynamic_contract_registry_min_fields
  stddev: dynamic_contract_registry_stddev_fields
  stddev_pop: dynamic_contract_registry_stddev_pop_fields
  stddev_samp: dynamic_contract_registry_stddev_samp_fields
  sum: dynamic_contract_registry_sum_fields
  var_pop: dynamic_contract_registry_var_pop_fields
  var_samp: dynamic_contract_registry_var_samp_fields
  variance: dynamic_contract_registry_variance_fields
}

"""aggregate avg on columns"""
type dynamic_contract_registry_avg_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""
Boolean expression to filter rows from the table "dynamic_contract_registry". All fields are combined with a logical 'AND'.
"""
input dynamic_contract_registry_bool_exp {
  _and: [dynamic_contract_registry_bool_exp!]
  _not: dynamic_contract_registry_bool_exp
  _or: [dynamic_contract_registry_bool_exp!]
  chain_id: Int_comparison_exp
  contract_address: String_comparison_exp
  contract_type: contract_type_comparison_exp
  id: String_comparison_exp
  is_pre_registered: Boolean_comparison_exp
  registering_event_block_number: Int_comparison_exp
  registering_event_block_timestamp: Int_comparison_exp
  registering_event_contract_name: String_comparison_exp
  registering_event_log_index: Int_comparison_exp
  registering_event_name: String_comparison_exp
  registering_event_src_address: String_comparison_exp
}

"""
unique or primary key constraints on table "dynamic_contract_registry"
"""
enum dynamic_contract_registry_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  dynamic_contract_registry_pkey
}

"""
input type for incrementing numeric columns in table "dynamic_contract_registry"
"""
input dynamic_contract_registry_inc_input {
  chain_id: Int
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_log_index: Int
}

"""
input type for inserting data into table "dynamic_contract_registry"
"""
input dynamic_contract_registry_insert_input {
  chain_id: Int
  contract_address: String
  contract_type: contract_type
  id: String
  is_pre_registered: Boolean
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_contract_name: String
  registering_event_log_index: Int
  registering_event_name: String
  registering_event_src_address: String
}

"""aggregate max on columns"""
type dynamic_contract_registry_max_fields {
  chain_id: Int
  contract_address: String
  contract_type: contract_type
  id: String
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_contract_name: String
  registering_event_log_index: Int
  registering_event_name: String
  registering_event_src_address: String
}

"""aggregate min on columns"""
type dynamic_contract_registry_min_fields {
  chain_id: Int
  contract_address: String
  contract_type: contract_type
  id: String
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_contract_name: String
  registering_event_log_index: Int
  registering_event_name: String
  registering_event_src_address: String
}

"""
response of any mutation on the table "dynamic_contract_registry"
"""
type dynamic_contract_registry_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [dynamic_contract_registry!]!
}

"""
on_conflict condition type for table "dynamic_contract_registry"
"""
input dynamic_contract_registry_on_conflict {
  constraint: dynamic_contract_registry_constraint!
  update_columns: [dynamic_contract_registry_update_column!]! = []
  where: dynamic_contract_registry_bool_exp
}

"""Ordering options when selecting data from "dynamic_contract_registry"."""
input dynamic_contract_registry_order_by {
  chain_id: order_by
  contract_address: order_by
  contract_type: order_by
  id: order_by
  is_pre_registered: order_by
  registering_event_block_number: order_by
  registering_event_block_timestamp: order_by
  registering_event_contract_name: order_by
  registering_event_log_index: order_by
  registering_event_name: order_by
  registering_event_src_address: order_by
}

"""primary key columns input for table: dynamic_contract_registry"""
input dynamic_contract_registry_pk_columns_input {
  id: String!
}

"""
select columns of table "dynamic_contract_registry"
"""
enum dynamic_contract_registry_select_column {
  """column name"""
  chain_id

  """column name"""
  contract_address

  """column name"""
  contract_type

  """column name"""
  id

  """column name"""
  is_pre_registered

  """column name"""
  registering_event_block_number

  """column name"""
  registering_event_block_timestamp

  """column name"""
  registering_event_contract_name

  """column name"""
  registering_event_log_index

  """column name"""
  registering_event_name

  """column name"""
  registering_event_src_address
}

"""
input type for updating data in table "dynamic_contract_registry"
"""
input dynamic_contract_registry_set_input {
  chain_id: Int
  contract_address: String
  contract_type: contract_type
  id: String
  is_pre_registered: Boolean
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_contract_name: String
  registering_event_log_index: Int
  registering_event_name: String
  registering_event_src_address: String
}

"""aggregate stddev on columns"""
type dynamic_contract_registry_stddev_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""aggregate stddev_pop on columns"""
type dynamic_contract_registry_stddev_pop_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""aggregate stddev_samp on columns"""
type dynamic_contract_registry_stddev_samp_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""
Streaming cursor of the table "dynamic_contract_registry"
"""
input dynamic_contract_registry_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: dynamic_contract_registry_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input dynamic_contract_registry_stream_cursor_value_input {
  chain_id: Int
  contract_address: String
  contract_type: contract_type
  id: String
  is_pre_registered: Boolean
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_contract_name: String
  registering_event_log_index: Int
  registering_event_name: String
  registering_event_src_address: String
}

"""aggregate sum on columns"""
type dynamic_contract_registry_sum_fields {
  chain_id: Int
  registering_event_block_number: Int
  registering_event_block_timestamp: Int
  registering_event_log_index: Int
}

"""
update columns of table "dynamic_contract_registry"
"""
enum dynamic_contract_registry_update_column {
  """column name"""
  chain_id

  """column name"""
  contract_address

  """column name"""
  contract_type

  """column name"""
  id

  """column name"""
  is_pre_registered

  """column name"""
  registering_event_block_number

  """column name"""
  registering_event_block_timestamp

  """column name"""
  registering_event_contract_name

  """column name"""
  registering_event_log_index

  """column name"""
  registering_event_name

  """column name"""
  registering_event_src_address
}

input dynamic_contract_registry_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: dynamic_contract_registry_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: dynamic_contract_registry_set_input

  """filter the rows which have to be updated"""
  where: dynamic_contract_registry_bool_exp!
}

"""aggregate var_pop on columns"""
type dynamic_contract_registry_var_pop_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""aggregate var_samp on columns"""
type dynamic_contract_registry_var_samp_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""aggregate variance on columns"""
type dynamic_contract_registry_variance_fields {
  chain_id: Float
  registering_event_block_number: Float
  registering_event_block_timestamp: Float
  registering_event_log_index: Float
}

"""
columns and relationships of "end_of_block_range_scanned_data"
"""
type end_of_block_range_scanned_data {
  block_hash: String!
  block_number: Int!
  block_timestamp: Int!
  chain_id: Int!
}

"""
aggregated selection of "end_of_block_range_scanned_data"
"""
type end_of_block_range_scanned_data_aggregate {
  aggregate: end_of_block_range_scanned_data_aggregate_fields
  nodes: [end_of_block_range_scanned_data!]!
}

"""
aggregate fields of "end_of_block_range_scanned_data"
"""
type end_of_block_range_scanned_data_aggregate_fields {
  avg: end_of_block_range_scanned_data_avg_fields
  count(columns: [end_of_block_range_scanned_data_select_column!], distinct: Boolean): Int!
  max: end_of_block_range_scanned_data_max_fields
  min: end_of_block_range_scanned_data_min_fields
  stddev: end_of_block_range_scanned_data_stddev_fields
  stddev_pop: end_of_block_range_scanned_data_stddev_pop_fields
  stddev_samp: end_of_block_range_scanned_data_stddev_samp_fields
  sum: end_of_block_range_scanned_data_sum_fields
  var_pop: end_of_block_range_scanned_data_var_pop_fields
  var_samp: end_of_block_range_scanned_data_var_samp_fields
  variance: end_of_block_range_scanned_data_variance_fields
}

"""aggregate avg on columns"""
type end_of_block_range_scanned_data_avg_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""
Boolean expression to filter rows from the table "end_of_block_range_scanned_data". All fields are combined with a logical 'AND'.
"""
input end_of_block_range_scanned_data_bool_exp {
  _and: [end_of_block_range_scanned_data_bool_exp!]
  _not: end_of_block_range_scanned_data_bool_exp
  _or: [end_of_block_range_scanned_data_bool_exp!]
  block_hash: String_comparison_exp
  block_number: Int_comparison_exp
  block_timestamp: Int_comparison_exp
  chain_id: Int_comparison_exp
}

"""
unique or primary key constraints on table "end_of_block_range_scanned_data"
"""
enum end_of_block_range_scanned_data_constraint {
  """
  unique or primary key constraint on columns "chain_id", "block_number"
  """
  end_of_block_range_scanned_data_pkey
}

"""
input type for incrementing numeric columns in table "end_of_block_range_scanned_data"
"""
input end_of_block_range_scanned_data_inc_input {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""
input type for inserting data into table "end_of_block_range_scanned_data"
"""
input end_of_block_range_scanned_data_insert_input {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""aggregate max on columns"""
type end_of_block_range_scanned_data_max_fields {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""aggregate min on columns"""
type end_of_block_range_scanned_data_min_fields {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""
response of any mutation on the table "end_of_block_range_scanned_data"
"""
type end_of_block_range_scanned_data_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [end_of_block_range_scanned_data!]!
}

"""
on_conflict condition type for table "end_of_block_range_scanned_data"
"""
input end_of_block_range_scanned_data_on_conflict {
  constraint: end_of_block_range_scanned_data_constraint!
  update_columns: [end_of_block_range_scanned_data_update_column!]! = []
  where: end_of_block_range_scanned_data_bool_exp
}

"""
Ordering options when selecting data from "end_of_block_range_scanned_data".
"""
input end_of_block_range_scanned_data_order_by {
  block_hash: order_by
  block_number: order_by
  block_timestamp: order_by
  chain_id: order_by
}

"""primary key columns input for table: end_of_block_range_scanned_data"""
input end_of_block_range_scanned_data_pk_columns_input {
  block_number: Int!
  chain_id: Int!
}

"""
select columns of table "end_of_block_range_scanned_data"
"""
enum end_of_block_range_scanned_data_select_column {
  """column name"""
  block_hash

  """column name"""
  block_number

  """column name"""
  block_timestamp

  """column name"""
  chain_id
}

"""
input type for updating data in table "end_of_block_range_scanned_data"
"""
input end_of_block_range_scanned_data_set_input {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""aggregate stddev on columns"""
type end_of_block_range_scanned_data_stddev_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""aggregate stddev_pop on columns"""
type end_of_block_range_scanned_data_stddev_pop_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""aggregate stddev_samp on columns"""
type end_of_block_range_scanned_data_stddev_samp_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""
Streaming cursor of the table "end_of_block_range_scanned_data"
"""
input end_of_block_range_scanned_data_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: end_of_block_range_scanned_data_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input end_of_block_range_scanned_data_stream_cursor_value_input {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""aggregate sum on columns"""
type end_of_block_range_scanned_data_sum_fields {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
}

"""
update columns of table "end_of_block_range_scanned_data"
"""
enum end_of_block_range_scanned_data_update_column {
  """column name"""
  block_hash

  """column name"""
  block_number

  """column name"""
  block_timestamp

  """column name"""
  chain_id
}

input end_of_block_range_scanned_data_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: end_of_block_range_scanned_data_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: end_of_block_range_scanned_data_set_input

  """filter the rows which have to be updated"""
  where: end_of_block_range_scanned_data_bool_exp!
}

"""aggregate var_pop on columns"""
type end_of_block_range_scanned_data_var_pop_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""aggregate var_samp on columns"""
type end_of_block_range_scanned_data_var_samp_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""aggregate variance on columns"""
type end_of_block_range_scanned_data_variance_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
}

"""
columns and relationships of "event_sync_state"
"""
type event_sync_state {
  block_number: Int!
  block_timestamp: Int!
  chain_id: Int!
  is_pre_registering_dynamic_contracts: Boolean!
  log_index: Int!
}

"""
aggregated selection of "event_sync_state"
"""
type event_sync_state_aggregate {
  aggregate: event_sync_state_aggregate_fields
  nodes: [event_sync_state!]!
}

"""
aggregate fields of "event_sync_state"
"""
type event_sync_state_aggregate_fields {
  avg: event_sync_state_avg_fields
  count(columns: [event_sync_state_select_column!], distinct: Boolean): Int!
  max: event_sync_state_max_fields
  min: event_sync_state_min_fields
  stddev: event_sync_state_stddev_fields
  stddev_pop: event_sync_state_stddev_pop_fields
  stddev_samp: event_sync_state_stddev_samp_fields
  sum: event_sync_state_sum_fields
  var_pop: event_sync_state_var_pop_fields
  var_samp: event_sync_state_var_samp_fields
  variance: event_sync_state_variance_fields
}

"""aggregate avg on columns"""
type event_sync_state_avg_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

"""
Boolean expression to filter rows from the table "event_sync_state". All fields are combined with a logical 'AND'.
"""
input event_sync_state_bool_exp {
  _and: [event_sync_state_bool_exp!]
  _not: event_sync_state_bool_exp
  _or: [event_sync_state_bool_exp!]
  block_number: Int_comparison_exp
  block_timestamp: Int_comparison_exp
  chain_id: Int_comparison_exp
  is_pre_registering_dynamic_contracts: Boolean_comparison_exp
  log_index: Int_comparison_exp
}

"""
unique or primary key constraints on table "event_sync_state"
"""
enum event_sync_state_constraint {
  """
  unique or primary key constraint on columns "chain_id"
  """
  event_sync_state_pkey
}

"""
input type for incrementing numeric columns in table "event_sync_state"
"""
input event_sync_state_inc_input {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  log_index: Int
}

"""
input type for inserting data into table "event_sync_state"
"""
input event_sync_state_insert_input {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  is_pre_registering_dynamic_contracts: Boolean
  log_index: Int
}

"""aggregate max on columns"""
type event_sync_state_max_fields {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  log_index: Int
}

"""aggregate min on columns"""
type event_sync_state_min_fields {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  log_index: Int
}

"""
response of any mutation on the table "event_sync_state"
"""
type event_sync_state_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [event_sync_state!]!
}

"""
on_conflict condition type for table "event_sync_state"
"""
input event_sync_state_on_conflict {
  constraint: event_sync_state_constraint!
  update_columns: [event_sync_state_update_column!]! = []
  where: event_sync_state_bool_exp
}

"""Ordering options when selecting data from "event_sync_state"."""
input event_sync_state_order_by {
  block_number: order_by
  block_timestamp: order_by
  chain_id: order_by
  is_pre_registering_dynamic_contracts: order_by
  log_index: order_by
}

"""primary key columns input for table: event_sync_state"""
input event_sync_state_pk_columns_input {
  chain_id: Int!
}

"""
select columns of table "event_sync_state"
"""
enum event_sync_state_select_column {
  """column name"""
  block_number

  """column name"""
  block_timestamp

  """column name"""
  chain_id

  """column name"""
  is_pre_registering_dynamic_contracts

  """column name"""
  log_index
}

"""
input type for updating data in table "event_sync_state"
"""
input event_sync_state_set_input {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  is_pre_registering_dynamic_contracts: Boolean
  log_index: Int
}

"""aggregate stddev on columns"""
type event_sync_state_stddev_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

"""aggregate stddev_pop on columns"""
type event_sync_state_stddev_pop_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

"""aggregate stddev_samp on columns"""
type event_sync_state_stddev_samp_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

"""
Streaming cursor of the table "event_sync_state"
"""
input event_sync_state_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: event_sync_state_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input event_sync_state_stream_cursor_value_input {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  is_pre_registering_dynamic_contracts: Boolean
  log_index: Int
}

"""aggregate sum on columns"""
type event_sync_state_sum_fields {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  log_index: Int
}

"""
update columns of table "event_sync_state"
"""
enum event_sync_state_update_column {
  """column name"""
  block_number

  """column name"""
  block_timestamp

  """column name"""
  chain_id

  """column name"""
  is_pre_registering_dynamic_contracts

  """column name"""
  log_index
}

input event_sync_state_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: event_sync_state_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: event_sync_state_set_input

  """filter the rows which have to be updated"""
  where: event_sync_state_bool_exp!
}

"""aggregate var_pop on columns"""
type event_sync_state_var_pop_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

"""aggregate var_samp on columns"""
type event_sync_state_var_samp_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

"""aggregate variance on columns"""
type event_sync_state_variance_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  log_index: Float
}

scalar feesource

"""
Boolean expression to compare columns of type "feesource". All fields are combined with logical 'AND'.
"""
input feesource_comparison_exp {
  _eq: feesource
  _gt: feesource
  _gte: feesource
  _in: [feesource!]
  _is_null: Boolean
  _lt: feesource
  _lte: feesource
  _neq: feesource
  _nin: [feesource!]
}

scalar jsonb

input jsonb_cast_exp {
  String: String_comparison_exp
}

"""
Boolean expression to compare columns of type "jsonb". All fields are combined with logical 'AND'.
"""
input jsonb_comparison_exp {
  _cast: jsonb_cast_exp

  """is the column contained in the given json value"""
  _contained_in: jsonb

  """does the column contain the given json value at the top level"""
  _contains: jsonb
  _eq: jsonb
  _gt: jsonb
  _gte: jsonb

  """does the string exist as a top-level key in the column"""
  _has_key: String

  """do all of these strings exist as top-level keys in the column"""
  _has_keys_all: [String!]

  """do any of these strings exist as top-level keys in the column"""
  _has_keys_any: [String!]
  _in: [jsonb!]
  _is_null: Boolean
  _lt: jsonb
  _lte: jsonb
  _neq: jsonb
  _nin: [jsonb!]
}

"""mutation root"""
type mutation_root {
  """
  delete data from the table: "BondingCurve"
  """
  delete_BondingCurve(
    """filter the rows which have to be deleted"""
    where: BondingCurve_bool_exp!
  ): BondingCurve_mutation_response

  """
  delete single row from the table: "BondingCurve"
  """
  delete_BondingCurve_by_pk(id: String!): BondingCurve

  """
  delete data from the table: "Bounty"
  """
  delete_Bounty(
    """filter the rows which have to be deleted"""
    where: Bounty_bool_exp!
  ): Bounty_mutation_response

  """
  delete data from the table: "BountyClaim"
  """
  delete_BountyClaim(
    """filter the rows which have to be deleted"""
    where: BountyClaim_bool_exp!
  ): BountyClaim_mutation_response

  """
  delete single row from the table: "BountyClaim"
  """
  delete_BountyClaim_by_pk(id: String!): BountyClaim

  """
  delete data from the table: "BountyContributor"
  """
  delete_BountyContributor(
    """filter the rows which have to be deleted"""
    where: BountyContributor_bool_exp!
  ): BountyContributor_mutation_response

  """
  delete single row from the table: "BountyContributor"
  """
  delete_BountyContributor_by_pk(id: String!): BountyContributor

  """
  delete data from the table: "BountyModule"
  """
  delete_BountyModule(
    """filter the rows which have to be deleted"""
    where: BountyModule_bool_exp!
  ): BountyModule_mutation_response

  """
  delete single row from the table: "BountyModule"
  """
  delete_BountyModule_by_pk(id: String!): BountyModule

  """
  delete single row from the table: "Bounty"
  """
  delete_Bounty_by_pk(id: String!): Bounty

  """
  delete data from the table: "CurveDayData"
  """
  delete_CurveDayData(
    """filter the rows which have to be deleted"""
    where: CurveDayData_bool_exp!
  ): CurveDayData_mutation_response

  """
  delete single row from the table: "CurveDayData"
  """
  delete_CurveDayData_by_pk(id: String!): CurveDayData

  """
  delete data from the table: "CurveHourData"
  """
  delete_CurveHourData(
    """filter the rows which have to be deleted"""
    where: CurveHourData_bool_exp!
  ): CurveHourData_mutation_response

  """
  delete single row from the table: "CurveHourData"
  """
  delete_CurveHourData_by_pk(id: String!): CurveHourData

  """
  delete data from the table: "Deposit"
  """
  delete_Deposit(
    """filter the rows which have to be deleted"""
    where: Deposit_bool_exp!
  ): Deposit_mutation_response

  """
  delete data from the table: "DepositVault"
  """
  delete_DepositVault(
    """filter the rows which have to be deleted"""
    where: DepositVault_bool_exp!
  ): DepositVault_mutation_response

  """
  delete single row from the table: "DepositVault"
  """
  delete_DepositVault_by_pk(id: String!): DepositVault

  """
  delete single row from the table: "Deposit"
  """
  delete_Deposit_by_pk(id: String!): Deposit

  """
  delete data from the table: "IssuanceTokenDayData"
  """
  delete_IssuanceTokenDayData(
    """filter the rows which have to be deleted"""
    where: IssuanceTokenDayData_bool_exp!
  ): IssuanceTokenDayData_mutation_response

  """
  delete single row from the table: "IssuanceTokenDayData"
  """
  delete_IssuanceTokenDayData_by_pk(id: String!): IssuanceTokenDayData

  """
  delete data from the table: "IssuanceTokenHourData"
  """
  delete_IssuanceTokenHourData(
    """filter the rows which have to be deleted"""
    where: IssuanceTokenHourData_bool_exp!
  ): IssuanceTokenHourData_mutation_response

  """
  delete single row from the table: "IssuanceTokenHourData"
  """
  delete_IssuanceTokenHourData_by_pk(id: String!): IssuanceTokenHourData

  """
  delete data from the table: "LinearVesting"
  """
  delete_LinearVesting(
    """filter the rows which have to be deleted"""
    where: LinearVesting_bool_exp!
  ): LinearVesting_mutation_response

  """
  delete single row from the table: "LinearVesting"
  """
  delete_LinearVesting_by_pk(id: String!): LinearVesting

  """
  delete data from the table: "ProjectFee"
  """
  delete_ProjectFee(
    """filter the rows which have to be deleted"""
    where: ProjectFee_bool_exp!
  ): ProjectFee_mutation_response

  """
  delete single row from the table: "ProjectFee"
  """
  delete_ProjectFee_by_pk(id: String!): ProjectFee

  """
  delete data from the table: "ProtocolFee"
  """
  delete_ProtocolFee(
    """filter the rows which have to be deleted"""
    where: ProtocolFee_bool_exp!
  ): ProtocolFee_mutation_response

  """
  delete single row from the table: "ProtocolFee"
  """
  delete_ProtocolFee_by_pk(id: String!): ProtocolFee

  """
  delete data from the table: "StreamingPaymentProcessor"
  """
  delete_StreamingPaymentProcessor(
    """filter the rows which have to be deleted"""
    where: StreamingPaymentProcessor_bool_exp!
  ): StreamingPaymentProcessor_mutation_response

  """
  delete single row from the table: "StreamingPaymentProcessor"
  """
  delete_StreamingPaymentProcessor_by_pk(id: String!): StreamingPaymentProcessor

  """
  delete data from the table: "Swap"
  """
  delete_Swap(
    """filter the rows which have to be deleted"""
    where: Swap_bool_exp!
  ): Swap_mutation_response

  """
  delete single row from the table: "Swap"
  """
  delete_Swap_by_pk(id: String!): Swap

  """
  delete data from the table: "Token"
  """
  delete_Token(
    """filter the rows which have to be deleted"""
    where: Token_bool_exp!
  ): Token_mutation_response

  """
  delete single row from the table: "Token"
  """
  delete_Token_by_pk(id: String!): Token

  """
  delete data from the table: "Transfer"
  """
  delete_Transfer(
    """filter the rows which have to be deleted"""
    where: Transfer_bool_exp!
  ): Transfer_mutation_response

  """
  delete single row from the table: "Transfer"
  """
  delete_Transfer_by_pk(id: String!): Transfer

  """
  delete data from the table: "Workflow"
  """
  delete_Workflow(
    """filter the rows which have to be deleted"""
    where: Workflow_bool_exp!
  ): Workflow_mutation_response

  """
  delete data from the table: "WorkflowModule"
  """
  delete_WorkflowModule(
    """filter the rows which have to be deleted"""
    where: WorkflowModule_bool_exp!
  ): WorkflowModule_mutation_response

  """
  delete data from the table: "WorkflowModuleType"
  """
  delete_WorkflowModuleType(
    """filter the rows which have to be deleted"""
    where: WorkflowModuleType_bool_exp!
  ): WorkflowModuleType_mutation_response

  """
  delete single row from the table: "WorkflowModuleType"
  """
  delete_WorkflowModuleType_by_pk(id: String!): WorkflowModuleType

  """
  delete single row from the table: "WorkflowModule"
  """
  delete_WorkflowModule_by_pk(id: String!): WorkflowModule

  """
  delete single row from the table: "Workflow"
  """
  delete_Workflow_by_pk(id: String!): Workflow

  """
  delete data from the table: "chain_metadata"
  """
  delete_chain_metadata(
    """filter the rows which have to be deleted"""
    where: chain_metadata_bool_exp!
  ): chain_metadata_mutation_response

  """
  delete single row from the table: "chain_metadata"
  """
  delete_chain_metadata_by_pk(chain_id: Int!): chain_metadata

  """
  delete data from the table: "dynamic_contract_registry"
  """
  delete_dynamic_contract_registry(
    """filter the rows which have to be deleted"""
    where: dynamic_contract_registry_bool_exp!
  ): dynamic_contract_registry_mutation_response

  """
  delete single row from the table: "dynamic_contract_registry"
  """
  delete_dynamic_contract_registry_by_pk(id: String!): dynamic_contract_registry

  """
  delete data from the table: "end_of_block_range_scanned_data"
  """
  delete_end_of_block_range_scanned_data(
    """filter the rows which have to be deleted"""
    where: end_of_block_range_scanned_data_bool_exp!
  ): end_of_block_range_scanned_data_mutation_response

  """
  delete single row from the table: "end_of_block_range_scanned_data"
  """
  delete_end_of_block_range_scanned_data_by_pk(block_number: Int!, chain_id: Int!): end_of_block_range_scanned_data

  """
  delete data from the table: "event_sync_state"
  """
  delete_event_sync_state(
    """filter the rows which have to be deleted"""
    where: event_sync_state_bool_exp!
  ): event_sync_state_mutation_response

  """
  delete single row from the table: "event_sync_state"
  """
  delete_event_sync_state_by_pk(chain_id: Int!): event_sync_state

  """
  delete data from the table: "persisted_state"
  """
  delete_persisted_state(
    """filter the rows which have to be deleted"""
    where: persisted_state_bool_exp!
  ): persisted_state_mutation_response

  """
  delete single row from the table: "persisted_state"
  """
  delete_persisted_state_by_pk(id: Int!): persisted_state

  """
  delete data from the table: "raw_events"
  """
  delete_raw_events(
    """filter the rows which have to be deleted"""
    where: raw_events_bool_exp!
  ): raw_events_mutation_response

  """
  delete single row from the table: "raw_events"
  """
  delete_raw_events_by_pk(serial: Int!): raw_events

  """
  insert data into the table: "BondingCurve"
  """
  insert_BondingCurve(
    """the rows to be inserted"""
    objects: [BondingCurve_insert_input!]!

    """upsert condition"""
    on_conflict: BondingCurve_on_conflict
  ): BondingCurve_mutation_response

  """
  insert a single row into the table: "BondingCurve"
  """
  insert_BondingCurve_one(
    """the row to be inserted"""
    object: BondingCurve_insert_input!

    """upsert condition"""
    on_conflict: BondingCurve_on_conflict
  ): BondingCurve

  """
  insert data into the table: "Bounty"
  """
  insert_Bounty(
    """the rows to be inserted"""
    objects: [Bounty_insert_input!]!

    """upsert condition"""
    on_conflict: Bounty_on_conflict
  ): Bounty_mutation_response

  """
  insert data into the table: "BountyClaim"
  """
  insert_BountyClaim(
    """the rows to be inserted"""
    objects: [BountyClaim_insert_input!]!

    """upsert condition"""
    on_conflict: BountyClaim_on_conflict
  ): BountyClaim_mutation_response

  """
  insert a single row into the table: "BountyClaim"
  """
  insert_BountyClaim_one(
    """the row to be inserted"""
    object: BountyClaim_insert_input!

    """upsert condition"""
    on_conflict: BountyClaim_on_conflict
  ): BountyClaim

  """
  insert data into the table: "BountyContributor"
  """
  insert_BountyContributor(
    """the rows to be inserted"""
    objects: [BountyContributor_insert_input!]!

    """upsert condition"""
    on_conflict: BountyContributor_on_conflict
  ): BountyContributor_mutation_response

  """
  insert a single row into the table: "BountyContributor"
  """
  insert_BountyContributor_one(
    """the row to be inserted"""
    object: BountyContributor_insert_input!

    """upsert condition"""
    on_conflict: BountyContributor_on_conflict
  ): BountyContributor

  """
  insert data into the table: "BountyModule"
  """
  insert_BountyModule(
    """the rows to be inserted"""
    objects: [BountyModule_insert_input!]!

    """upsert condition"""
    on_conflict: BountyModule_on_conflict
  ): BountyModule_mutation_response

  """
  insert a single row into the table: "BountyModule"
  """
  insert_BountyModule_one(
    """the row to be inserted"""
    object: BountyModule_insert_input!

    """upsert condition"""
    on_conflict: BountyModule_on_conflict
  ): BountyModule

  """
  insert a single row into the table: "Bounty"
  """
  insert_Bounty_one(
    """the row to be inserted"""
    object: Bounty_insert_input!

    """upsert condition"""
    on_conflict: Bounty_on_conflict
  ): Bounty

  """
  insert data into the table: "CurveDayData"
  """
  insert_CurveDayData(
    """the rows to be inserted"""
    objects: [CurveDayData_insert_input!]!

    """upsert condition"""
    on_conflict: CurveDayData_on_conflict
  ): CurveDayData_mutation_response

  """
  insert a single row into the table: "CurveDayData"
  """
  insert_CurveDayData_one(
    """the row to be inserted"""
    object: CurveDayData_insert_input!

    """upsert condition"""
    on_conflict: CurveDayData_on_conflict
  ): CurveDayData

  """
  insert data into the table: "CurveHourData"
  """
  insert_CurveHourData(
    """the rows to be inserted"""
    objects: [CurveHourData_insert_input!]!

    """upsert condition"""
    on_conflict: CurveHourData_on_conflict
  ): CurveHourData_mutation_response

  """
  insert a single row into the table: "CurveHourData"
  """
  insert_CurveHourData_one(
    """the row to be inserted"""
    object: CurveHourData_insert_input!

    """upsert condition"""
    on_conflict: CurveHourData_on_conflict
  ): CurveHourData

  """
  insert data into the table: "Deposit"
  """
  insert_Deposit(
    """the rows to be inserted"""
    objects: [Deposit_insert_input!]!

    """upsert condition"""
    on_conflict: Deposit_on_conflict
  ): Deposit_mutation_response

  """
  insert data into the table: "DepositVault"
  """
  insert_DepositVault(
    """the rows to be inserted"""
    objects: [DepositVault_insert_input!]!

    """upsert condition"""
    on_conflict: DepositVault_on_conflict
  ): DepositVault_mutation_response

  """
  insert a single row into the table: "DepositVault"
  """
  insert_DepositVault_one(
    """the row to be inserted"""
    object: DepositVault_insert_input!

    """upsert condition"""
    on_conflict: DepositVault_on_conflict
  ): DepositVault

  """
  insert a single row into the table: "Deposit"
  """
  insert_Deposit_one(
    """the row to be inserted"""
    object: Deposit_insert_input!

    """upsert condition"""
    on_conflict: Deposit_on_conflict
  ): Deposit

  """
  insert data into the table: "IssuanceTokenDayData"
  """
  insert_IssuanceTokenDayData(
    """the rows to be inserted"""
    objects: [IssuanceTokenDayData_insert_input!]!

    """upsert condition"""
    on_conflict: IssuanceTokenDayData_on_conflict
  ): IssuanceTokenDayData_mutation_response

  """
  insert a single row into the table: "IssuanceTokenDayData"
  """
  insert_IssuanceTokenDayData_one(
    """the row to be inserted"""
    object: IssuanceTokenDayData_insert_input!

    """upsert condition"""
    on_conflict: IssuanceTokenDayData_on_conflict
  ): IssuanceTokenDayData

  """
  insert data into the table: "IssuanceTokenHourData"
  """
  insert_IssuanceTokenHourData(
    """the rows to be inserted"""
    objects: [IssuanceTokenHourData_insert_input!]!

    """upsert condition"""
    on_conflict: IssuanceTokenHourData_on_conflict
  ): IssuanceTokenHourData_mutation_response

  """
  insert a single row into the table: "IssuanceTokenHourData"
  """
  insert_IssuanceTokenHourData_one(
    """the row to be inserted"""
    object: IssuanceTokenHourData_insert_input!

    """upsert condition"""
    on_conflict: IssuanceTokenHourData_on_conflict
  ): IssuanceTokenHourData

  """
  insert data into the table: "LinearVesting"
  """
  insert_LinearVesting(
    """the rows to be inserted"""
    objects: [LinearVesting_insert_input!]!

    """upsert condition"""
    on_conflict: LinearVesting_on_conflict
  ): LinearVesting_mutation_response

  """
  insert a single row into the table: "LinearVesting"
  """
  insert_LinearVesting_one(
    """the row to be inserted"""
    object: LinearVesting_insert_input!

    """upsert condition"""
    on_conflict: LinearVesting_on_conflict
  ): LinearVesting

  """
  insert data into the table: "ProjectFee"
  """
  insert_ProjectFee(
    """the rows to be inserted"""
    objects: [ProjectFee_insert_input!]!

    """upsert condition"""
    on_conflict: ProjectFee_on_conflict
  ): ProjectFee_mutation_response

  """
  insert a single row into the table: "ProjectFee"
  """
  insert_ProjectFee_one(
    """the row to be inserted"""
    object: ProjectFee_insert_input!

    """upsert condition"""
    on_conflict: ProjectFee_on_conflict
  ): ProjectFee

  """
  insert data into the table: "ProtocolFee"
  """
  insert_ProtocolFee(
    """the rows to be inserted"""
    objects: [ProtocolFee_insert_input!]!

    """upsert condition"""
    on_conflict: ProtocolFee_on_conflict
  ): ProtocolFee_mutation_response

  """
  insert a single row into the table: "ProtocolFee"
  """
  insert_ProtocolFee_one(
    """the row to be inserted"""
    object: ProtocolFee_insert_input!

    """upsert condition"""
    on_conflict: ProtocolFee_on_conflict
  ): ProtocolFee

  """
  insert data into the table: "StreamingPaymentProcessor"
  """
  insert_StreamingPaymentProcessor(
    """the rows to be inserted"""
    objects: [StreamingPaymentProcessor_insert_input!]!

    """upsert condition"""
    on_conflict: StreamingPaymentProcessor_on_conflict
  ): StreamingPaymentProcessor_mutation_response

  """
  insert a single row into the table: "StreamingPaymentProcessor"
  """
  insert_StreamingPaymentProcessor_one(
    """the row to be inserted"""
    object: StreamingPaymentProcessor_insert_input!

    """upsert condition"""
    on_conflict: StreamingPaymentProcessor_on_conflict
  ): StreamingPaymentProcessor

  """
  insert data into the table: "Swap"
  """
  insert_Swap(
    """the rows to be inserted"""
    objects: [Swap_insert_input!]!

    """upsert condition"""
    on_conflict: Swap_on_conflict
  ): Swap_mutation_response

  """
  insert a single row into the table: "Swap"
  """
  insert_Swap_one(
    """the row to be inserted"""
    object: Swap_insert_input!

    """upsert condition"""
    on_conflict: Swap_on_conflict
  ): Swap

  """
  insert data into the table: "Token"
  """
  insert_Token(
    """the rows to be inserted"""
    objects: [Token_insert_input!]!

    """upsert condition"""
    on_conflict: Token_on_conflict
  ): Token_mutation_response

  """
  insert a single row into the table: "Token"
  """
  insert_Token_one(
    """the row to be inserted"""
    object: Token_insert_input!

    """upsert condition"""
    on_conflict: Token_on_conflict
  ): Token

  """
  insert data into the table: "Transfer"
  """
  insert_Transfer(
    """the rows to be inserted"""
    objects: [Transfer_insert_input!]!

    """upsert condition"""
    on_conflict: Transfer_on_conflict
  ): Transfer_mutation_response

  """
  insert a single row into the table: "Transfer"
  """
  insert_Transfer_one(
    """the row to be inserted"""
    object: Transfer_insert_input!

    """upsert condition"""
    on_conflict: Transfer_on_conflict
  ): Transfer

  """
  insert data into the table: "Workflow"
  """
  insert_Workflow(
    """the rows to be inserted"""
    objects: [Workflow_insert_input!]!

    """upsert condition"""
    on_conflict: Workflow_on_conflict
  ): Workflow_mutation_response

  """
  insert data into the table: "WorkflowModule"
  """
  insert_WorkflowModule(
    """the rows to be inserted"""
    objects: [WorkflowModule_insert_input!]!

    """upsert condition"""
    on_conflict: WorkflowModule_on_conflict
  ): WorkflowModule_mutation_response

  """
  insert data into the table: "WorkflowModuleType"
  """
  insert_WorkflowModuleType(
    """the rows to be inserted"""
    objects: [WorkflowModuleType_insert_input!]!

    """upsert condition"""
    on_conflict: WorkflowModuleType_on_conflict
  ): WorkflowModuleType_mutation_response

  """
  insert a single row into the table: "WorkflowModuleType"
  """
  insert_WorkflowModuleType_one(
    """the row to be inserted"""
    object: WorkflowModuleType_insert_input!

    """upsert condition"""
    on_conflict: WorkflowModuleType_on_conflict
  ): WorkflowModuleType

  """
  insert a single row into the table: "WorkflowModule"
  """
  insert_WorkflowModule_one(
    """the row to be inserted"""
    object: WorkflowModule_insert_input!

    """upsert condition"""
    on_conflict: WorkflowModule_on_conflict
  ): WorkflowModule

  """
  insert a single row into the table: "Workflow"
  """
  insert_Workflow_one(
    """the row to be inserted"""
    object: Workflow_insert_input!

    """upsert condition"""
    on_conflict: Workflow_on_conflict
  ): Workflow

  """
  insert data into the table: "chain_metadata"
  """
  insert_chain_metadata(
    """the rows to be inserted"""
    objects: [chain_metadata_insert_input!]!

    """upsert condition"""
    on_conflict: chain_metadata_on_conflict
  ): chain_metadata_mutation_response

  """
  insert a single row into the table: "chain_metadata"
  """
  insert_chain_metadata_one(
    """the row to be inserted"""
    object: chain_metadata_insert_input!

    """upsert condition"""
    on_conflict: chain_metadata_on_conflict
  ): chain_metadata

  """
  insert data into the table: "dynamic_contract_registry"
  """
  insert_dynamic_contract_registry(
    """the rows to be inserted"""
    objects: [dynamic_contract_registry_insert_input!]!

    """upsert condition"""
    on_conflict: dynamic_contract_registry_on_conflict
  ): dynamic_contract_registry_mutation_response

  """
  insert a single row into the table: "dynamic_contract_registry"
  """
  insert_dynamic_contract_registry_one(
    """the row to be inserted"""
    object: dynamic_contract_registry_insert_input!

    """upsert condition"""
    on_conflict: dynamic_contract_registry_on_conflict
  ): dynamic_contract_registry

  """
  insert data into the table: "end_of_block_range_scanned_data"
  """
  insert_end_of_block_range_scanned_data(
    """the rows to be inserted"""
    objects: [end_of_block_range_scanned_data_insert_input!]!

    """upsert condition"""
    on_conflict: end_of_block_range_scanned_data_on_conflict
  ): end_of_block_range_scanned_data_mutation_response

  """
  insert a single row into the table: "end_of_block_range_scanned_data"
  """
  insert_end_of_block_range_scanned_data_one(
    """the row to be inserted"""
    object: end_of_block_range_scanned_data_insert_input!

    """upsert condition"""
    on_conflict: end_of_block_range_scanned_data_on_conflict
  ): end_of_block_range_scanned_data

  """
  insert data into the table: "event_sync_state"
  """
  insert_event_sync_state(
    """the rows to be inserted"""
    objects: [event_sync_state_insert_input!]!

    """upsert condition"""
    on_conflict: event_sync_state_on_conflict
  ): event_sync_state_mutation_response

  """
  insert a single row into the table: "event_sync_state"
  """
  insert_event_sync_state_one(
    """the row to be inserted"""
    object: event_sync_state_insert_input!

    """upsert condition"""
    on_conflict: event_sync_state_on_conflict
  ): event_sync_state

  """
  insert data into the table: "persisted_state"
  """
  insert_persisted_state(
    """the rows to be inserted"""
    objects: [persisted_state_insert_input!]!

    """upsert condition"""
    on_conflict: persisted_state_on_conflict
  ): persisted_state_mutation_response

  """
  insert a single row into the table: "persisted_state"
  """
  insert_persisted_state_one(
    """the row to be inserted"""
    object: persisted_state_insert_input!

    """upsert condition"""
    on_conflict: persisted_state_on_conflict
  ): persisted_state

  """
  insert data into the table: "raw_events"
  """
  insert_raw_events(
    """the rows to be inserted"""
    objects: [raw_events_insert_input!]!

    """upsert condition"""
    on_conflict: raw_events_on_conflict
  ): raw_events_mutation_response

  """
  insert a single row into the table: "raw_events"
  """
  insert_raw_events_one(
    """the row to be inserted"""
    object: raw_events_insert_input!

    """upsert condition"""
    on_conflict: raw_events_on_conflict
  ): raw_events

  """
  update data of the table: "BondingCurve"
  """
  update_BondingCurve(
    """increments the numeric columns with given value of the filtered values"""
    _inc: BondingCurve_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: BondingCurve_set_input

    """filter the rows which have to be updated"""
    where: BondingCurve_bool_exp!
  ): BondingCurve_mutation_response

  """
  update single row of the table: "BondingCurve"
  """
  update_BondingCurve_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: BondingCurve_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: BondingCurve_set_input
    pk_columns: BondingCurve_pk_columns_input!
  ): BondingCurve

  """
  update multiples rows of table: "BondingCurve"
  """
  update_BondingCurve_many(
    """updates to execute, in order"""
    updates: [BondingCurve_updates!]!
  ): [BondingCurve_mutation_response]

  """
  update data of the table: "Bounty"
  """
  update_Bounty(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Bounty_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Bounty_set_input

    """filter the rows which have to be updated"""
    where: Bounty_bool_exp!
  ): Bounty_mutation_response

  """
  update data of the table: "BountyClaim"
  """
  update_BountyClaim(
    """sets the columns of the filtered rows to the given values"""
    _set: BountyClaim_set_input

    """filter the rows which have to be updated"""
    where: BountyClaim_bool_exp!
  ): BountyClaim_mutation_response

  """
  update single row of the table: "BountyClaim"
  """
  update_BountyClaim_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: BountyClaim_set_input
    pk_columns: BountyClaim_pk_columns_input!
  ): BountyClaim

  """
  update multiples rows of table: "BountyClaim"
  """
  update_BountyClaim_many(
    """updates to execute, in order"""
    updates: [BountyClaim_updates!]!
  ): [BountyClaim_mutation_response]

  """
  update data of the table: "BountyContributor"
  """
  update_BountyContributor(
    """increments the numeric columns with given value of the filtered values"""
    _inc: BountyContributor_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: BountyContributor_set_input

    """filter the rows which have to be updated"""
    where: BountyContributor_bool_exp!
  ): BountyContributor_mutation_response

  """
  update single row of the table: "BountyContributor"
  """
  update_BountyContributor_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: BountyContributor_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: BountyContributor_set_input
    pk_columns: BountyContributor_pk_columns_input!
  ): BountyContributor

  """
  update multiples rows of table: "BountyContributor"
  """
  update_BountyContributor_many(
    """updates to execute, in order"""
    updates: [BountyContributor_updates!]!
  ): [BountyContributor_mutation_response]

  """
  update data of the table: "BountyModule"
  """
  update_BountyModule(
    """increments the numeric columns with given value of the filtered values"""
    _inc: BountyModule_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: BountyModule_set_input

    """filter the rows which have to be updated"""
    where: BountyModule_bool_exp!
  ): BountyModule_mutation_response

  """
  update single row of the table: "BountyModule"
  """
  update_BountyModule_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: BountyModule_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: BountyModule_set_input
    pk_columns: BountyModule_pk_columns_input!
  ): BountyModule

  """
  update multiples rows of table: "BountyModule"
  """
  update_BountyModule_many(
    """updates to execute, in order"""
    updates: [BountyModule_updates!]!
  ): [BountyModule_mutation_response]

  """
  update single row of the table: "Bounty"
  """
  update_Bounty_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Bounty_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Bounty_set_input
    pk_columns: Bounty_pk_columns_input!
  ): Bounty

  """
  update multiples rows of table: "Bounty"
  """
  update_Bounty_many(
    """updates to execute, in order"""
    updates: [Bounty_updates!]!
  ): [Bounty_mutation_response]

  """
  update data of the table: "CurveDayData"
  """
  update_CurveDayData(
    """increments the numeric columns with given value of the filtered values"""
    _inc: CurveDayData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: CurveDayData_set_input

    """filter the rows which have to be updated"""
    where: CurveDayData_bool_exp!
  ): CurveDayData_mutation_response

  """
  update single row of the table: "CurveDayData"
  """
  update_CurveDayData_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: CurveDayData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: CurveDayData_set_input
    pk_columns: CurveDayData_pk_columns_input!
  ): CurveDayData

  """
  update multiples rows of table: "CurveDayData"
  """
  update_CurveDayData_many(
    """updates to execute, in order"""
    updates: [CurveDayData_updates!]!
  ): [CurveDayData_mutation_response]

  """
  update data of the table: "CurveHourData"
  """
  update_CurveHourData(
    """increments the numeric columns with given value of the filtered values"""
    _inc: CurveHourData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: CurveHourData_set_input

    """filter the rows which have to be updated"""
    where: CurveHourData_bool_exp!
  ): CurveHourData_mutation_response

  """
  update single row of the table: "CurveHourData"
  """
  update_CurveHourData_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: CurveHourData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: CurveHourData_set_input
    pk_columns: CurveHourData_pk_columns_input!
  ): CurveHourData

  """
  update multiples rows of table: "CurveHourData"
  """
  update_CurveHourData_many(
    """updates to execute, in order"""
    updates: [CurveHourData_updates!]!
  ): [CurveHourData_mutation_response]

  """
  update data of the table: "Deposit"
  """
  update_Deposit(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Deposit_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Deposit_set_input

    """filter the rows which have to be updated"""
    where: Deposit_bool_exp!
  ): Deposit_mutation_response

  """
  update data of the table: "DepositVault"
  """
  update_DepositVault(
    """increments the numeric columns with given value of the filtered values"""
    _inc: DepositVault_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: DepositVault_set_input

    """filter the rows which have to be updated"""
    where: DepositVault_bool_exp!
  ): DepositVault_mutation_response

  """
  update single row of the table: "DepositVault"
  """
  update_DepositVault_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: DepositVault_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: DepositVault_set_input
    pk_columns: DepositVault_pk_columns_input!
  ): DepositVault

  """
  update multiples rows of table: "DepositVault"
  """
  update_DepositVault_many(
    """updates to execute, in order"""
    updates: [DepositVault_updates!]!
  ): [DepositVault_mutation_response]

  """
  update single row of the table: "Deposit"
  """
  update_Deposit_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Deposit_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Deposit_set_input
    pk_columns: Deposit_pk_columns_input!
  ): Deposit

  """
  update multiples rows of table: "Deposit"
  """
  update_Deposit_many(
    """updates to execute, in order"""
    updates: [Deposit_updates!]!
  ): [Deposit_mutation_response]

  """
  update data of the table: "IssuanceTokenDayData"
  """
  update_IssuanceTokenDayData(
    """increments the numeric columns with given value of the filtered values"""
    _inc: IssuanceTokenDayData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: IssuanceTokenDayData_set_input

    """filter the rows which have to be updated"""
    where: IssuanceTokenDayData_bool_exp!
  ): IssuanceTokenDayData_mutation_response

  """
  update single row of the table: "IssuanceTokenDayData"
  """
  update_IssuanceTokenDayData_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: IssuanceTokenDayData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: IssuanceTokenDayData_set_input
    pk_columns: IssuanceTokenDayData_pk_columns_input!
  ): IssuanceTokenDayData

  """
  update multiples rows of table: "IssuanceTokenDayData"
  """
  update_IssuanceTokenDayData_many(
    """updates to execute, in order"""
    updates: [IssuanceTokenDayData_updates!]!
  ): [IssuanceTokenDayData_mutation_response]

  """
  update data of the table: "IssuanceTokenHourData"
  """
  update_IssuanceTokenHourData(
    """increments the numeric columns with given value of the filtered values"""
    _inc: IssuanceTokenHourData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: IssuanceTokenHourData_set_input

    """filter the rows which have to be updated"""
    where: IssuanceTokenHourData_bool_exp!
  ): IssuanceTokenHourData_mutation_response

  """
  update single row of the table: "IssuanceTokenHourData"
  """
  update_IssuanceTokenHourData_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: IssuanceTokenHourData_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: IssuanceTokenHourData_set_input
    pk_columns: IssuanceTokenHourData_pk_columns_input!
  ): IssuanceTokenHourData

  """
  update multiples rows of table: "IssuanceTokenHourData"
  """
  update_IssuanceTokenHourData_many(
    """updates to execute, in order"""
    updates: [IssuanceTokenHourData_updates!]!
  ): [IssuanceTokenHourData_mutation_response]

  """
  update data of the table: "LinearVesting"
  """
  update_LinearVesting(
    """increments the numeric columns with given value of the filtered values"""
    _inc: LinearVesting_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: LinearVesting_set_input

    """filter the rows which have to be updated"""
    where: LinearVesting_bool_exp!
  ): LinearVesting_mutation_response

  """
  update single row of the table: "LinearVesting"
  """
  update_LinearVesting_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: LinearVesting_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: LinearVesting_set_input
    pk_columns: LinearVesting_pk_columns_input!
  ): LinearVesting

  """
  update multiples rows of table: "LinearVesting"
  """
  update_LinearVesting_many(
    """updates to execute, in order"""
    updates: [LinearVesting_updates!]!
  ): [LinearVesting_mutation_response]

  """
  update data of the table: "ProjectFee"
  """
  update_ProjectFee(
    """increments the numeric columns with given value of the filtered values"""
    _inc: ProjectFee_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: ProjectFee_set_input

    """filter the rows which have to be updated"""
    where: ProjectFee_bool_exp!
  ): ProjectFee_mutation_response

  """
  update single row of the table: "ProjectFee"
  """
  update_ProjectFee_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: ProjectFee_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: ProjectFee_set_input
    pk_columns: ProjectFee_pk_columns_input!
  ): ProjectFee

  """
  update multiples rows of table: "ProjectFee"
  """
  update_ProjectFee_many(
    """updates to execute, in order"""
    updates: [ProjectFee_updates!]!
  ): [ProjectFee_mutation_response]

  """
  update data of the table: "ProtocolFee"
  """
  update_ProtocolFee(
    """increments the numeric columns with given value of the filtered values"""
    _inc: ProtocolFee_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: ProtocolFee_set_input

    """filter the rows which have to be updated"""
    where: ProtocolFee_bool_exp!
  ): ProtocolFee_mutation_response

  """
  update single row of the table: "ProtocolFee"
  """
  update_ProtocolFee_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: ProtocolFee_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: ProtocolFee_set_input
    pk_columns: ProtocolFee_pk_columns_input!
  ): ProtocolFee

  """
  update multiples rows of table: "ProtocolFee"
  """
  update_ProtocolFee_many(
    """updates to execute, in order"""
    updates: [ProtocolFee_updates!]!
  ): [ProtocolFee_mutation_response]

  """
  update data of the table: "StreamingPaymentProcessor"
  """
  update_StreamingPaymentProcessor(
    """increments the numeric columns with given value of the filtered values"""
    _inc: StreamingPaymentProcessor_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: StreamingPaymentProcessor_set_input

    """filter the rows which have to be updated"""
    where: StreamingPaymentProcessor_bool_exp!
  ): StreamingPaymentProcessor_mutation_response

  """
  update single row of the table: "StreamingPaymentProcessor"
  """
  update_StreamingPaymentProcessor_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: StreamingPaymentProcessor_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: StreamingPaymentProcessor_set_input
    pk_columns: StreamingPaymentProcessor_pk_columns_input!
  ): StreamingPaymentProcessor

  """
  update multiples rows of table: "StreamingPaymentProcessor"
  """
  update_StreamingPaymentProcessor_many(
    """updates to execute, in order"""
    updates: [StreamingPaymentProcessor_updates!]!
  ): [StreamingPaymentProcessor_mutation_response]

  """
  update data of the table: "Swap"
  """
  update_Swap(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Swap_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Swap_set_input

    """filter the rows which have to be updated"""
    where: Swap_bool_exp!
  ): Swap_mutation_response

  """
  update single row of the table: "Swap"
  """
  update_Swap_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Swap_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Swap_set_input
    pk_columns: Swap_pk_columns_input!
  ): Swap

  """
  update multiples rows of table: "Swap"
  """
  update_Swap_many(
    """updates to execute, in order"""
    updates: [Swap_updates!]!
  ): [Swap_mutation_response]

  """
  update data of the table: "Token"
  """
  update_Token(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Token_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Token_set_input

    """filter the rows which have to be updated"""
    where: Token_bool_exp!
  ): Token_mutation_response

  """
  update single row of the table: "Token"
  """
  update_Token_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Token_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Token_set_input
    pk_columns: Token_pk_columns_input!
  ): Token

  """
  update multiples rows of table: "Token"
  """
  update_Token_many(
    """updates to execute, in order"""
    updates: [Token_updates!]!
  ): [Token_mutation_response]

  """
  update data of the table: "Transfer"
  """
  update_Transfer(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Transfer_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Transfer_set_input

    """filter the rows which have to be updated"""
    where: Transfer_bool_exp!
  ): Transfer_mutation_response

  """
  update single row of the table: "Transfer"
  """
  update_Transfer_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Transfer_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Transfer_set_input
    pk_columns: Transfer_pk_columns_input!
  ): Transfer

  """
  update multiples rows of table: "Transfer"
  """
  update_Transfer_many(
    """updates to execute, in order"""
    updates: [Transfer_updates!]!
  ): [Transfer_mutation_response]

  """
  update data of the table: "Workflow"
  """
  update_Workflow(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Workflow_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Workflow_set_input

    """filter the rows which have to be updated"""
    where: Workflow_bool_exp!
  ): Workflow_mutation_response

  """
  update data of the table: "WorkflowModule"
  """
  update_WorkflowModule(
    """increments the numeric columns with given value of the filtered values"""
    _inc: WorkflowModule_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: WorkflowModule_set_input

    """filter the rows which have to be updated"""
    where: WorkflowModule_bool_exp!
  ): WorkflowModule_mutation_response

  """
  update data of the table: "WorkflowModuleType"
  """
  update_WorkflowModuleType(
    """increments the numeric columns with given value of the filtered values"""
    _inc: WorkflowModuleType_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: WorkflowModuleType_set_input

    """filter the rows which have to be updated"""
    where: WorkflowModuleType_bool_exp!
  ): WorkflowModuleType_mutation_response

  """
  update single row of the table: "WorkflowModuleType"
  """
  update_WorkflowModuleType_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: WorkflowModuleType_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: WorkflowModuleType_set_input
    pk_columns: WorkflowModuleType_pk_columns_input!
  ): WorkflowModuleType

  """
  update multiples rows of table: "WorkflowModuleType"
  """
  update_WorkflowModuleType_many(
    """updates to execute, in order"""
    updates: [WorkflowModuleType_updates!]!
  ): [WorkflowModuleType_mutation_response]

  """
  update single row of the table: "WorkflowModule"
  """
  update_WorkflowModule_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: WorkflowModule_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: WorkflowModule_set_input
    pk_columns: WorkflowModule_pk_columns_input!
  ): WorkflowModule

  """
  update multiples rows of table: "WorkflowModule"
  """
  update_WorkflowModule_many(
    """updates to execute, in order"""
    updates: [WorkflowModule_updates!]!
  ): [WorkflowModule_mutation_response]

  """
  update single row of the table: "Workflow"
  """
  update_Workflow_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: Workflow_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: Workflow_set_input
    pk_columns: Workflow_pk_columns_input!
  ): Workflow

  """
  update multiples rows of table: "Workflow"
  """
  update_Workflow_many(
    """updates to execute, in order"""
    updates: [Workflow_updates!]!
  ): [Workflow_mutation_response]

  """
  update data of the table: "chain_metadata"
  """
  update_chain_metadata(
    """increments the numeric columns with given value of the filtered values"""
    _inc: chain_metadata_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: chain_metadata_set_input

    """filter the rows which have to be updated"""
    where: chain_metadata_bool_exp!
  ): chain_metadata_mutation_response

  """
  update single row of the table: "chain_metadata"
  """
  update_chain_metadata_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: chain_metadata_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: chain_metadata_set_input
    pk_columns: chain_metadata_pk_columns_input!
  ): chain_metadata

  """
  update multiples rows of table: "chain_metadata"
  """
  update_chain_metadata_many(
    """updates to execute, in order"""
    updates: [chain_metadata_updates!]!
  ): [chain_metadata_mutation_response]

  """
  update data of the table: "dynamic_contract_registry"
  """
  update_dynamic_contract_registry(
    """increments the numeric columns with given value of the filtered values"""
    _inc: dynamic_contract_registry_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: dynamic_contract_registry_set_input

    """filter the rows which have to be updated"""
    where: dynamic_contract_registry_bool_exp!
  ): dynamic_contract_registry_mutation_response

  """
  update single row of the table: "dynamic_contract_registry"
  """
  update_dynamic_contract_registry_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: dynamic_contract_registry_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: dynamic_contract_registry_set_input
    pk_columns: dynamic_contract_registry_pk_columns_input!
  ): dynamic_contract_registry

  """
  update multiples rows of table: "dynamic_contract_registry"
  """
  update_dynamic_contract_registry_many(
    """updates to execute, in order"""
    updates: [dynamic_contract_registry_updates!]!
  ): [dynamic_contract_registry_mutation_response]

  """
  update data of the table: "end_of_block_range_scanned_data"
  """
  update_end_of_block_range_scanned_data(
    """increments the numeric columns with given value of the filtered values"""
    _inc: end_of_block_range_scanned_data_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: end_of_block_range_scanned_data_set_input

    """filter the rows which have to be updated"""
    where: end_of_block_range_scanned_data_bool_exp!
  ): end_of_block_range_scanned_data_mutation_response

  """
  update single row of the table: "end_of_block_range_scanned_data"
  """
  update_end_of_block_range_scanned_data_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: end_of_block_range_scanned_data_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: end_of_block_range_scanned_data_set_input
    pk_columns: end_of_block_range_scanned_data_pk_columns_input!
  ): end_of_block_range_scanned_data

  """
  update multiples rows of table: "end_of_block_range_scanned_data"
  """
  update_end_of_block_range_scanned_data_many(
    """updates to execute, in order"""
    updates: [end_of_block_range_scanned_data_updates!]!
  ): [end_of_block_range_scanned_data_mutation_response]

  """
  update data of the table: "event_sync_state"
  """
  update_event_sync_state(
    """increments the numeric columns with given value of the filtered values"""
    _inc: event_sync_state_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: event_sync_state_set_input

    """filter the rows which have to be updated"""
    where: event_sync_state_bool_exp!
  ): event_sync_state_mutation_response

  """
  update single row of the table: "event_sync_state"
  """
  update_event_sync_state_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: event_sync_state_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: event_sync_state_set_input
    pk_columns: event_sync_state_pk_columns_input!
  ): event_sync_state

  """
  update multiples rows of table: "event_sync_state"
  """
  update_event_sync_state_many(
    """updates to execute, in order"""
    updates: [event_sync_state_updates!]!
  ): [event_sync_state_mutation_response]

  """
  update data of the table: "persisted_state"
  """
  update_persisted_state(
    """increments the numeric columns with given value of the filtered values"""
    _inc: persisted_state_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: persisted_state_set_input

    """filter the rows which have to be updated"""
    where: persisted_state_bool_exp!
  ): persisted_state_mutation_response

  """
  update single row of the table: "persisted_state"
  """
  update_persisted_state_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: persisted_state_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: persisted_state_set_input
    pk_columns: persisted_state_pk_columns_input!
  ): persisted_state

  """
  update multiples rows of table: "persisted_state"
  """
  update_persisted_state_many(
    """updates to execute, in order"""
    updates: [persisted_state_updates!]!
  ): [persisted_state_mutation_response]

  """
  update data of the table: "raw_events"
  """
  update_raw_events(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: raw_events_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: raw_events_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: raw_events_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: raw_events_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: raw_events_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: raw_events_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: raw_events_set_input

    """filter the rows which have to be updated"""
    where: raw_events_bool_exp!
  ): raw_events_mutation_response

  """
  update single row of the table: "raw_events"
  """
  update_raw_events_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: raw_events_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: raw_events_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: raw_events_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: raw_events_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: raw_events_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: raw_events_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: raw_events_set_input
    pk_columns: raw_events_pk_columns_input!
  ): raw_events

  """
  update multiples rows of table: "raw_events"
  """
  update_raw_events_many(
    """updates to execute, in order"""
    updates: [raw_events_updates!]!
  ): [raw_events_mutation_response]
}

scalar numeric

"""
Boolean expression to compare columns of type "numeric". All fields are combined with logical 'AND'.
"""
input numeric_comparison_exp {
  _eq: numeric
  _gt: numeric
  _gte: numeric
  _in: [numeric!]
  _is_null: Boolean
  _lt: numeric
  _lte: numeric
  _neq: numeric
  _nin: [numeric!]
}

"""column ordering options"""
enum order_by {
  """in ascending order, nulls last"""
  asc

  """in ascending order, nulls first"""
  asc_nulls_first

  """in ascending order, nulls last"""
  asc_nulls_last

  """in descending order, nulls first"""
  desc

  """in descending order, nulls first"""
  desc_nulls_first

  """in descending order, nulls last"""
  desc_nulls_last
}

"""
columns and relationships of "persisted_state"
"""
type persisted_state {
  abi_files_hash: String!
  config_hash: String!
  envio_version: String!
  handler_files_hash: String!
  id: Int!
  schema_hash: String!
}

"""
aggregated selection of "persisted_state"
"""
type persisted_state_aggregate {
  aggregate: persisted_state_aggregate_fields
  nodes: [persisted_state!]!
}

"""
aggregate fields of "persisted_state"
"""
type persisted_state_aggregate_fields {
  avg: persisted_state_avg_fields
  count(columns: [persisted_state_select_column!], distinct: Boolean): Int!
  max: persisted_state_max_fields
  min: persisted_state_min_fields
  stddev: persisted_state_stddev_fields
  stddev_pop: persisted_state_stddev_pop_fields
  stddev_samp: persisted_state_stddev_samp_fields
  sum: persisted_state_sum_fields
  var_pop: persisted_state_var_pop_fields
  var_samp: persisted_state_var_samp_fields
  variance: persisted_state_variance_fields
}

"""aggregate avg on columns"""
type persisted_state_avg_fields {
  id: Float
}

"""
Boolean expression to filter rows from the table "persisted_state". All fields are combined with a logical 'AND'.
"""
input persisted_state_bool_exp {
  _and: [persisted_state_bool_exp!]
  _not: persisted_state_bool_exp
  _or: [persisted_state_bool_exp!]
  abi_files_hash: String_comparison_exp
  config_hash: String_comparison_exp
  envio_version: String_comparison_exp
  handler_files_hash: String_comparison_exp
  id: Int_comparison_exp
  schema_hash: String_comparison_exp
}

"""
unique or primary key constraints on table "persisted_state"
"""
enum persisted_state_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  persisted_state_pkey
}

"""
input type for incrementing numeric columns in table "persisted_state"
"""
input persisted_state_inc_input {
  id: Int
}

"""
input type for inserting data into table "persisted_state"
"""
input persisted_state_insert_input {
  abi_files_hash: String
  config_hash: String
  envio_version: String
  handler_files_hash: String
  id: Int
  schema_hash: String
}

"""aggregate max on columns"""
type persisted_state_max_fields {
  abi_files_hash: String
  config_hash: String
  envio_version: String
  handler_files_hash: String
  id: Int
  schema_hash: String
}

"""aggregate min on columns"""
type persisted_state_min_fields {
  abi_files_hash: String
  config_hash: String
  envio_version: String
  handler_files_hash: String
  id: Int
  schema_hash: String
}

"""
response of any mutation on the table "persisted_state"
"""
type persisted_state_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [persisted_state!]!
}

"""
on_conflict condition type for table "persisted_state"
"""
input persisted_state_on_conflict {
  constraint: persisted_state_constraint!
  update_columns: [persisted_state_update_column!]! = []
  where: persisted_state_bool_exp
}

"""Ordering options when selecting data from "persisted_state"."""
input persisted_state_order_by {
  abi_files_hash: order_by
  config_hash: order_by
  envio_version: order_by
  handler_files_hash: order_by
  id: order_by
  schema_hash: order_by
}

"""primary key columns input for table: persisted_state"""
input persisted_state_pk_columns_input {
  id: Int!
}

"""
select columns of table "persisted_state"
"""
enum persisted_state_select_column {
  """column name"""
  abi_files_hash

  """column name"""
  config_hash

  """column name"""
  envio_version

  """column name"""
  handler_files_hash

  """column name"""
  id

  """column name"""
  schema_hash
}

"""
input type for updating data in table "persisted_state"
"""
input persisted_state_set_input {
  abi_files_hash: String
  config_hash: String
  envio_version: String
  handler_files_hash: String
  id: Int
  schema_hash: String
}

"""aggregate stddev on columns"""
type persisted_state_stddev_fields {
  id: Float
}

"""aggregate stddev_pop on columns"""
type persisted_state_stddev_pop_fields {
  id: Float
}

"""aggregate stddev_samp on columns"""
type persisted_state_stddev_samp_fields {
  id: Float
}

"""
Streaming cursor of the table "persisted_state"
"""
input persisted_state_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: persisted_state_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input persisted_state_stream_cursor_value_input {
  abi_files_hash: String
  config_hash: String
  envio_version: String
  handler_files_hash: String
  id: Int
  schema_hash: String
}

"""aggregate sum on columns"""
type persisted_state_sum_fields {
  id: Int
}

"""
update columns of table "persisted_state"
"""
enum persisted_state_update_column {
  """column name"""
  abi_files_hash

  """column name"""
  config_hash

  """column name"""
  envio_version

  """column name"""
  handler_files_hash

  """column name"""
  id

  """column name"""
  schema_hash
}

input persisted_state_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: persisted_state_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: persisted_state_set_input

  """filter the rows which have to be updated"""
  where: persisted_state_bool_exp!
}

"""aggregate var_pop on columns"""
type persisted_state_var_pop_fields {
  id: Float
}

"""aggregate var_samp on columns"""
type persisted_state_var_samp_fields {
  id: Float
}

"""aggregate variance on columns"""
type persisted_state_variance_fields {
  id: Float
}

type query_root {
  """
  fetch data from the table: "BondingCurve"
  """
  BondingCurve(
    """distinct select on columns"""
    distinct_on: [BondingCurve_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BondingCurve_order_by!]

    """filter the rows returned"""
    where: BondingCurve_bool_exp
  ): [BondingCurve!]!

  """
  fetch aggregated fields from the table: "BondingCurve"
  """
  BondingCurve_aggregate(
    """distinct select on columns"""
    distinct_on: [BondingCurve_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BondingCurve_order_by!]

    """filter the rows returned"""
    where: BondingCurve_bool_exp
  ): BondingCurve_aggregate!

  """fetch data from the table: "BondingCurve" using primary key columns"""
  BondingCurve_by_pk(id: String!): BondingCurve

  """
  fetch data from the table: "Bounty"
  """
  Bounty(
    """distinct select on columns"""
    distinct_on: [Bounty_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Bounty_order_by!]

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): [Bounty!]!

  """
  fetch data from the table: "BountyClaim"
  """
  BountyClaim(
    """distinct select on columns"""
    distinct_on: [BountyClaim_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyClaim_order_by!]

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): [BountyClaim!]!

  """
  fetch aggregated fields from the table: "BountyClaim"
  """
  BountyClaim_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyClaim_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyClaim_order_by!]

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): BountyClaim_aggregate!

  """fetch data from the table: "BountyClaim" using primary key columns"""
  BountyClaim_by_pk(id: String!): BountyClaim

  """
  fetch data from the table: "BountyContributor"
  """
  BountyContributor(
    """distinct select on columns"""
    distinct_on: [BountyContributor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyContributor_order_by!]

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): [BountyContributor!]!

  """
  fetch aggregated fields from the table: "BountyContributor"
  """
  BountyContributor_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyContributor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyContributor_order_by!]

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): BountyContributor_aggregate!

  """
  fetch data from the table: "BountyContributor" using primary key columns
  """
  BountyContributor_by_pk(id: String!): BountyContributor

  """
  fetch data from the table: "BountyModule"
  """
  BountyModule(
    """distinct select on columns"""
    distinct_on: [BountyModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyModule_order_by!]

    """filter the rows returned"""
    where: BountyModule_bool_exp
  ): [BountyModule!]!

  """
  fetch aggregated fields from the table: "BountyModule"
  """
  BountyModule_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyModule_order_by!]

    """filter the rows returned"""
    where: BountyModule_bool_exp
  ): BountyModule_aggregate!

  """fetch data from the table: "BountyModule" using primary key columns"""
  BountyModule_by_pk(id: String!): BountyModule

  """
  fetch aggregated fields from the table: "Bounty"
  """
  Bounty_aggregate(
    """distinct select on columns"""
    distinct_on: [Bounty_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Bounty_order_by!]

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): Bounty_aggregate!

  """fetch data from the table: "Bounty" using primary key columns"""
  Bounty_by_pk(id: String!): Bounty

  """
  fetch data from the table: "CurveDayData"
  """
  CurveDayData(
    """distinct select on columns"""
    distinct_on: [CurveDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveDayData_order_by!]

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): [CurveDayData!]!

  """
  fetch aggregated fields from the table: "CurveDayData"
  """
  CurveDayData_aggregate(
    """distinct select on columns"""
    distinct_on: [CurveDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveDayData_order_by!]

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): CurveDayData_aggregate!

  """fetch data from the table: "CurveDayData" using primary key columns"""
  CurveDayData_by_pk(id: String!): CurveDayData

  """
  fetch data from the table: "CurveHourData"
  """
  CurveHourData(
    """distinct select on columns"""
    distinct_on: [CurveHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveHourData_order_by!]

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): [CurveHourData!]!

  """
  fetch aggregated fields from the table: "CurveHourData"
  """
  CurveHourData_aggregate(
    """distinct select on columns"""
    distinct_on: [CurveHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveHourData_order_by!]

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): CurveHourData_aggregate!

  """fetch data from the table: "CurveHourData" using primary key columns"""
  CurveHourData_by_pk(id: String!): CurveHourData

  """
  fetch data from the table: "Deposit"
  """
  Deposit(
    """distinct select on columns"""
    distinct_on: [Deposit_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Deposit_order_by!]

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): [Deposit!]!

  """
  fetch data from the table: "DepositVault"
  """
  DepositVault(
    """distinct select on columns"""
    distinct_on: [DepositVault_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [DepositVault_order_by!]

    """filter the rows returned"""
    where: DepositVault_bool_exp
  ): [DepositVault!]!

  """
  fetch aggregated fields from the table: "DepositVault"
  """
  DepositVault_aggregate(
    """distinct select on columns"""
    distinct_on: [DepositVault_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [DepositVault_order_by!]

    """filter the rows returned"""
    where: DepositVault_bool_exp
  ): DepositVault_aggregate!

  """fetch data from the table: "DepositVault" using primary key columns"""
  DepositVault_by_pk(id: String!): DepositVault

  """
  fetch aggregated fields from the table: "Deposit"
  """
  Deposit_aggregate(
    """distinct select on columns"""
    distinct_on: [Deposit_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Deposit_order_by!]

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): Deposit_aggregate!

  """fetch data from the table: "Deposit" using primary key columns"""
  Deposit_by_pk(id: String!): Deposit

  """
  fetch data from the table: "IssuanceTokenDayData"
  """
  IssuanceTokenDayData(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenDayData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): [IssuanceTokenDayData!]!

  """
  fetch aggregated fields from the table: "IssuanceTokenDayData"
  """
  IssuanceTokenDayData_aggregate(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenDayData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): IssuanceTokenDayData_aggregate!

  """
  fetch data from the table: "IssuanceTokenDayData" using primary key columns
  """
  IssuanceTokenDayData_by_pk(id: String!): IssuanceTokenDayData

  """
  fetch data from the table: "IssuanceTokenHourData"
  """
  IssuanceTokenHourData(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenHourData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): [IssuanceTokenHourData!]!

  """
  fetch aggregated fields from the table: "IssuanceTokenHourData"
  """
  IssuanceTokenHourData_aggregate(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenHourData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): IssuanceTokenHourData_aggregate!

  """
  fetch data from the table: "IssuanceTokenHourData" using primary key columns
  """
  IssuanceTokenHourData_by_pk(id: String!): IssuanceTokenHourData

  """
  fetch data from the table: "LinearVesting"
  """
  LinearVesting(
    """distinct select on columns"""
    distinct_on: [LinearVesting_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [LinearVesting_order_by!]

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): [LinearVesting!]!

  """
  fetch aggregated fields from the table: "LinearVesting"
  """
  LinearVesting_aggregate(
    """distinct select on columns"""
    distinct_on: [LinearVesting_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [LinearVesting_order_by!]

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): LinearVesting_aggregate!

  """fetch data from the table: "LinearVesting" using primary key columns"""
  LinearVesting_by_pk(id: String!): LinearVesting

  """
  fetch data from the table: "ProjectFee"
  """
  ProjectFee(
    """distinct select on columns"""
    distinct_on: [ProjectFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProjectFee_order_by!]

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): [ProjectFee!]!

  """
  fetch aggregated fields from the table: "ProjectFee"
  """
  ProjectFee_aggregate(
    """distinct select on columns"""
    distinct_on: [ProjectFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProjectFee_order_by!]

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): ProjectFee_aggregate!

  """fetch data from the table: "ProjectFee" using primary key columns"""
  ProjectFee_by_pk(id: String!): ProjectFee

  """
  fetch data from the table: "ProtocolFee"
  """
  ProtocolFee(
    """distinct select on columns"""
    distinct_on: [ProtocolFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProtocolFee_order_by!]

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): [ProtocolFee!]!

  """
  fetch aggregated fields from the table: "ProtocolFee"
  """
  ProtocolFee_aggregate(
    """distinct select on columns"""
    distinct_on: [ProtocolFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProtocolFee_order_by!]

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): ProtocolFee_aggregate!

  """fetch data from the table: "ProtocolFee" using primary key columns"""
  ProtocolFee_by_pk(id: String!): ProtocolFee

  """
  fetch data from the table: "StreamingPaymentProcessor"
  """
  StreamingPaymentProcessor(
    """distinct select on columns"""
    distinct_on: [StreamingPaymentProcessor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [StreamingPaymentProcessor_order_by!]

    """filter the rows returned"""
    where: StreamingPaymentProcessor_bool_exp
  ): [StreamingPaymentProcessor!]!

  """
  fetch aggregated fields from the table: "StreamingPaymentProcessor"
  """
  StreamingPaymentProcessor_aggregate(
    """distinct select on columns"""
    distinct_on: [StreamingPaymentProcessor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [StreamingPaymentProcessor_order_by!]

    """filter the rows returned"""
    where: StreamingPaymentProcessor_bool_exp
  ): StreamingPaymentProcessor_aggregate!

  """
  fetch data from the table: "StreamingPaymentProcessor" using primary key columns
  """
  StreamingPaymentProcessor_by_pk(id: String!): StreamingPaymentProcessor

  """
  fetch data from the table: "Swap"
  """
  Swap(
    """distinct select on columns"""
    distinct_on: [Swap_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Swap_order_by!]

    """filter the rows returned"""
    where: Swap_bool_exp
  ): [Swap!]!

  """
  fetch aggregated fields from the table: "Swap"
  """
  Swap_aggregate(
    """distinct select on columns"""
    distinct_on: [Swap_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Swap_order_by!]

    """filter the rows returned"""
    where: Swap_bool_exp
  ): Swap_aggregate!

  """fetch data from the table: "Swap" using primary key columns"""
  Swap_by_pk(id: String!): Swap

  """
  fetch data from the table: "Token"
  """
  Token(
    """distinct select on columns"""
    distinct_on: [Token_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Token_order_by!]

    """filter the rows returned"""
    where: Token_bool_exp
  ): [Token!]!

  """
  fetch aggregated fields from the table: "Token"
  """
  Token_aggregate(
    """distinct select on columns"""
    distinct_on: [Token_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Token_order_by!]

    """filter the rows returned"""
    where: Token_bool_exp
  ): Token_aggregate!

  """fetch data from the table: "Token" using primary key columns"""
  Token_by_pk(id: String!): Token

  """
  fetch data from the table: "Transfer"
  """
  Transfer(
    """distinct select on columns"""
    distinct_on: [Transfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Transfer_order_by!]

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): [Transfer!]!

  """
  fetch aggregated fields from the table: "Transfer"
  """
  Transfer_aggregate(
    """distinct select on columns"""
    distinct_on: [Transfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Transfer_order_by!]

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): Transfer_aggregate!

  """fetch data from the table: "Transfer" using primary key columns"""
  Transfer_by_pk(id: String!): Transfer

  """
  fetch data from the table: "Workflow"
  """
  Workflow(
    """distinct select on columns"""
    distinct_on: [Workflow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Workflow_order_by!]

    """filter the rows returned"""
    where: Workflow_bool_exp
  ): [Workflow!]!

  """
  fetch data from the table: "WorkflowModule"
  """
  WorkflowModule(
    """distinct select on columns"""
    distinct_on: [WorkflowModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModule_order_by!]

    """filter the rows returned"""
    where: WorkflowModule_bool_exp
  ): [WorkflowModule!]!

  """
  fetch data from the table: "WorkflowModuleType"
  """
  WorkflowModuleType(
    """distinct select on columns"""
    distinct_on: [WorkflowModuleType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModuleType_order_by!]

    """filter the rows returned"""
    where: WorkflowModuleType_bool_exp
  ): [WorkflowModuleType!]!

  """
  fetch aggregated fields from the table: "WorkflowModuleType"
  """
  WorkflowModuleType_aggregate(
    """distinct select on columns"""
    distinct_on: [WorkflowModuleType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModuleType_order_by!]

    """filter the rows returned"""
    where: WorkflowModuleType_bool_exp
  ): WorkflowModuleType_aggregate!

  """
  fetch data from the table: "WorkflowModuleType" using primary key columns
  """
  WorkflowModuleType_by_pk(id: String!): WorkflowModuleType

  """
  fetch aggregated fields from the table: "WorkflowModule"
  """
  WorkflowModule_aggregate(
    """distinct select on columns"""
    distinct_on: [WorkflowModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModule_order_by!]

    """filter the rows returned"""
    where: WorkflowModule_bool_exp
  ): WorkflowModule_aggregate!

  """fetch data from the table: "WorkflowModule" using primary key columns"""
  WorkflowModule_by_pk(id: String!): WorkflowModule

  """
  fetch aggregated fields from the table: "Workflow"
  """
  Workflow_aggregate(
    """distinct select on columns"""
    distinct_on: [Workflow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Workflow_order_by!]

    """filter the rows returned"""
    where: Workflow_bool_exp
  ): Workflow_aggregate!

  """fetch data from the table: "Workflow" using primary key columns"""
  Workflow_by_pk(id: String!): Workflow

  """
  fetch data from the table: "chain_metadata"
  """
  chain_metadata(
    """distinct select on columns"""
    distinct_on: [chain_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [chain_metadata_order_by!]

    """filter the rows returned"""
    where: chain_metadata_bool_exp
  ): [chain_metadata!]!

  """
  fetch aggregated fields from the table: "chain_metadata"
  """
  chain_metadata_aggregate(
    """distinct select on columns"""
    distinct_on: [chain_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [chain_metadata_order_by!]

    """filter the rows returned"""
    where: chain_metadata_bool_exp
  ): chain_metadata_aggregate!

  """fetch data from the table: "chain_metadata" using primary key columns"""
  chain_metadata_by_pk(chain_id: Int!): chain_metadata

  """
  fetch data from the table: "dynamic_contract_registry"
  """
  dynamic_contract_registry(
    """distinct select on columns"""
    distinct_on: [dynamic_contract_registry_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [dynamic_contract_registry_order_by!]

    """filter the rows returned"""
    where: dynamic_contract_registry_bool_exp
  ): [dynamic_contract_registry!]!

  """
  fetch aggregated fields from the table: "dynamic_contract_registry"
  """
  dynamic_contract_registry_aggregate(
    """distinct select on columns"""
    distinct_on: [dynamic_contract_registry_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [dynamic_contract_registry_order_by!]

    """filter the rows returned"""
    where: dynamic_contract_registry_bool_exp
  ): dynamic_contract_registry_aggregate!

  """
  fetch data from the table: "dynamic_contract_registry" using primary key columns
  """
  dynamic_contract_registry_by_pk(id: String!): dynamic_contract_registry

  """
  fetch data from the table: "end_of_block_range_scanned_data"
  """
  end_of_block_range_scanned_data(
    """distinct select on columns"""
    distinct_on: [end_of_block_range_scanned_data_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [end_of_block_range_scanned_data_order_by!]

    """filter the rows returned"""
    where: end_of_block_range_scanned_data_bool_exp
  ): [end_of_block_range_scanned_data!]!

  """
  fetch aggregated fields from the table: "end_of_block_range_scanned_data"
  """
  end_of_block_range_scanned_data_aggregate(
    """distinct select on columns"""
    distinct_on: [end_of_block_range_scanned_data_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [end_of_block_range_scanned_data_order_by!]

    """filter the rows returned"""
    where: end_of_block_range_scanned_data_bool_exp
  ): end_of_block_range_scanned_data_aggregate!

  """
  fetch data from the table: "end_of_block_range_scanned_data" using primary key columns
  """
  end_of_block_range_scanned_data_by_pk(block_number: Int!, chain_id: Int!): end_of_block_range_scanned_data

  """
  fetch data from the table: "event_sync_state"
  """
  event_sync_state(
    """distinct select on columns"""
    distinct_on: [event_sync_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [event_sync_state_order_by!]

    """filter the rows returned"""
    where: event_sync_state_bool_exp
  ): [event_sync_state!]!

  """
  fetch aggregated fields from the table: "event_sync_state"
  """
  event_sync_state_aggregate(
    """distinct select on columns"""
    distinct_on: [event_sync_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [event_sync_state_order_by!]

    """filter the rows returned"""
    where: event_sync_state_bool_exp
  ): event_sync_state_aggregate!

  """
  fetch data from the table: "event_sync_state" using primary key columns
  """
  event_sync_state_by_pk(chain_id: Int!): event_sync_state

  """
  fetch data from the table: "persisted_state"
  """
  persisted_state(
    """distinct select on columns"""
    distinct_on: [persisted_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [persisted_state_order_by!]

    """filter the rows returned"""
    where: persisted_state_bool_exp
  ): [persisted_state!]!

  """
  fetch aggregated fields from the table: "persisted_state"
  """
  persisted_state_aggregate(
    """distinct select on columns"""
    distinct_on: [persisted_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [persisted_state_order_by!]

    """filter the rows returned"""
    where: persisted_state_bool_exp
  ): persisted_state_aggregate!

  """fetch data from the table: "persisted_state" using primary key columns"""
  persisted_state_by_pk(id: Int!): persisted_state

  """
  fetch data from the table: "raw_events"
  """
  raw_events(
    """distinct select on columns"""
    distinct_on: [raw_events_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [raw_events_order_by!]

    """filter the rows returned"""
    where: raw_events_bool_exp
  ): [raw_events!]!

  """
  fetch aggregated fields from the table: "raw_events"
  """
  raw_events_aggregate(
    """distinct select on columns"""
    distinct_on: [raw_events_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [raw_events_order_by!]

    """filter the rows returned"""
    where: raw_events_bool_exp
  ): raw_events_aggregate!

  """fetch data from the table: "raw_events" using primary key columns"""
  raw_events_by_pk(serial: Int!): raw_events
}

"""
columns and relationships of "raw_events"
"""
type raw_events {
  block_fields(
    """JSON select path"""
    path: String
  ): jsonb!
  block_hash: String!
  block_number: Int!
  block_timestamp: Int!
  chain_id: Int!
  contract_name: String!
  db_write_timestamp: timestamp
  event_id: numeric!
  event_name: String!
  log_index: Int!
  params(
    """JSON select path"""
    path: String
  ): jsonb!
  serial: Int!
  src_address: String!
  transaction_fields(
    """JSON select path"""
    path: String
  ): jsonb!
}

"""
aggregated selection of "raw_events"
"""
type raw_events_aggregate {
  aggregate: raw_events_aggregate_fields
  nodes: [raw_events!]!
}

"""
aggregate fields of "raw_events"
"""
type raw_events_aggregate_fields {
  avg: raw_events_avg_fields
  count(columns: [raw_events_select_column!], distinct: Boolean): Int!
  max: raw_events_max_fields
  min: raw_events_min_fields
  stddev: raw_events_stddev_fields
  stddev_pop: raw_events_stddev_pop_fields
  stddev_samp: raw_events_stddev_samp_fields
  sum: raw_events_sum_fields
  var_pop: raw_events_var_pop_fields
  var_samp: raw_events_var_samp_fields
  variance: raw_events_variance_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input raw_events_append_input {
  block_fields: jsonb
  params: jsonb
  transaction_fields: jsonb
}

"""aggregate avg on columns"""
type raw_events_avg_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

"""
Boolean expression to filter rows from the table "raw_events". All fields are combined with a logical 'AND'.
"""
input raw_events_bool_exp {
  _and: [raw_events_bool_exp!]
  _not: raw_events_bool_exp
  _or: [raw_events_bool_exp!]
  block_fields: jsonb_comparison_exp
  block_hash: String_comparison_exp
  block_number: Int_comparison_exp
  block_timestamp: Int_comparison_exp
  chain_id: Int_comparison_exp
  contract_name: String_comparison_exp
  db_write_timestamp: timestamp_comparison_exp
  event_id: numeric_comparison_exp
  event_name: String_comparison_exp
  log_index: Int_comparison_exp
  params: jsonb_comparison_exp
  serial: Int_comparison_exp
  src_address: String_comparison_exp
  transaction_fields: jsonb_comparison_exp
}

"""
unique or primary key constraints on table "raw_events"
"""
enum raw_events_constraint {
  """
  unique or primary key constraint on columns "serial"
  """
  raw_events_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input raw_events_delete_at_path_input {
  block_fields: [String!]
  params: [String!]
  transaction_fields: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input raw_events_delete_elem_input {
  block_fields: Int
  params: Int
  transaction_fields: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input raw_events_delete_key_input {
  block_fields: String
  params: String
  transaction_fields: String
}

"""
input type for incrementing numeric columns in table "raw_events"
"""
input raw_events_inc_input {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  event_id: numeric
  log_index: Int
  serial: Int
}

"""
input type for inserting data into table "raw_events"
"""
input raw_events_insert_input {
  block_fields: jsonb
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  contract_name: String
  db_write_timestamp: timestamp
  event_id: numeric
  event_name: String
  log_index: Int
  params: jsonb
  serial: Int
  src_address: String
  transaction_fields: jsonb
}

"""aggregate max on columns"""
type raw_events_max_fields {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  contract_name: String
  db_write_timestamp: timestamp
  event_id: numeric
  event_name: String
  log_index: Int
  serial: Int
  src_address: String
}

"""aggregate min on columns"""
type raw_events_min_fields {
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  contract_name: String
  db_write_timestamp: timestamp
  event_id: numeric
  event_name: String
  log_index: Int
  serial: Int
  src_address: String
}

"""
response of any mutation on the table "raw_events"
"""
type raw_events_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [raw_events!]!
}

"""
on_conflict condition type for table "raw_events"
"""
input raw_events_on_conflict {
  constraint: raw_events_constraint!
  update_columns: [raw_events_update_column!]! = []
  where: raw_events_bool_exp
}

"""Ordering options when selecting data from "raw_events"."""
input raw_events_order_by {
  block_fields: order_by
  block_hash: order_by
  block_number: order_by
  block_timestamp: order_by
  chain_id: order_by
  contract_name: order_by
  db_write_timestamp: order_by
  event_id: order_by
  event_name: order_by
  log_index: order_by
  params: order_by
  serial: order_by
  src_address: order_by
  transaction_fields: order_by
}

"""primary key columns input for table: raw_events"""
input raw_events_pk_columns_input {
  serial: Int!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input raw_events_prepend_input {
  block_fields: jsonb
  params: jsonb
  transaction_fields: jsonb
}

"""
select columns of table "raw_events"
"""
enum raw_events_select_column {
  """column name"""
  block_fields

  """column name"""
  block_hash

  """column name"""
  block_number

  """column name"""
  block_timestamp

  """column name"""
  chain_id

  """column name"""
  contract_name

  """column name"""
  db_write_timestamp

  """column name"""
  event_id

  """column name"""
  event_name

  """column name"""
  log_index

  """column name"""
  params

  """column name"""
  serial

  """column name"""
  src_address

  """column name"""
  transaction_fields
}

"""
input type for updating data in table "raw_events"
"""
input raw_events_set_input {
  block_fields: jsonb
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  contract_name: String
  db_write_timestamp: timestamp
  event_id: numeric
  event_name: String
  log_index: Int
  params: jsonb
  serial: Int
  src_address: String
  transaction_fields: jsonb
}

"""aggregate stddev on columns"""
type raw_events_stddev_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

"""aggregate stddev_pop on columns"""
type raw_events_stddev_pop_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

"""aggregate stddev_samp on columns"""
type raw_events_stddev_samp_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

"""
Streaming cursor of the table "raw_events"
"""
input raw_events_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: raw_events_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input raw_events_stream_cursor_value_input {
  block_fields: jsonb
  block_hash: String
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  contract_name: String
  db_write_timestamp: timestamp
  event_id: numeric
  event_name: String
  log_index: Int
  params: jsonb
  serial: Int
  src_address: String
  transaction_fields: jsonb
}

"""aggregate sum on columns"""
type raw_events_sum_fields {
  block_number: Int
  block_timestamp: Int
  chain_id: Int
  event_id: numeric
  log_index: Int
  serial: Int
}

"""
update columns of table "raw_events"
"""
enum raw_events_update_column {
  """column name"""
  block_fields

  """column name"""
  block_hash

  """column name"""
  block_number

  """column name"""
  block_timestamp

  """column name"""
  chain_id

  """column name"""
  contract_name

  """column name"""
  db_write_timestamp

  """column name"""
  event_id

  """column name"""
  event_name

  """column name"""
  log_index

  """column name"""
  params

  """column name"""
  serial

  """column name"""
  src_address

  """column name"""
  transaction_fields
}

input raw_events_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: raw_events_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: raw_events_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: raw_events_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: raw_events_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: raw_events_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: raw_events_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: raw_events_set_input

  """filter the rows which have to be updated"""
  where: raw_events_bool_exp!
}

"""aggregate var_pop on columns"""
type raw_events_var_pop_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

"""aggregate var_samp on columns"""
type raw_events_var_samp_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

"""aggregate variance on columns"""
type raw_events_variance_fields {
  block_number: Float
  block_timestamp: Float
  chain_id: Float
  event_id: Float
  log_index: Float
  serial: Float
}

type subscription_root {
  """
  fetch data from the table: "BondingCurve"
  """
  BondingCurve(
    """distinct select on columns"""
    distinct_on: [BondingCurve_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BondingCurve_order_by!]

    """filter the rows returned"""
    where: BondingCurve_bool_exp
  ): [BondingCurve!]!

  """
  fetch aggregated fields from the table: "BondingCurve"
  """
  BondingCurve_aggregate(
    """distinct select on columns"""
    distinct_on: [BondingCurve_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BondingCurve_order_by!]

    """filter the rows returned"""
    where: BondingCurve_bool_exp
  ): BondingCurve_aggregate!

  """fetch data from the table: "BondingCurve" using primary key columns"""
  BondingCurve_by_pk(id: String!): BondingCurve

  """
  fetch data from the table in a streaming manner: "BondingCurve"
  """
  BondingCurve_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [BondingCurve_stream_cursor_input]!

    """filter the rows returned"""
    where: BondingCurve_bool_exp
  ): [BondingCurve!]!

  """
  fetch data from the table: "Bounty"
  """
  Bounty(
    """distinct select on columns"""
    distinct_on: [Bounty_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Bounty_order_by!]

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): [Bounty!]!

  """
  fetch data from the table: "BountyClaim"
  """
  BountyClaim(
    """distinct select on columns"""
    distinct_on: [BountyClaim_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyClaim_order_by!]

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): [BountyClaim!]!

  """
  fetch aggregated fields from the table: "BountyClaim"
  """
  BountyClaim_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyClaim_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyClaim_order_by!]

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): BountyClaim_aggregate!

  """fetch data from the table: "BountyClaim" using primary key columns"""
  BountyClaim_by_pk(id: String!): BountyClaim

  """
  fetch data from the table in a streaming manner: "BountyClaim"
  """
  BountyClaim_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [BountyClaim_stream_cursor_input]!

    """filter the rows returned"""
    where: BountyClaim_bool_exp
  ): [BountyClaim!]!

  """
  fetch data from the table: "BountyContributor"
  """
  BountyContributor(
    """distinct select on columns"""
    distinct_on: [BountyContributor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyContributor_order_by!]

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): [BountyContributor!]!

  """
  fetch aggregated fields from the table: "BountyContributor"
  """
  BountyContributor_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyContributor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyContributor_order_by!]

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): BountyContributor_aggregate!

  """
  fetch data from the table: "BountyContributor" using primary key columns
  """
  BountyContributor_by_pk(id: String!): BountyContributor

  """
  fetch data from the table in a streaming manner: "BountyContributor"
  """
  BountyContributor_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [BountyContributor_stream_cursor_input]!

    """filter the rows returned"""
    where: BountyContributor_bool_exp
  ): [BountyContributor!]!

  """
  fetch data from the table: "BountyModule"
  """
  BountyModule(
    """distinct select on columns"""
    distinct_on: [BountyModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyModule_order_by!]

    """filter the rows returned"""
    where: BountyModule_bool_exp
  ): [BountyModule!]!

  """
  fetch aggregated fields from the table: "BountyModule"
  """
  BountyModule_aggregate(
    """distinct select on columns"""
    distinct_on: [BountyModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [BountyModule_order_by!]

    """filter the rows returned"""
    where: BountyModule_bool_exp
  ): BountyModule_aggregate!

  """fetch data from the table: "BountyModule" using primary key columns"""
  BountyModule_by_pk(id: String!): BountyModule

  """
  fetch data from the table in a streaming manner: "BountyModule"
  """
  BountyModule_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [BountyModule_stream_cursor_input]!

    """filter the rows returned"""
    where: BountyModule_bool_exp
  ): [BountyModule!]!

  """
  fetch aggregated fields from the table: "Bounty"
  """
  Bounty_aggregate(
    """distinct select on columns"""
    distinct_on: [Bounty_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Bounty_order_by!]

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): Bounty_aggregate!

  """fetch data from the table: "Bounty" using primary key columns"""
  Bounty_by_pk(id: String!): Bounty

  """
  fetch data from the table in a streaming manner: "Bounty"
  """
  Bounty_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [Bounty_stream_cursor_input]!

    """filter the rows returned"""
    where: Bounty_bool_exp
  ): [Bounty!]!

  """
  fetch data from the table: "CurveDayData"
  """
  CurveDayData(
    """distinct select on columns"""
    distinct_on: [CurveDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveDayData_order_by!]

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): [CurveDayData!]!

  """
  fetch aggregated fields from the table: "CurveDayData"
  """
  CurveDayData_aggregate(
    """distinct select on columns"""
    distinct_on: [CurveDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveDayData_order_by!]

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): CurveDayData_aggregate!

  """fetch data from the table: "CurveDayData" using primary key columns"""
  CurveDayData_by_pk(id: String!): CurveDayData

  """
  fetch data from the table in a streaming manner: "CurveDayData"
  """
  CurveDayData_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [CurveDayData_stream_cursor_input]!

    """filter the rows returned"""
    where: CurveDayData_bool_exp
  ): [CurveDayData!]!

  """
  fetch data from the table: "CurveHourData"
  """
  CurveHourData(
    """distinct select on columns"""
    distinct_on: [CurveHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveHourData_order_by!]

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): [CurveHourData!]!

  """
  fetch aggregated fields from the table: "CurveHourData"
  """
  CurveHourData_aggregate(
    """distinct select on columns"""
    distinct_on: [CurveHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [CurveHourData_order_by!]

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): CurveHourData_aggregate!

  """fetch data from the table: "CurveHourData" using primary key columns"""
  CurveHourData_by_pk(id: String!): CurveHourData

  """
  fetch data from the table in a streaming manner: "CurveHourData"
  """
  CurveHourData_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [CurveHourData_stream_cursor_input]!

    """filter the rows returned"""
    where: CurveHourData_bool_exp
  ): [CurveHourData!]!

  """
  fetch data from the table: "Deposit"
  """
  Deposit(
    """distinct select on columns"""
    distinct_on: [Deposit_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Deposit_order_by!]

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): [Deposit!]!

  """
  fetch data from the table: "DepositVault"
  """
  DepositVault(
    """distinct select on columns"""
    distinct_on: [DepositVault_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [DepositVault_order_by!]

    """filter the rows returned"""
    where: DepositVault_bool_exp
  ): [DepositVault!]!

  """
  fetch aggregated fields from the table: "DepositVault"
  """
  DepositVault_aggregate(
    """distinct select on columns"""
    distinct_on: [DepositVault_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [DepositVault_order_by!]

    """filter the rows returned"""
    where: DepositVault_bool_exp
  ): DepositVault_aggregate!

  """fetch data from the table: "DepositVault" using primary key columns"""
  DepositVault_by_pk(id: String!): DepositVault

  """
  fetch data from the table in a streaming manner: "DepositVault"
  """
  DepositVault_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [DepositVault_stream_cursor_input]!

    """filter the rows returned"""
    where: DepositVault_bool_exp
  ): [DepositVault!]!

  """
  fetch aggregated fields from the table: "Deposit"
  """
  Deposit_aggregate(
    """distinct select on columns"""
    distinct_on: [Deposit_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Deposit_order_by!]

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): Deposit_aggregate!

  """fetch data from the table: "Deposit" using primary key columns"""
  Deposit_by_pk(id: String!): Deposit

  """
  fetch data from the table in a streaming manner: "Deposit"
  """
  Deposit_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [Deposit_stream_cursor_input]!

    """filter the rows returned"""
    where: Deposit_bool_exp
  ): [Deposit!]!

  """
  fetch data from the table: "IssuanceTokenDayData"
  """
  IssuanceTokenDayData(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenDayData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): [IssuanceTokenDayData!]!

  """
  fetch aggregated fields from the table: "IssuanceTokenDayData"
  """
  IssuanceTokenDayData_aggregate(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenDayData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenDayData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): IssuanceTokenDayData_aggregate!

  """
  fetch data from the table: "IssuanceTokenDayData" using primary key columns
  """
  IssuanceTokenDayData_by_pk(id: String!): IssuanceTokenDayData

  """
  fetch data from the table in a streaming manner: "IssuanceTokenDayData"
  """
  IssuanceTokenDayData_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [IssuanceTokenDayData_stream_cursor_input]!

    """filter the rows returned"""
    where: IssuanceTokenDayData_bool_exp
  ): [IssuanceTokenDayData!]!

  """
  fetch data from the table: "IssuanceTokenHourData"
  """
  IssuanceTokenHourData(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenHourData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): [IssuanceTokenHourData!]!

  """
  fetch aggregated fields from the table: "IssuanceTokenHourData"
  """
  IssuanceTokenHourData_aggregate(
    """distinct select on columns"""
    distinct_on: [IssuanceTokenHourData_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [IssuanceTokenHourData_order_by!]

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): IssuanceTokenHourData_aggregate!

  """
  fetch data from the table: "IssuanceTokenHourData" using primary key columns
  """
  IssuanceTokenHourData_by_pk(id: String!): IssuanceTokenHourData

  """
  fetch data from the table in a streaming manner: "IssuanceTokenHourData"
  """
  IssuanceTokenHourData_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [IssuanceTokenHourData_stream_cursor_input]!

    """filter the rows returned"""
    where: IssuanceTokenHourData_bool_exp
  ): [IssuanceTokenHourData!]!

  """
  fetch data from the table: "LinearVesting"
  """
  LinearVesting(
    """distinct select on columns"""
    distinct_on: [LinearVesting_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [LinearVesting_order_by!]

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): [LinearVesting!]!

  """
  fetch aggregated fields from the table: "LinearVesting"
  """
  LinearVesting_aggregate(
    """distinct select on columns"""
    distinct_on: [LinearVesting_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [LinearVesting_order_by!]

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): LinearVesting_aggregate!

  """fetch data from the table: "LinearVesting" using primary key columns"""
  LinearVesting_by_pk(id: String!): LinearVesting

  """
  fetch data from the table in a streaming manner: "LinearVesting"
  """
  LinearVesting_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [LinearVesting_stream_cursor_input]!

    """filter the rows returned"""
    where: LinearVesting_bool_exp
  ): [LinearVesting!]!

  """
  fetch data from the table: "ProjectFee"
  """
  ProjectFee(
    """distinct select on columns"""
    distinct_on: [ProjectFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProjectFee_order_by!]

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): [ProjectFee!]!

  """
  fetch aggregated fields from the table: "ProjectFee"
  """
  ProjectFee_aggregate(
    """distinct select on columns"""
    distinct_on: [ProjectFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProjectFee_order_by!]

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): ProjectFee_aggregate!

  """fetch data from the table: "ProjectFee" using primary key columns"""
  ProjectFee_by_pk(id: String!): ProjectFee

  """
  fetch data from the table in a streaming manner: "ProjectFee"
  """
  ProjectFee_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [ProjectFee_stream_cursor_input]!

    """filter the rows returned"""
    where: ProjectFee_bool_exp
  ): [ProjectFee!]!

  """
  fetch data from the table: "ProtocolFee"
  """
  ProtocolFee(
    """distinct select on columns"""
    distinct_on: [ProtocolFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProtocolFee_order_by!]

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): [ProtocolFee!]!

  """
  fetch aggregated fields from the table: "ProtocolFee"
  """
  ProtocolFee_aggregate(
    """distinct select on columns"""
    distinct_on: [ProtocolFee_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [ProtocolFee_order_by!]

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): ProtocolFee_aggregate!

  """fetch data from the table: "ProtocolFee" using primary key columns"""
  ProtocolFee_by_pk(id: String!): ProtocolFee

  """
  fetch data from the table in a streaming manner: "ProtocolFee"
  """
  ProtocolFee_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [ProtocolFee_stream_cursor_input]!

    """filter the rows returned"""
    where: ProtocolFee_bool_exp
  ): [ProtocolFee!]!

  """
  fetch data from the table: "StreamingPaymentProcessor"
  """
  StreamingPaymentProcessor(
    """distinct select on columns"""
    distinct_on: [StreamingPaymentProcessor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [StreamingPaymentProcessor_order_by!]

    """filter the rows returned"""
    where: StreamingPaymentProcessor_bool_exp
  ): [StreamingPaymentProcessor!]!

  """
  fetch aggregated fields from the table: "StreamingPaymentProcessor"
  """
  StreamingPaymentProcessor_aggregate(
    """distinct select on columns"""
    distinct_on: [StreamingPaymentProcessor_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [StreamingPaymentProcessor_order_by!]

    """filter the rows returned"""
    where: StreamingPaymentProcessor_bool_exp
  ): StreamingPaymentProcessor_aggregate!

  """
  fetch data from the table: "StreamingPaymentProcessor" using primary key columns
  """
  StreamingPaymentProcessor_by_pk(id: String!): StreamingPaymentProcessor

  """
  fetch data from the table in a streaming manner: "StreamingPaymentProcessor"
  """
  StreamingPaymentProcessor_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [StreamingPaymentProcessor_stream_cursor_input]!

    """filter the rows returned"""
    where: StreamingPaymentProcessor_bool_exp
  ): [StreamingPaymentProcessor!]!

  """
  fetch data from the table: "Swap"
  """
  Swap(
    """distinct select on columns"""
    distinct_on: [Swap_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Swap_order_by!]

    """filter the rows returned"""
    where: Swap_bool_exp
  ): [Swap!]!

  """
  fetch aggregated fields from the table: "Swap"
  """
  Swap_aggregate(
    """distinct select on columns"""
    distinct_on: [Swap_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Swap_order_by!]

    """filter the rows returned"""
    where: Swap_bool_exp
  ): Swap_aggregate!

  """fetch data from the table: "Swap" using primary key columns"""
  Swap_by_pk(id: String!): Swap

  """
  fetch data from the table in a streaming manner: "Swap"
  """
  Swap_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [Swap_stream_cursor_input]!

    """filter the rows returned"""
    where: Swap_bool_exp
  ): [Swap!]!

  """
  fetch data from the table: "Token"
  """
  Token(
    """distinct select on columns"""
    distinct_on: [Token_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Token_order_by!]

    """filter the rows returned"""
    where: Token_bool_exp
  ): [Token!]!

  """
  fetch aggregated fields from the table: "Token"
  """
  Token_aggregate(
    """distinct select on columns"""
    distinct_on: [Token_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Token_order_by!]

    """filter the rows returned"""
    where: Token_bool_exp
  ): Token_aggregate!

  """fetch data from the table: "Token" using primary key columns"""
  Token_by_pk(id: String!): Token

  """
  fetch data from the table in a streaming manner: "Token"
  """
  Token_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [Token_stream_cursor_input]!

    """filter the rows returned"""
    where: Token_bool_exp
  ): [Token!]!

  """
  fetch data from the table: "Transfer"
  """
  Transfer(
    """distinct select on columns"""
    distinct_on: [Transfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Transfer_order_by!]

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): [Transfer!]!

  """
  fetch aggregated fields from the table: "Transfer"
  """
  Transfer_aggregate(
    """distinct select on columns"""
    distinct_on: [Transfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Transfer_order_by!]

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): Transfer_aggregate!

  """fetch data from the table: "Transfer" using primary key columns"""
  Transfer_by_pk(id: String!): Transfer

  """
  fetch data from the table in a streaming manner: "Transfer"
  """
  Transfer_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [Transfer_stream_cursor_input]!

    """filter the rows returned"""
    where: Transfer_bool_exp
  ): [Transfer!]!

  """
  fetch data from the table: "Workflow"
  """
  Workflow(
    """distinct select on columns"""
    distinct_on: [Workflow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Workflow_order_by!]

    """filter the rows returned"""
    where: Workflow_bool_exp
  ): [Workflow!]!

  """
  fetch data from the table: "WorkflowModule"
  """
  WorkflowModule(
    """distinct select on columns"""
    distinct_on: [WorkflowModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModule_order_by!]

    """filter the rows returned"""
    where: WorkflowModule_bool_exp
  ): [WorkflowModule!]!

  """
  fetch data from the table: "WorkflowModuleType"
  """
  WorkflowModuleType(
    """distinct select on columns"""
    distinct_on: [WorkflowModuleType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModuleType_order_by!]

    """filter the rows returned"""
    where: WorkflowModuleType_bool_exp
  ): [WorkflowModuleType!]!

  """
  fetch aggregated fields from the table: "WorkflowModuleType"
  """
  WorkflowModuleType_aggregate(
    """distinct select on columns"""
    distinct_on: [WorkflowModuleType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModuleType_order_by!]

    """filter the rows returned"""
    where: WorkflowModuleType_bool_exp
  ): WorkflowModuleType_aggregate!

  """
  fetch data from the table: "WorkflowModuleType" using primary key columns
  """
  WorkflowModuleType_by_pk(id: String!): WorkflowModuleType

  """
  fetch data from the table in a streaming manner: "WorkflowModuleType"
  """
  WorkflowModuleType_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [WorkflowModuleType_stream_cursor_input]!

    """filter the rows returned"""
    where: WorkflowModuleType_bool_exp
  ): [WorkflowModuleType!]!

  """
  fetch aggregated fields from the table: "WorkflowModule"
  """
  WorkflowModule_aggregate(
    """distinct select on columns"""
    distinct_on: [WorkflowModule_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [WorkflowModule_order_by!]

    """filter the rows returned"""
    where: WorkflowModule_bool_exp
  ): WorkflowModule_aggregate!

  """fetch data from the table: "WorkflowModule" using primary key columns"""
  WorkflowModule_by_pk(id: String!): WorkflowModule

  """
  fetch data from the table in a streaming manner: "WorkflowModule"
  """
  WorkflowModule_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [WorkflowModule_stream_cursor_input]!

    """filter the rows returned"""
    where: WorkflowModule_bool_exp
  ): [WorkflowModule!]!

  """
  fetch aggregated fields from the table: "Workflow"
  """
  Workflow_aggregate(
    """distinct select on columns"""
    distinct_on: [Workflow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [Workflow_order_by!]

    """filter the rows returned"""
    where: Workflow_bool_exp
  ): Workflow_aggregate!

  """fetch data from the table: "Workflow" using primary key columns"""
  Workflow_by_pk(id: String!): Workflow

  """
  fetch data from the table in a streaming manner: "Workflow"
  """
  Workflow_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [Workflow_stream_cursor_input]!

    """filter the rows returned"""
    where: Workflow_bool_exp
  ): [Workflow!]!

  """
  fetch data from the table: "chain_metadata"
  """
  chain_metadata(
    """distinct select on columns"""
    distinct_on: [chain_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [chain_metadata_order_by!]

    """filter the rows returned"""
    where: chain_metadata_bool_exp
  ): [chain_metadata!]!

  """
  fetch aggregated fields from the table: "chain_metadata"
  """
  chain_metadata_aggregate(
    """distinct select on columns"""
    distinct_on: [chain_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [chain_metadata_order_by!]

    """filter the rows returned"""
    where: chain_metadata_bool_exp
  ): chain_metadata_aggregate!

  """fetch data from the table: "chain_metadata" using primary key columns"""
  chain_metadata_by_pk(chain_id: Int!): chain_metadata

  """
  fetch data from the table in a streaming manner: "chain_metadata"
  """
  chain_metadata_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [chain_metadata_stream_cursor_input]!

    """filter the rows returned"""
    where: chain_metadata_bool_exp
  ): [chain_metadata!]!

  """
  fetch data from the table: "dynamic_contract_registry"
  """
  dynamic_contract_registry(
    """distinct select on columns"""
    distinct_on: [dynamic_contract_registry_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [dynamic_contract_registry_order_by!]

    """filter the rows returned"""
    where: dynamic_contract_registry_bool_exp
  ): [dynamic_contract_registry!]!

  """
  fetch aggregated fields from the table: "dynamic_contract_registry"
  """
  dynamic_contract_registry_aggregate(
    """distinct select on columns"""
    distinct_on: [dynamic_contract_registry_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [dynamic_contract_registry_order_by!]

    """filter the rows returned"""
    where: dynamic_contract_registry_bool_exp
  ): dynamic_contract_registry_aggregate!

  """
  fetch data from the table: "dynamic_contract_registry" using primary key columns
  """
  dynamic_contract_registry_by_pk(id: String!): dynamic_contract_registry

  """
  fetch data from the table in a streaming manner: "dynamic_contract_registry"
  """
  dynamic_contract_registry_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [dynamic_contract_registry_stream_cursor_input]!

    """filter the rows returned"""
    where: dynamic_contract_registry_bool_exp
  ): [dynamic_contract_registry!]!

  """
  fetch data from the table: "end_of_block_range_scanned_data"
  """
  end_of_block_range_scanned_data(
    """distinct select on columns"""
    distinct_on: [end_of_block_range_scanned_data_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [end_of_block_range_scanned_data_order_by!]

    """filter the rows returned"""
    where: end_of_block_range_scanned_data_bool_exp
  ): [end_of_block_range_scanned_data!]!

  """
  fetch aggregated fields from the table: "end_of_block_range_scanned_data"
  """
  end_of_block_range_scanned_data_aggregate(
    """distinct select on columns"""
    distinct_on: [end_of_block_range_scanned_data_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [end_of_block_range_scanned_data_order_by!]

    """filter the rows returned"""
    where: end_of_block_range_scanned_data_bool_exp
  ): end_of_block_range_scanned_data_aggregate!

  """
  fetch data from the table: "end_of_block_range_scanned_data" using primary key columns
  """
  end_of_block_range_scanned_data_by_pk(block_number: Int!, chain_id: Int!): end_of_block_range_scanned_data

  """
  fetch data from the table in a streaming manner: "end_of_block_range_scanned_data"
  """
  end_of_block_range_scanned_data_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [end_of_block_range_scanned_data_stream_cursor_input]!

    """filter the rows returned"""
    where: end_of_block_range_scanned_data_bool_exp
  ): [end_of_block_range_scanned_data!]!

  """
  fetch data from the table: "event_sync_state"
  """
  event_sync_state(
    """distinct select on columns"""
    distinct_on: [event_sync_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [event_sync_state_order_by!]

    """filter the rows returned"""
    where: event_sync_state_bool_exp
  ): [event_sync_state!]!

  """
  fetch aggregated fields from the table: "event_sync_state"
  """
  event_sync_state_aggregate(
    """distinct select on columns"""
    distinct_on: [event_sync_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [event_sync_state_order_by!]

    """filter the rows returned"""
    where: event_sync_state_bool_exp
  ): event_sync_state_aggregate!

  """
  fetch data from the table: "event_sync_state" using primary key columns
  """
  event_sync_state_by_pk(chain_id: Int!): event_sync_state

  """
  fetch data from the table in a streaming manner: "event_sync_state"
  """
  event_sync_state_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [event_sync_state_stream_cursor_input]!

    """filter the rows returned"""
    where: event_sync_state_bool_exp
  ): [event_sync_state!]!

  """
  fetch data from the table: "persisted_state"
  """
  persisted_state(
    """distinct select on columns"""
    distinct_on: [persisted_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [persisted_state_order_by!]

    """filter the rows returned"""
    where: persisted_state_bool_exp
  ): [persisted_state!]!

  """
  fetch aggregated fields from the table: "persisted_state"
  """
  persisted_state_aggregate(
    """distinct select on columns"""
    distinct_on: [persisted_state_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [persisted_state_order_by!]

    """filter the rows returned"""
    where: persisted_state_bool_exp
  ): persisted_state_aggregate!

  """fetch data from the table: "persisted_state" using primary key columns"""
  persisted_state_by_pk(id: Int!): persisted_state

  """
  fetch data from the table in a streaming manner: "persisted_state"
  """
  persisted_state_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [persisted_state_stream_cursor_input]!

    """filter the rows returned"""
    where: persisted_state_bool_exp
  ): [persisted_state!]!

  """
  fetch data from the table: "raw_events"
  """
  raw_events(
    """distinct select on columns"""
    distinct_on: [raw_events_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [raw_events_order_by!]

    """filter the rows returned"""
    where: raw_events_bool_exp
  ): [raw_events!]!

  """
  fetch aggregated fields from the table: "raw_events"
  """
  raw_events_aggregate(
    """distinct select on columns"""
    distinct_on: [raw_events_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [raw_events_order_by!]

    """filter the rows returned"""
    where: raw_events_bool_exp
  ): raw_events_aggregate!

  """fetch data from the table: "raw_events" using primary key columns"""
  raw_events_by_pk(serial: Int!): raw_events

  """
  fetch data from the table in a streaming manner: "raw_events"
  """
  raw_events_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [raw_events_stream_cursor_input]!

    """filter the rows returned"""
    where: raw_events_bool_exp
  ): [raw_events!]!
}

scalar swaptype

"""
Boolean expression to compare columns of type "swaptype". All fields are combined with logical 'AND'.
"""
input swaptype_comparison_exp {
  _eq: swaptype
  _gt: swaptype
  _gte: swaptype
  _in: [swaptype!]
  _is_null: Boolean
  _lt: swaptype
  _lte: swaptype
  _neq: swaptype
  _nin: [swaptype!]
}

scalar timestamp

"""
Boolean expression to compare columns of type "timestamp". All fields are combined with logical 'AND'.
"""
input timestamp_comparison_exp {
  _eq: timestamp
  _gt: timestamp
  _gte: timestamp
  _in: [timestamp!]
  _is_null: Boolean
  _lt: timestamp
  _lte: timestamp
  _neq: timestamp
  _nin: [timestamp!]
}

scalar timestamptz

"""
Boolean expression to compare columns of type "timestamptz". All fields are combined with logical 'AND'.
"""
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

scalar vestingstatus

"""
Boolean expression to compare columns of type "vestingstatus". All fields are combined with logical 'AND'.
"""
input vestingstatus_comparison_exp {
  _eq: vestingstatus
  _gt: vestingstatus
  _gte: vestingstatus
  _in: [vestingstatus!]
  _is_null: Boolean
  _lt: vestingstatus
  _lte: vestingstatus
  _neq: vestingstatus
  _nin: [vestingstatus!]
}